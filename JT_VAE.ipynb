{"cells":[{"cell_type":"code","source":["import os\nimport glob\nimport gzip\nimport numpy as np\nimport pandas as pd\nimport pickle\nfrom rdkit import Chem\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\n\nimport math, random, sys\nfrom optparse import OptionParser\nfrom collections import deque\n\nfrom icml18_jtnn.jtnn import *\nimport rdkit\nimport csv\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["os.listdir()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[2]: [&#39;conf&#39;, &#39;logs&#39;, &#39;derby.log&#39;, &#39;ganglia&#39;, &#39;eventlogs&#39;]\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["datasets = [\"Homopiperazines\",\"Piperazines\",\"Piperidines\",\"Sulphamides\"]\nnames = [\"JAK1 EC50 nM 1027\",\"JAK2 EC50 nM 1024\",\"JAK3 EC50 nM 1026\"]\nnames = names + ['TYK2 EC50 nM 1025']\nfiles = [\"/dbfs/FileStore/tables/Homopiperazines_cleaned_Feb_2019.sdf\",\n         \"/dbfs/FileStore/tables/Piperazines_cleaned_Feb_2019.sdf\",\n         \"/dbfs/FileStore/tables/Piperidines_cleaned_Feb_2019.sdf\",\n         \"/dbfs/FileStore/tables/Sulphamides_cleaned_Feb_2019.sdf\",\n        ]\nPARENT_DIR = '/dbfs/FileStore/tables'\nPICKLES_DIR = '/dbfs/FileStore/pickles'\nMODEL_DIR = os.path.join(PICKLES_DIR, \"jtvae_model\")\nMOSES_DIR = '/dbfs/FileStore/moses'\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["#full_descriptors = pickle.load(open('/'.join([PICKLES_DIR,'20190317-full_descriptors.p']),'rb'))\nfull_internal = pickle.load(open('/'.join([PICKLES_DIR,'20190317-full_internal.p']),'rb')).dropna(subset=names)\nprint(full_internal.shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(1825, 25)\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["from molvs import Standardizer\ns = Standardizer()\nfull_internal['Isomeric_canon'] = [Chem.MolToSmiles(s.standardize(Chem.MolFromSmiles(smi)), canonical = True) for smi in full_internal['Canonical Smiles']]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(full_internal.filter(['Isomeric_canon']), full_internal.filter(names), test_size=0.2, random_state=7)\n\nfull_internal.filter(['Isomeric_canon']).to_csv(os.path.join(PARENT_DIR,'full_smiles.txt'), header=None,index=False)\nX_train.filter(['Isomeric_canon']).to_csv(os.path.join(PARENT_DIR,'X_train_smiles.txt'), header=None,index=False)\nX_test.filter(['Isomeric_canon']).to_csv(os.path.join(PARENT_DIR,'X_test_smiles.txt'), header=None,index=False)\nfor name in names:\n  full_internal.filter([name]).to_csv(os.path.join(PARENT_DIR,name+'-full.txt'), header=None,index=False)\n  y_train.filter([name]).to_csv(os.path.join(PARENT_DIR,name+'-y_train.txt'), header=None,index=False)\n  y_test.filter([name]).to_csv(os.path.join(PARENT_DIR,name+'-y_test.txt'), header=None,index=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["X_train = pd.read_csv(os.path.join(PARENT_DIR,'X_train_smiles.txt'), header=None, squeeze=True).astype(str).tolist()\nX_test = pd.read_csv(os.path.join(PARENT_DIR,'X_test_smiles.txt'), header=None, squeeze=True).astype(str).tolist()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["zinc_13t09 = pd.read_csv('/dbfs/FileStore/ZINC/13_t90.smi',sep='\\t', header=None)\nzinc_13t09 = zinc_13t09.rename(columns={0:'Canonical Smiles',1:'ID'})\nfrom rdkit.Chem import Descriptors, Lipinski\nfrom mordred import SLogP, Calculator\n\nmols = [Chem.MolFromSmiles(smi) for smi in zinc_13t09['Canonical Smiles'] if Chem.MolFromSmiles(smi) is not None]\nrb = [Descriptors.NumRotatableBonds(mol) for mol in mols]\nhbd = [Lipinski.NumHDonors(mol) for mol in mols]\nhba = [Lipinski.NumHAcceptors(mol) for mol in mols]\npsa = [Descriptors.TPSA(mol) for mol in mols]\n\ncalc1 = Calculator()\ncalc1.register(SLogP)\nslogp = calc1.pandas(mols,nproc=1)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1862933486268680&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     14</span> slogp <span class=\"ansi-blue-fg\">=</span> calc1<span class=\"ansi-blue-fg\">.</span>pandas<span class=\"ansi-blue-fg\">(</span>mols<span class=\"ansi-blue-fg\">,</span>nproc<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     15</span> <span class=\"ansi-green-fg\">import</span> seaborn <span class=\"ansi-green-fg\">as</span> sns<span class=\"ansi-blue-fg\">;</span> sns<span class=\"ansi-blue-fg\">.</span>set<span class=\"ansi-blue-fg\">(</span>color_codes<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">True</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 16</span><span class=\"ansi-red-fg\"> </span>plt<span class=\"ansi-blue-fg\">.</span>close<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     17</span> fig <span class=\"ansi-blue-fg\">=</span> plt<span class=\"ansi-blue-fg\">.</span>figure<span class=\"ansi-blue-fg\">(</span>figsize<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">12</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-cyan-fg\">2.5</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     18</span> plt<span class=\"ansi-blue-fg\">.</span>subplot<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-cyan-fg\">5</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;plt&#39; is not defined</div>"]}}],"execution_count":8},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nimport seaborn as sns; sns.set(color_codes=True)\nplt.close()\nfig = plt.figure(figsize=(12,2.5))\nplt.subplot(1,5,1)\nax = sns.kdeplot(slogp['SLogP'].tolist(), shade=True, color=\"r\")\nax.set_title('SLogP')\nplt.subplot(1,5,2)\nax = sns.kdeplot(psa, shade=True, color=\"b\")\nax.set_title('TPSA')\nplt.subplot(1,5,3)\nplt.hist(rb)\nplt.title('Rotatable Bonds')\nplt.subplot(1,5,4)\nplt.hist(hbd)\nplt.title('HB Donors')\nplt.subplot(1,5,5)\nplt.hist(hba)\nplt.title('HB Acceptors')\nplt.tight_layout()\ndisplay(plt.show())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"image/png":["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"]}}],"execution_count":9},{"cell_type":"code","source":["zinc_13t09_clean = [Chem.MolToSmiles(s.standardize(mol), canonical = True) for mol in mols]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["print(full_internal['Isomeric_canon'].str.contains('@').any())\nprint(any('@' in smi for smi in zinc_13t09_clean))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">True\nTrue\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["filt_13t09 = pd.read_csv(os.path.join(PARENT_DIR,'13_t90_exPAINS.csv'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["filt_13t09 = filt_13t09[filt_13t09.FILTER=='OK']"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["Preprocessing"],"metadata":{}},{"cell_type":"code","source":["from icml18_jtnn.fast_jtnn.mol_tree import *\ncset = set()\nfor line in full_internal['Isomeric_canon']:\n    #smiles = line.split()[0]\n    mol = MolTree(line)\n    for c in mol.nodes:\n        cset.add(c.smiles)\nprint(len(cset))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">87\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["zinc_13t09_clean = [Chem.MolToSmiles(s.standardize(Chem.MolFromSmiles(smi)), canonical = True) for smi in zinc_13t09_clean]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["filt_13t09.SMILES = [Chem.MolToSmiles(s.standardize(Chem.MolFromSmiles(smi)), canonical = True) for smi in filt_13t09.SMILES]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["pickle.dump(zinc_13t09_clean, open(os.path.join(PICKLES_DIR,'13t09_clean.p'),'wb'))\npickle.dump(filt_13t09.SMILES.tolist(), open(os.path.join(PICKLES_DIR,'13t09_filt.p'),'wb'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["import pickle \nlen(pickle.load(open(os.path.join(PICKLES_DIR,'13t09_filt.p'),'rb')))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3211997084194649&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">import</span> pickle\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>len<span class=\"ansi-blue-fg\">(</span>pickle<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>open<span class=\"ansi-blue-fg\">(</span>os<span class=\"ansi-blue-fg\">.</span>path<span class=\"ansi-blue-fg\">.</span>join<span class=\"ansi-blue-fg\">(</span>PICKLES_DIR<span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;13t09_filt.p&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;rb&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;os&#39; is not defined</div>"]}}],"execution_count":19},{"cell_type":"code","source":["# vocab for full_internal + ZINC_13t09\n#from IPython import display\nfrom icml18_jtnn.fast_jtnn.mol_tree import *\ncset = set()\nsize = len(full_internal['Isomeric_canon'].tolist()+zinc_13t09_clean)\nfor i, line in enumerate(full_internal['Isomeric_canon'].tolist()+zinc_13t09_clean):\n    #print(i,'/',size)\n    #display.clear_output(wait=True)\n    #smiles = line.split()[0]\n    mol = MolTree(line)\n    for c in mol.nodes:\n        cset.add(c.smiles)\npickle.dump(Vocab(list(cset)),open(os.path.join(PICKLES_DIR,'Vocab-full_internal-ZINC_13t09.p'),'wb'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"code","source":["# vocab for full_internal + ZINC_13t09_filtered\n#from IPython import display\nfrom icml18_jtnn.fast_jtnn.mol_tree import *\ncset = set()\nsize = len(full_internal['Isomeric_canon'].tolist()+filt_13t09.SMILES.tolist())\nfor i, line in enumerate(full_internal['Isomeric_canon'].tolist()+filt_13t09.SMILES.tolist()):\n    #print(i,'/',size)\n    #display.clear_output(wait=True)\n    #smiles = line.split()[0]\n    mol = MolTree(line)\n    for c in mol.nodes:\n        cset.add(c.smiles)\nprint(len(cset))\npickle.dump(Vocab(list(cset)),open(os.path.join(PICKLES_DIR,'Vocab-full_internal-ZINC_13t09_filt.p'),'wb'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">629\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["with open('/dbfs/FileStore/ZINC/13t09_clean.txt', 'w+') as f:\n  f.write('\\n'.join(zinc_13t09_clean))\n  f.close()\nfilt_13t09.filter(['SMILES']).to_csv('/dbfs/FileStore/ZINC/13t09_filt.txt',header=None,index=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["%sh head /dbfs/FileStore/ZINC/13t09_filt.txt"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Cc1n[n-]c(C(F)(F)F)n1\n[O-]c1cc([O-])n2nncc2n1\n[O-]c1cc([O-])n2ncnc2n1\nCc1cc(C(F)(F)F)co1\nCc1ccc(C(F)(F)F)o1\nCc1ncc(C(F)(F)F)[nH]1\nCc1[nH]cnc1C(F)(F)F\nCc1c[nH]nc1C(F)(F)F\nCn1nccc1C(F)(F)F\nFC(F)(F)Cc1c[nH]cn1\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["def train_prop(model, lr, beta, batch_size, MAX_EPOCH, SAVE_DIR, SMILES_DIR, PROP_DIR, pretrain=True, model_path=None, PRINT_ITER=20, last_epoch = 0, log_file=None):\n    if pretrain:\n        for param in model.parameters():\n            if param.dim() == 1:\n                nn.init.constant(param, 0)\n            else:\n                nn.init.xavier_normal(param)\n    else:\n        model.load_state_dict(torch.load(model_path))\n    model = model.cuda()\n    print( \"Model #Params: %dK\" % (sum([x.nelement() for x in model.parameters()]) / 1000,))\n\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    scheduler = lr_scheduler.ExponentialLR(optimizer, 0.9)\n    scheduler.step()\n\n    dataset = PropDataset(SMILES_DIR, PROP_DIR)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=lambda x:x)\n\n    if log_file:\n        of_connection = open(out_file, 'w')\n        writer = csv.writer(of_connection)\n\n        # Write the headers to the file\n        writer.writerow(['loss', 'kl_div', 'wacc', 'tacc', 'sacc', 'dacc', 'word_acc', 'topo_acc', 'assm_acc', 'steo_acc'])\n    #MAX_EPOCH = int(3)\n    #PRINT_ITER = 20\n\n    for epoch in range(MAX_EPOCH):\n        word_acc,topo_acc,assm_acc,steo_acc,prop_acc = 0,0,0,0,0\n\n        for it, batch in enumerate(dataloader):\n            for mol_tree,_ in batch:\n                for node in mol_tree.nodes:\n                    if node.label not in node.cands:\n                        node.cands.append(node.label)\n                        node.cand_mols.append(node.label_mol)\n\n            model.zero_grad()\n            loss, kl_div, wacc, tacc, sacc, dacc, pacc = model(batch, beta=beta)\n            loss.backward()\n            optimizer.step()\n\n            word_acc += wacc\n            topo_acc += tacc\n            assm_acc += sacc\n            steo_acc += dacc\n            prop_acc += pacc\n            writer.writerow([loss, kl_div, wacc, tacc, sacc, dacc, word_acc, topo_acc, assm_acc, steo_acc])\n            if (it + 1) % PRINT_ITER == 0:\n                word_acc = word_acc / PRINT_ITER * 100\n                topo_acc = topo_acc / PRINT_ITER * 100\n                assm_acc = assm_acc / PRINT_ITER * 100\n                steo_acc = steo_acc / PRINT_ITER * 100\n                prop_acc = prop_acc / PRINT_ITER\n\n                print(\"KL: %.1f, Word: %.2f, Topo: %.2f, Assm: %.2f, Steo: %.2f, Prop: %.4f\" % (kl_div, word_acc, topo_acc, assm_acc, steo_acc, prop_acc))\n                word_acc,topo_acc,assm_acc,steo_acc,prop_acc = 0,0,0,0,0\n                sys.stdout.flush()\n\n        scheduler.step()\n        print( \"learning rate: %.6f\" % scheduler.get_lr()[0])\n        if not os.path.exists(SAVE_DIR):\n            os.makedirs(SAVE_DIR)\n        savename = \"/prop_model.iter-\"\n        if pretrain:\n            savename = \"/pretrain_KL-prop_model.iter-\"\n        torch.save(model.state_dict(), SAVE_DIR + savename + str(epoch+last_epoch))\n        print('\\nModel saved to: ',SAVE_DIR + savename + str(epoch+last_epoch))\n    of_connection.close()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"code","source":["def train_vae(model, lr, beta, batch_size, MAX_EPOCH, SAVE_DIR, SMILES_DIR, pretrain=True, model_load=None, PRINT_ITER=20, last_epoch = 0, log_file=None):\n    if pretrain:\n        for param in model.parameters():\n            if param.dim() == 1:\n                nn.init.constant(param, 0)\n            else:\n                nn.init.xavier_normal(param)\n    else:\n        model.load_state_dict(torch.load(model_load))\n    model = model.cuda()\n    print( \"Model #Params: %dK\" % (sum([x.nelement() for x in model.parameters()]) / 1000,))\n\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    scheduler = lr_scheduler.ExponentialLR(optimizer, 0.9)\n    scheduler.step()\n    log_df = []\n    dataset = MoleculeDataset(SMILES_DIR)\n    last_epoch+=1\n    if log_file:\n        of_connection = open(out_file, 'w')\n        writer = csv.writer(of_connection)\n\n        # Write the headers to the file\n        writer.writerow(['loss', 'kl_div', 'wacc', 'tacc', 'sacc', 'dacc', 'word_acc', 'topo_acc', 'assm_acc', 'steo_acc'])\n    #MAX_EPOCH = int(3)\n    #PRINT_ITER = 20\n\n    for epoch in range(MAX_EPOCH):\n        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=lambda x:x, \n                                drop_last=True)\n        \n        word_acc,topo_acc,assm_acc,steo_acc= 0,0,0,0\n\n        for it, batch in enumerate(dataloader):\n            for mol_tree in batch:\n                for node in mol_tree.nodes:\n                    if node.label not in node.cands:\n                        node.cands.append(node.label)\n                        node.cand_mols.append(node.label_mol)\n\n            model.zero_grad()\n            loss, kl_div, wacc, tacc, sacc, dacc = model(batch, beta=beta)\n            loss.backward()\n            optimizer.step()\n            \n            word_acc += wacc\n            topo_acc += tacc\n            assm_acc += sacc\n            steo_acc += dacc\n            #prop_acc += pacc\n            \n            \n            writer.writerow([loss, kl_div, wacc, tacc, sacc, dacc, word_acc, topo_acc, assm_acc, steo_acc])\n            \n            if (it + 1) % PRINT_ITER == 0:\n                word_acc = word_acc / PRINT_ITER * 100\n                topo_acc = topo_acc / PRINT_ITER * 100\n                assm_acc = assm_acc / PRINT_ITER * 100\n                steo_acc = steo_acc / PRINT_ITER * 100\n                #prop_acc = prop_acc / PRINT_ITER\n\n                print(\"KL: %.1f, Word: %.2f, Topo: %.2f, Assm: %.2f, Steo: %.2f\" % \n                      (kl_div, word_acc, topo_acc, assm_acc, steo_acc))\n                word_acc,topo_acc,assm_acc,steo_acc = 0,0,0,0\n                sys.stdout.flush()\n    \n        scheduler.step()\n        print( \"learning rate: %.6f\" % scheduler.get_lr()[0])\n        if not os.path.exists(SAVE_DIR):\n            os.makedirs(SAVE_DIR)\n        savename = \"/vae_model.iter-\"\n        if pretrain:\n            savename = \"/pretrain-vae_model.iter-\"\n        torch.save(model.state_dict(), SAVE_DIR + savename + str(epoch+last_epoch))\n        print('Model saved to: ',SAVE_DIR + savename + str(epoch+last_epoch)+'\\n')\n    of_connection.close()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["# Pretrain"],"metadata":{}},{"cell_type":"code","source":["vocab = pickle.load(open(os.path.join(PICKLES_DIR,'Vocab-full_internal-ZINC_13t09.p'),'rb'))\n\nweight_dir = os.path.join(MODEL_DIR,'13t09_clean')\nif not os.path.exists(weight_dir):\n  os.mkdir(weight_dir)\nout_file = os.path.join(weight_dir,'pretrain_log-13t09_clean.csv')\n\nbatch_size = int(40)\nhidden_size = int(420)\nlatent_size = int(56)\ndepth = int(3)\nbeta = 0.0\nlr = 1e-3\n\nmodel = JTNNVAE(vocab, hidden_size, latent_size, depth)\n\ntrain_vae(model=model, \n          lr=lr, \n          beta=beta, \n          batch_size=batch_size, \n          MAX_EPOCH=30, \n          SAVE_DIR=weight_dir, \n          SMILES_DIR='/dbfs/FileStore/ZINC/13t09_clean.txt', \n          pretrain=True, \n          PRINT_ITER=20,\n          log_file=out_file)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["vocab = pickle.load(open(os.path.join(PICKLES_DIR,'Vocab-full_internal-ZINC_13t09_filt.p'),'rb'))\n\nweight_dir = os.path.join(MODEL_DIR,'13t09_filt')\nif not os.path.exists(weight_dir):\n  os.mkdir(weight_dir)\nout_file = os.path.join(weight_dir,'pretrain_log-13t09_filt.csv')\n\nbatch_size = int(40)\nhidden_size = int(420)\nlatent_size = int(56)\ndepth = int(3)\nbeta = 0.0\nlr = 1e-3\n\nmodel = JTNNVAE(vocab, hidden_size, latent_size, depth)\n\ntrain_vae(model=model, \n          lr=lr, \n          beta=beta, \n          batch_size=batch_size, \n          MAX_EPOCH=30, \n          SAVE_DIR=weight_dir, \n          SMILES_DIR='/dbfs/FileStore/ZINC/13t09_filt.txt', \n          pretrain=True, \n          PRINT_ITER=20,\n          log_file=out_file)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction=&#39;sum&#39; instead.\n  warnings.warn(warning.format(ret))\n/local_disk0/tmp/1556727629545-0/PythonShell.py:7: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n  import pickle\n/local_disk0/tmp/1556727629545-0/PythonShell.py:5: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n  import linecache\nModel #Params: 4377K\n/local_disk0/spark-de16ad5c-8f36-432f-99f8-154216fd263f/userFiles-7c134309-84ad-48bf-9f1a-7ad652c1b0dc/addedFile6234755862196679065dbfs__FileStore_jars_23c5a07d_a093_423e_97a9_a303ec5f6ff5_icml18_jtnn_0_1_py3_7_3fd5e-93fb9.egg/icml18_jtnn/jtnn/jtnn_vae.py:166: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\nKL: 117.9, Word: 20.10, Topo: 72.51, Assm: 48.36, Steo: 62.50\nKL: 128.8, Word: 26.49, Topo: 86.32, Assm: 52.89, Steo: 56.67\nKL: 155.9, Word: 29.46, Topo: 90.19, Assm: 53.40, Steo: 57.50\nKL: 174.1, Word: 37.48, Topo: 90.64, Assm: 51.91, Steo: 60.83\nKL: 197.4, Word: 44.16, Topo: 92.10, Assm: 51.62, Steo: 77.92\nKL: 235.5, Word: 48.18, Topo: 93.93, Assm: 53.67, Steo: 75.00\nKL: 213.6, Word: 53.57, Topo: 93.99, Assm: 52.63, Steo: 71.25\nKL: 256.0, Word: 54.58, Topo: 94.30, Assm: 56.59, Steo: 72.50\nKL: 297.9, Word: 58.84, Topo: 95.13, Assm: 56.15, Steo: 74.17\nKL: 285.4, Word: 60.56, Topo: 94.73, Assm: 58.14, Steo: 82.50\nKL: 335.5, Word: 61.69, Topo: 95.47, Assm: 60.43, Steo: 97.50\nKL: 311.3, Word: 63.15, Topo: 95.56, Assm: 59.30, Steo: 95.00\nKL: 363.7, Word: 64.63, Topo: 95.44, Assm: 60.25, Steo: 100.00\nKL: 376.7, Word: 65.34, Topo: 96.26, Assm: 57.36, Steo: 100.00\nKL: 479.5, Word: 65.60, Topo: 96.47, Assm: 62.03, Steo: 98.33\nKL: 387.5, Word: 67.38, Topo: 96.50, Assm: 62.08, Steo: 100.00\nKL: 444.3, Word: 68.48, Topo: 96.51, Assm: 64.55, Steo: 95.00\nKL: 460.8, Word: 69.60, Topo: 94.46, Assm: 66.33, Steo: 92.50\nKL: 469.4, Word: 70.94, Topo: 94.79, Assm: 64.70, Steo: 100.00\nKL: 450.0, Word: 71.19, Topo: 96.11, Assm: 63.13, Steo: 98.33\nKL: 459.5, Word: 73.30, Topo: 96.53, Assm: 63.64, Steo: 100.00\nKL: 517.9, Word: 72.98, Topo: 97.03, Assm: 65.44, Steo: 100.00\nKL: 472.6, Word: 73.03, Topo: 96.00, Assm: 66.10, Steo: 100.00\nKL: 444.4, Word: 73.61, Topo: 96.32, Assm: 66.10, Steo: 100.00\nKL: 498.7, Word: 74.83, Topo: 96.54, Assm: 67.80, Steo: 100.00\nKL: 508.4, Word: 75.70, Topo: 96.88, Assm: 65.94, Steo: 100.00\nKL: 496.5, Word: 76.27, Topo: 97.11, Assm: 66.64, Steo: 100.00\nKL: 502.1, Word: 76.97, Topo: 97.00, Assm: 66.91, Steo: 100.00\nKL: 558.0, Word: 78.30, Topo: 96.73, Assm: 67.05, Steo: 100.00\nKL: 569.5, Word: 78.36, Topo: 97.68, Assm: 69.81, Steo: 100.00\nKL: 633.8, Word: 78.87, Topo: 97.49, Assm: 68.63, Steo: 100.00\nKL: 611.6, Word: 79.14, Topo: 97.44, Assm: 70.02, Steo: 100.00\nKL: 570.3, Word: 79.13, Topo: 96.74, Assm: 69.32, Steo: 100.00\nKL: 591.8, Word: 78.84, Topo: 97.86, Assm: 70.08, Steo: 100.00\nKL: 593.8, Word: 79.40, Topo: 97.26, Assm: 70.38, Steo: 100.00\nKL: 645.1, Word: 80.33, Topo: 97.28, Assm: 69.78, Steo: 95.00\nKL: 614.9, Word: 80.64, Topo: 97.14, Assm: 69.72, Steo: 95.00\nKL: 663.9, Word: 80.48, Topo: 97.31, Assm: 68.59, Steo: 100.00\nKL: 576.4, Word: 81.14, Topo: 97.77, Assm: 70.53, Steo: 100.00\nKL: 649.0, Word: 82.97, Topo: 97.33, Assm: 70.98, Steo: 100.00\nKL: 635.5, Word: 83.10, Topo: 97.44, Assm: 72.11, Steo: 100.00\nKL: 664.6, Word: 82.85, Topo: 97.49, Assm: 72.65, Steo: 100.00\nKL: 708.4, Word: 83.63, Topo: 97.75, Assm: 70.16, Steo: 100.00\nKL: 645.4, Word: 84.29, Topo: 97.58, Assm: 69.40, Steo: 100.00\nKL: 639.7, Word: 84.47, Topo: 97.95, Assm: 72.13, Steo: 100.00\nKL: 686.1, Word: 84.18, Topo: 97.55, Assm: 71.32, Steo: 100.00\nKL: 701.8, Word: 83.34, Topo: 97.90, Assm: 73.53, Steo: 100.00\nKL: 699.0, Word: 85.25, Topo: 97.92, Assm: 74.65, Steo: 100.00\nKL: 671.8, Word: 84.95, Topo: 97.98, Assm: 71.38, Steo: 100.00\nKL: 698.3, Word: 85.34, Topo: 98.20, Assm: 76.31, Steo: 100.00\nKL: 800.3, Word: 84.76, Topo: 97.84, Assm: 76.69, Steo: 100.00\nKL: 689.4, Word: 84.93, Topo: 97.76, Assm: 77.61, Steo: 100.00\nKL: 643.8, Word: 84.72, Topo: 97.34, Assm: 74.55, Steo: 100.00\nKL: 673.1, Word: 85.43, Topo: 97.36, Assm: 78.10, Steo: 100.00\nKL: 735.6, Word: 86.17, Topo: 97.87, Assm: 77.15, Steo: 100.00\nKL: 750.9, Word: 87.37, Topo: 98.37, Assm: 76.79, Steo: 100.00\nKL: 786.0, Word: 88.04, Topo: 98.43, Assm: 75.98, Steo: 100.00\nKL: 740.0, Word: 88.01, Topo: 98.41, Assm: 78.35, Steo: 100.00\nKL: 733.8, Word: 88.23, Topo: 98.14, Assm: 78.46, Steo: 100.00\nKL: 762.5, Word: 88.33, Topo: 98.35, Assm: 78.25, Steo: 100.00\nKL: 828.5, Word: 87.67, Topo: 98.52, Assm: 78.76, Steo: 100.00\nKL: 775.0, Word: 89.11, Topo: 98.43, Assm: 77.55, Steo: 100.00\nKL: 786.2, Word: 88.91, Topo: 98.67, Assm: 79.26, Steo: 100.00\nKL: 853.8, Word: 89.61, Topo: 98.32, Assm: 79.60, Steo: 100.00\nKL: 763.1, Word: 88.72, Topo: 98.50, Assm: 80.11, Steo: 100.00\nKL: 790.4, Word: 89.81, Topo: 98.60, Assm: 79.90, Steo: 100.00\nlearning rate: 0.000900\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/pretrain-vae_model.iter-1\n\nKL: 809.9, Word: 89.62, Topo: 98.64, Assm: 80.36, Steo: 100.00\nKL: 850.4, Word: 90.41, Topo: 98.96, Assm: 81.79, Steo: 100.00\nKL: 811.9, Word: 90.69, Topo: 98.87, Assm: 80.93, Steo: 100.00\nKL: 778.3, Word: 90.57, Topo: 98.59, Assm: 79.72, Steo: 98.75\nKL: 857.3, Word: 90.77, Topo: 98.85, Assm: 82.61, Steo: 100.00\nKL: 824.0, Word: 90.58, Topo: 98.71, Assm: 81.47, Steo: 100.00\nKL: 846.8, Word: 90.24, Topo: 98.70, Assm: 81.83, Steo: 100.00\nKL: 861.2, Word: 90.79, Topo: 98.80, Assm: 83.92, Steo: 100.00\nKL: 776.8, Word: 90.98, Topo: 98.78, Assm: 80.44, Steo: 100.00\nKL: 918.1, Word: 90.50, Topo: 98.62, Assm: 80.72, Steo: 100.00\nKL: 814.4, Word: 90.48, Topo: 98.86, Assm: 81.03, Steo: 100.00\nKL: 897.4, Word: 90.97, Topo: 99.01, Assm: 81.19, Steo: 100.00\nKL: 891.5, Word: 91.18, Topo: 98.85, Assm: 81.84, Steo: 100.00\nKL: 950.5, Word: 91.70, Topo: 98.87, Assm: 81.71, Steo: 100.00\nKL: 877.0, Word: 91.47, Topo: 98.78, Assm: 82.55, Steo: 100.00\nKL: 800.7, Word: 91.13, Topo: 98.80, Assm: 81.77, Steo: 100.00\nKL: 898.9, Word: 92.49, Topo: 99.11, Assm: 83.56, Steo: 100.00\nKL: 862.8, Word: 92.35, Topo: 98.97, Assm: 82.03, Steo: 100.00\nKL: 909.8, Word: 92.46, Topo: 99.05, Assm: 84.43, Steo: 100.00\nKL: 863.6, Word: 91.68, Topo: 98.87, Assm: 83.31, Steo: 100.00\nKL: 883.8, Word: 92.62, Topo: 98.80, Assm: 84.18, Steo: 100.00\nKL: 864.5, Word: 91.69, Topo: 99.09, Assm: 84.36, Steo: 100.00\nKL: 845.5, Word: 92.36, Topo: 99.16, Assm: 81.47, Steo: 100.00\nKL: 878.6, Word: 92.31, Topo: 98.98, Assm: 85.44, Steo: 100.00\nKL: 833.5, Word: 92.06, Topo: 99.11, Assm: 83.32, Steo: 100.00\nKL: 854.7, Word: 90.94, Topo: 98.92, Assm: 83.76, Steo: 100.00\nKL: 859.1, Word: 91.91, Topo: 98.81, Assm: 83.59, Steo: 97.50\nKL: 889.4, Word: 92.00, Topo: 98.93, Assm: 82.84, Steo: 100.00\nKL: 942.7, Word: 92.08, Topo: 99.14, Assm: 83.78, Steo: 100.00\nKL: 980.9, Word: 92.54, Topo: 98.85, Assm: 83.56, Steo: 100.00\nKL: 923.6, Word: 92.78, Topo: 98.52, Assm: 83.96, Steo: 100.00\nKL: 934.6, Word: 92.27, Topo: 98.70, Assm: 82.51, Steo: 100.00\nKL: 914.5, Word: 93.08, Topo: 98.49, Assm: 83.72, Steo: 100.00\nKL: 896.4, Word: 92.75, Topo: 97.50, Assm: 84.34, Steo: 100.00\nKL: 868.6, Word: 92.78, Topo: 98.81, Assm: 83.10, Steo: 100.00\nKL: 880.6, Word: 92.36, Topo: 98.96, Assm: 83.99, Steo: 100.00\nKL: 902.5, Word: 92.63, Topo: 99.06, Assm: 84.99, Steo: 100.00\nKL: 966.4, Word: 93.23, Topo: 99.08, Assm: 83.27, Steo: 100.00\nKL: 861.0, Word: 92.90, Topo: 98.96, Assm: 82.21, Steo: 100.00\nKL: 947.6, Word: 93.56, Topo: 99.07, Assm: 84.72, Steo: 100.00\nKL: 917.4, Word: 93.03, Topo: 99.19, Assm: 83.42, Steo: 100.00\nKL: 946.7, Word: 92.68, Topo: 99.13, Assm: 83.68, Steo: 100.00\nKL: 953.8, Word: 92.74, Topo: 99.02, Assm: 85.09, Steo: 100.00\nKL: 886.1, Word: 93.53, Topo: 98.97, Assm: 85.11, Steo: 100.00\nKL: 911.8, Word: 92.88, Topo: 98.93, Assm: 85.53, Steo: 100.00\nKL: 942.2, Word: 93.37, Topo: 98.96, Assm: 85.47, Steo: 100.00\nKL: 886.6, Word: 93.46, Topo: 99.14, Assm: 85.42, Steo: 100.00\nKL: 891.2, Word: 93.96, Topo: 99.26, Assm: 86.81, Steo: 100.00\nKL: 966.7, Word: 93.54, Topo: 99.19, Assm: 86.56, Steo: 100.00\nKL: 900.4, Word: 93.26, Topo: 99.31, Assm: 85.78, Steo: 100.00\nKL: 973.1, Word: 94.05, Topo: 99.34, Assm: 86.70, Steo: 100.00\nKL: 1012.7, Word: 92.61, Topo: 99.08, Assm: 86.59, Steo: 100.00\nKL: 949.1, Word: 93.71, Topo: 99.24, Assm: 85.50, Steo: 100.00\nKL: 953.0, Word: 93.59, Topo: 99.00, Assm: 86.44, Steo: 100.00\nKL: 960.0, Word: 93.42, Topo: 99.02, Assm: 86.30, Steo: 100.00\nKL: 899.7, Word: 93.56, Topo: 98.94, Assm: 86.21, Steo: 100.00\nKL: 880.5, Word: 93.53, Topo: 99.11, Assm: 86.54, Steo: 100.00\nKL: 946.3, Word: 93.12, Topo: 98.68, Assm: 86.87, Steo: 100.00\nKL: 867.5, Word: 93.67, Topo: 99.14, Assm: 85.02, Steo: 100.00\nKL: 931.9, Word: 93.62, Topo: 99.20, Assm: 85.94, Steo: 100.00\nKL: 899.9, Word: 93.47, Topo: 99.30, Assm: 86.81, Steo: 100.00\nKL: 965.9, Word: 93.56, Topo: 99.28, Assm: 86.41, Steo: 100.00\nKL: 970.5, Word: 94.33, Topo: 99.23, Assm: 86.80, Steo: 100.00\nKL: 935.9, Word: 94.05, Topo: 99.22, Assm: 87.94, Steo: 100.00\nKL: 1002.6, Word: 93.52, Topo: 99.01, Assm: 85.93, Steo: 100.00\nKL: 974.5, Word: 94.11, Topo: 98.88, Assm: 85.85, Steo: 100.00\nlearning rate: 0.000810\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/pretrain-vae_model.iter-2\n\nKL: 932.1, Word: 95.46, Topo: 99.26, Assm: 86.73, Steo: 100.00\nKL: 923.3, Word: 94.85, Topo: 99.44, Assm: 88.90, Steo: 100.00\nKL: 1003.3, Word: 94.80, Topo: 99.24, Assm: 88.12, Steo: 100.00\nKL: 1002.1, Word: 95.30, Topo: 99.12, Assm: 87.87, Steo: 100.00\nKL: 987.1, Word: 95.37, Topo: 99.13, Assm: 89.36, Steo: 100.00\nKL: 948.6, Word: 95.73, Topo: 99.34, Assm: 89.36, Steo: 100.00\nKL: 944.5, Word: 94.98, Topo: 99.55, Assm: 88.06, Steo: 100.00\nKL: 991.9, Word: 95.18, Topo: 99.27, Assm: 88.69, Steo: 100.00\nKL: 988.3, Word: 95.22, Topo: 99.59, Assm: 87.54, Steo: 100.00\nKL: 1004.8, Word: 95.00, Topo: 99.37, Assm: 89.40, Steo: 100.00\nKL: 936.3, Word: 94.81, Topo: 99.28, Assm: 89.56, Steo: 100.00\nKL: 1034.1, Word: 94.75, Topo: 99.13, Assm: 87.19, Steo: 100.00\nKL: 992.0, Word: 94.72, Topo: 99.22, Assm: 88.08, Steo: 100.00\nKL: 915.4, Word: 94.91, Topo: 99.23, Assm: 89.41, Steo: 100.00\nKL: 1055.5, Word: 94.53, Topo: 99.32, Assm: 89.28, Steo: 100.00\nKL: 995.1, Word: 95.13, Topo: 99.22, Assm: 90.27, Steo: 100.00\nKL: 942.8, Word: 95.28, Topo: 99.32, Assm: 88.99, Steo: 100.00\nKL: 993.1, Word: 95.49, Topo: 99.39, Assm: 90.48, Steo: 100.00\nKL: 1007.2, Word: 95.41, Topo: 99.46, Assm: 88.57, Steo: 100.00\nKL: 1018.5, Word: 95.71, Topo: 99.28, Assm: 87.97, Steo: 100.00\nKL: 945.8, Word: 95.23, Topo: 99.41, Assm: 87.89, Steo: 100.00\nKL: 1056.7, Word: 95.64, Topo: 99.43, Assm: 90.21, Steo: 100.00\nKL: 1001.9, Word: 95.46, Topo: 99.40, Assm: 89.48, Steo: 100.00\nKL: 995.4, Word: 95.49, Topo: 99.35, Assm: 90.36, Steo: 100.00\nKL: 961.1, Word: 95.41, Topo: 99.44, Assm: 89.07, Steo: 100.00\nKL: 991.5, Word: 95.64, Topo: 99.32, Assm: 89.67, Steo: 100.00\nKL: 1080.3, Word: 95.26, Topo: 99.32, Assm: 91.06, Steo: 100.00\nKL: 1022.6, Word: 95.49, Topo: 99.20, Assm: 89.63, Steo: 100.00\nKL: 990.2, Word: 95.37, Topo: 99.33, Assm: 90.58, Steo: 100.00\nKL: 1021.4, Word: 95.39, Topo: 99.42, Assm: 88.90, Steo: 100.00\nKL: 922.0, Word: 95.32, Topo: 99.38, Assm: 88.16, Steo: 100.00\nKL: 1005.4, Word: 95.36, Topo: 99.46, Assm: 88.80, Steo: 100.00\nKL: 990.0, Word: 95.69, Topo: 99.31, Assm: 89.99, Steo: 100.00\nKL: 1001.1, Word: 95.38, Topo: 99.22, Assm: 90.39, Steo: 100.00\nKL: 1001.8, Word: 95.15, Topo: 99.10, Assm: 89.45, Steo: 100.00\nKL: 1017.4, Word: 95.59, Topo: 99.08, Assm: 90.64, Steo: 100.00\nKL: 1029.2, Word: 95.61, Topo: 99.32, Assm: 90.43, Steo: 100.00\nKL: 1005.5, Word: 95.55, Topo: 99.29, Assm: 89.20, Steo: 100.00\nKL: 978.9, Word: 95.18, Topo: 99.41, Assm: 90.64, Steo: 100.00\nKL: 1048.3, Word: 94.71, Topo: 99.38, Assm: 90.75, Steo: 100.00\nKL: 1044.5, Word: 95.63, Topo: 99.41, Assm: 89.85, Steo: 100.00\nKL: 933.3, Word: 95.40, Topo: 99.32, Assm: 90.40, Steo: 100.00\nKL: 1016.3, Word: 95.30, Topo: 99.14, Assm: 89.05, Steo: 100.00\nKL: 1087.3, Word: 95.67, Topo: 99.37, Assm: 89.84, Steo: 100.00\nKL: 974.3, Word: 95.34, Topo: 99.13, Assm: 90.68, Steo: 100.00\nKL: 998.5, Word: 95.13, Topo: 99.34, Assm: 92.69, Steo: 100.00\nKL: 1070.0, Word: 95.88, Topo: 99.43, Assm: 92.38, Steo: 100.00\nKL: 1097.6, Word: 96.03, Topo: 99.46, Assm: 90.29, Steo: 100.00\nKL: 1082.5, Word: 95.99, Topo: 99.31, Assm: 91.19, Steo: 100.00\nKL: 1130.9, Word: 96.16, Topo: 99.47, Assm: 90.62, Steo: 100.00\nKL: 1049.2, Word: 95.80, Topo: 99.42, Assm: 91.12, Steo: 100.00\nKL: 1119.5, Word: 95.19, Topo: 99.48, Assm: 90.97, Steo: 100.00\nKL: 1105.5, Word: 95.96, Topo: 99.50, Assm: 91.31, Steo: 100.00\nKL: 980.1, Word: 94.86, Topo: 99.33, Assm: 90.14, Steo: 100.00\nKL: 970.4, Word: 95.46, Topo: 99.38, Assm: 92.78, Steo: 100.00\nKL: 1014.4, Word: 95.79, Topo: 99.22, Assm: 91.44, Steo: 100.00\nKL: 1036.2, Word: 95.58, Topo: 99.34, Assm: 91.24, Steo: 100.00\nKL: 1051.3, Word: 95.85, Topo: 99.23, Assm: 91.74, Steo: 100.00\nKL: 1039.9, Word: 95.28, Topo: 99.36, Assm: 91.15, Steo: 100.00\nKL: 1056.4, Word: 95.76, Topo: 99.32, Assm: 91.18, Steo: 100.00\nKL: 1021.5, Word: 95.32, Topo: 99.19, Assm: 90.84, Steo: 100.00\nKL: 976.7, Word: 95.45, Topo: 99.47, Assm: 91.64, Steo: 100.00\nKL: 1044.3, Word: 95.87, Topo: 99.26, Assm: 92.34, Steo: 100.00\nKL: 997.5, Word: 95.58, Topo: 99.32, Assm: 91.91, Steo: 100.00\nKL: 992.6, Word: 94.93, Topo: 99.25, Assm: 91.55, Steo: 100.00\nKL: 1022.9, Word: 95.25, Topo: 99.21, Assm: 91.41, Steo: 100.00\nlearning rate: 0.000729\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/pretrain-vae_model.iter-3\n\nKL: 1094.1, Word: 96.71, Topo: 99.53, Assm: 93.07, Steo: 100.00\nKL: 1035.3, Word: 96.21, Topo: 99.59, Assm: 93.52, Steo: 100.00\nKL: 1029.2, Word: 97.08, Topo: 99.56, Assm: 92.31, Steo: 100.00\nKL: 1076.7, Word: 97.13, Topo: 99.54, Assm: 92.92, Steo: 100.00\nKL: 1058.8, Word: 96.77, Topo: 99.65, Assm: 93.93, Steo: 100.00\nKL: 1067.6, Word: 96.86, Topo: 99.64, Assm: 94.70, Steo: 100.00\nKL: 1143.6, Word: 97.45, Topo: 99.63, Assm: 91.99, Steo: 100.00\nKL: 1070.4, Word: 96.82, Topo: 99.52, Assm: 91.86, Steo: 100.00\nKL: 1122.3, Word: 97.23, Topo: 99.59, Assm: 91.96, Steo: 100.00\nKL: 1054.6, Word: 96.54, Topo: 99.47, Assm: 93.01, Steo: 100.00\nKL: 1118.8, Word: 96.78, Topo: 99.32, Assm: 93.34, Steo: 100.00\nKL: 1106.5, Word: 96.60, Topo: 99.50, Assm: 92.80, Steo: 100.00\nKL: 1053.5, Word: 96.45, Topo: 99.52, Assm: 92.65, Steo: 100.00\nKL: 1059.8, Word: 96.36, Topo: 99.49, Assm: 93.18, Steo: 100.00\nKL: 1092.8, Word: 96.27, Topo: 99.49, Assm: 93.10, Steo: 100.00\nKL: 1084.0, Word: 96.86, Topo: 99.60, Assm: 92.95, Steo: 100.00\nKL: 1019.2, Word: 96.69, Topo: 99.47, Assm: 93.03, Steo: 100.00\nKL: 1158.8, Word: 96.10, Topo: 99.58, Assm: 92.51, Steo: 100.00\nKL: 1025.8, Word: 96.70, Topo: 99.61, Assm: 92.81, Steo: 100.00\nKL: 1073.4, Word: 96.56, Topo: 99.43, Assm: 92.52, Steo: 100.00\nKL: 1056.4, Word: 96.58, Topo: 99.57, Assm: 92.54, Steo: 100.00\nKL: 1108.7, Word: 96.55, Topo: 99.54, Assm: 93.46, Steo: 100.00\nKL: 1076.1, Word: 96.55, Topo: 99.24, Assm: 92.91, Steo: 100.00\nKL: 1119.0, Word: 97.01, Topo: 99.41, Assm: 93.50, Steo: 100.00\nKL: 1025.0, Word: 96.74, Topo: 99.42, Assm: 92.34, Steo: 100.00\nKL: 1000.4, Word: 96.82, Topo: 99.63, Assm: 94.22, Steo: 100.00\nKL: 1099.3, Word: 96.38, Topo: 99.38, Assm: 93.32, Steo: 100.00\nKL: 1030.7, Word: 96.19, Topo: 99.47, Assm: 92.71, Steo: 100.00\nKL: 1086.2, Word: 96.52, Topo: 99.56, Assm: 93.91, Steo: 100.00\nKL: 1053.8, Word: 96.91, Topo: 99.55, Assm: 93.62, Steo: 100.00\nKL: 1041.4, Word: 96.49, Topo: 99.40, Assm: 93.55, Steo: 100.00\nKL: 1088.8, Word: 96.79, Topo: 99.45, Assm: 94.03, Steo: 100.00\nKL: 1188.3, Word: 96.77, Topo: 99.59, Assm: 93.44, Steo: 100.00\nKL: 1075.9, Word: 96.62, Topo: 99.64, Assm: 92.56, Steo: 100.00\nKL: 1128.7, Word: 96.64, Topo: 99.55, Assm: 93.62, Steo: 100.00\nKL: 1088.9, Word: 96.91, Topo: 99.27, Assm: 92.85, Steo: 100.00\nKL: 1107.2, Word: 97.04, Topo: 99.37, Assm: 94.00, Steo: 100.00\nKL: 1164.0, Word: 96.40, Topo: 99.50, Assm: 92.88, Steo: 100.00\nKL: 1034.5, Word: 96.73, Topo: 99.44, Assm: 93.87, Steo: 100.00\nKL: 1098.8, Word: 96.93, Topo: 99.48, Assm: 93.10, Steo: 100.00\nKL: 1100.7, Word: 96.03, Topo: 99.48, Assm: 91.83, Steo: 100.00\nKL: 1017.8, Word: 96.46, Topo: 99.44, Assm: 93.00, Steo: 100.00\nKL: 1067.8, Word: 96.40, Topo: 99.47, Assm: 93.70, Steo: 100.00\nKL: 1056.3, Word: 96.79, Topo: 99.58, Assm: 94.73, Steo: 100.00\nKL: 1077.7, Word: 96.52, Topo: 99.33, Assm: 93.81, Steo: 100.00\nKL: 1036.7, Word: 96.85, Topo: 99.54, Assm: 93.49, Steo: 100.00\nKL: 1106.8, Word: 96.67, Topo: 99.55, Assm: 93.63, Steo: 100.00\nKL: 1112.8, Word: 96.21, Topo: 99.53, Assm: 94.21, Steo: 100.00\nKL: 1104.1, Word: 96.95, Topo: 99.60, Assm: 93.82, Steo: 100.00\nKL: 1100.8, Word: 96.97, Topo: 99.41, Assm: 94.73, Steo: 100.00\nKL: 1134.3, Word: 97.16, Topo: 99.61, Assm: 93.96, Steo: 100.00\nKL: 1014.6, Word: 96.45, Topo: 99.48, Assm: 94.55, Steo: 100.00\nKL: 1092.5, Word: 96.45, Topo: 99.51, Assm: 93.66, Steo: 100.00\nKL: 1105.6, Word: 96.24, Topo: 99.45, Assm: 92.63, Steo: 100.00\nKL: 1099.0, Word: 96.82, Topo: 99.34, Assm: 93.76, Steo: 100.00\nKL: 1091.3, Word: 96.28, Topo: 99.46, Assm: 94.56, Steo: 100.00\nKL: 1145.1, Word: 96.45, Topo: 99.38, Assm: 94.72, Steo: 100.00\nKL: 1130.9, Word: 96.37, Topo: 99.42, Assm: 94.24, Steo: 100.00\nKL: 1050.9, Word: 96.28, Topo: 99.29, Assm: 93.59, Steo: 100.00\nKL: 1046.1, Word: 96.59, Topo: 99.35, Assm: 93.62, Steo: 100.00\nKL: 1075.2, Word: 96.44, Topo: 99.36, Assm: 94.36, Steo: 100.00\nKL: 1095.1, Word: 96.45, Topo: 99.65, Assm: 94.72, Steo: 100.00\nKL: 1145.4, Word: 96.85, Topo: 99.54, Assm: 94.90, Steo: 100.00\nKL: 1144.6, Word: 96.02, Topo: 99.51, Assm: 93.05, Steo: 100.00\nKL: 1052.5, Word: 96.20, Topo: 99.51, Assm: 93.29, Steo: 100.00\nKL: 1131.9, Word: 96.13, Topo: 99.52, Assm: 94.09, Steo: 100.00\nlearning rate: 0.000656\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/pretrain-vae_model.iter-4\n\nKL: 1049.4, Word: 97.32, Topo: 99.56, Assm: 95.04, Steo: 100.00\nKL: 1139.4, Word: 97.02, Topo: 99.50, Assm: 94.71, Steo: 100.00\nKL: 1061.9, Word: 97.88, Topo: 99.65, Assm: 94.87, Steo: 100.00\nKL: 1109.8, Word: 98.01, Topo: 99.55, Assm: 96.00, Steo: 100.00\nKL: 1135.7, Word: 97.67, Topo: 99.59, Assm: 95.40, Steo: 100.00\nKL: 1085.2, Word: 97.74, Topo: 99.67, Assm: 95.76, Steo: 100.00\nKL: 1028.4, Word: 97.71, Topo: 99.63, Assm: 94.87, Steo: 100.00\nKL: 1163.7, Word: 97.05, Topo: 99.62, Assm: 95.14, Steo: 100.00\nKL: 1081.1, Word: 97.79, Topo: 99.75, Assm: 95.36, Steo: 100.00\nKL: 1108.4, Word: 97.53, Topo: 99.62, Assm: 95.47, Steo: 100.00\nKL: 1157.1, Word: 97.76, Topo: 99.61, Assm: 95.19, Steo: 100.00\nKL: 1132.7, Word: 97.48, Topo: 99.50, Assm: 94.86, Steo: 100.00\nKL: 1072.7, Word: 97.46, Topo: 99.56, Assm: 95.18, Steo: 100.00\nKL: 1198.1, Word: 97.53, Topo: 99.76, Assm: 95.00, Steo: 100.00\nKL: 1050.0, Word: 97.64, Topo: 99.78, Assm: 95.21, Steo: 100.00\nKL: 1144.2, Word: 97.57, Topo: 99.66, Assm: 95.29, Steo: 100.00\nKL: 1127.3, Word: 97.43, Topo: 99.71, Assm: 94.81, Steo: 100.00\nKL: 1126.3, Word: 97.34, Topo: 99.60, Assm: 95.48, Steo: 100.00\nKL: 1148.2, Word: 97.60, Topo: 99.71, Assm: 95.48, Steo: 100.00\nKL: 1158.1, Word: 97.72, Topo: 99.74, Assm: 94.99, Steo: 100.00\nKL: 1161.1, Word: 97.80, Topo: 99.62, Assm: 94.81, Steo: 100.00\nKL: 1116.5, Word: 97.46, Topo: 99.71, Assm: 94.34, Steo: 100.00\nKL: 1125.5, Word: 97.74, Topo: 99.67, Assm: 95.93, Steo: 100.00\nKL: 1203.5, Word: 97.29, Topo: 99.73, Assm: 95.14, Steo: 100.00\nKL: 1136.8, Word: 97.81, Topo: 99.71, Assm: 95.04, Steo: 100.00\nKL: 1144.7, Word: 97.68, Topo: 99.59, Assm: 94.66, Steo: 100.00\nKL: 1158.9, Word: 97.43, Topo: 99.53, Assm: 95.61, Steo: 100.00\nKL: 1200.2, Word: 97.04, Topo: 99.60, Assm: 93.88, Steo: 100.00\nKL: 1180.9, Word: 97.55, Topo: 99.57, Assm: 95.69, Steo: 100.00\nKL: 1107.0, Word: 97.62, Topo: 99.68, Assm: 95.98, Steo: 100.00\nKL: 1154.2, Word: 97.50, Topo: 99.69, Assm: 95.64, Steo: 100.00\nKL: 1133.2, Word: 97.13, Topo: 99.52, Assm: 95.71, Steo: 100.00\nKL: 1154.9, Word: 97.20, Topo: 99.58, Assm: 95.57, Steo: 100.00\nKL: 1170.1, Word: 96.96, Topo: 99.59, Assm: 95.49, Steo: 100.00\nKL: 1113.3, Word: 97.08, Topo: 99.61, Assm: 96.77, Steo: 100.00\nKL: 1179.7, Word: 97.37, Topo: 99.68, Assm: 95.11, Steo: 100.00\nKL: 1150.0, Word: 97.35, Topo: 99.54, Assm: 95.71, Steo: 100.00\nKL: 1167.1, Word: 97.30, Topo: 99.60, Assm: 95.79, Steo: 100.00\nKL: 1188.1, Word: 97.40, Topo: 99.71, Assm: 95.60, Steo: 100.00\nKL: 1154.8, Word: 97.06, Topo: 99.57, Assm: 95.17, Steo: 100.00\nKL: 1211.5, Word: 97.49, Topo: 99.71, Assm: 95.81, Steo: 100.00\nKL: 1165.8, Word: 97.49, Topo: 99.46, Assm: 95.84, Steo: 100.00\nKL: 1098.7, Word: 97.06, Topo: 99.59, Assm: 96.02, Steo: 100.00\nKL: 1187.0, Word: 97.35, Topo: 99.41, Assm: 95.71, Steo: 100.00\nKL: 1146.5, Word: 97.25, Topo: 99.46, Assm: 95.39, Steo: 100.00\nKL: 1121.9, Word: 97.04, Topo: 99.63, Assm: 95.07, Steo: 100.00\nKL: 1196.4, Word: 97.36, Topo: 99.62, Assm: 95.19, Steo: 100.00\nKL: 1135.2, Word: 97.36, Topo: 99.71, Assm: 96.18, Steo: 100.00\nKL: 1170.2, Word: 97.26, Topo: 99.73, Assm: 95.16, Steo: 100.00\nKL: 1186.0, Word: 97.34, Topo: 99.60, Assm: 94.75, Steo: 100.00\nKL: 1183.5, Word: 97.31, Topo: 99.43, Assm: 95.51, Steo: 100.00\nKL: 1153.8, Word: 96.97, Topo: 99.62, Assm: 95.60, Steo: 100.00\nKL: 1089.5, Word: 96.88, Topo: 99.47, Assm: 96.14, Steo: 100.00\nKL: 1130.9, Word: 97.16, Topo: 99.64, Assm: 95.73, Steo: 100.00\nKL: 1187.0, Word: 97.21, Topo: 99.65, Assm: 95.16, Steo: 100.00\nKL: 1179.9, Word: 97.39, Topo: 99.63, Assm: 95.36, Steo: 100.00\nKL: 1174.5, Word: 97.26, Topo: 99.59, Assm: 95.91, Steo: 100.00\nKL: 1126.3, Word: 97.35, Topo: 99.55, Assm: 95.47, Steo: 100.00\nKL: 1204.6, Word: 97.04, Topo: 99.67, Assm: 94.33, Steo: 100.00\nKL: 1168.2, Word: 96.86, Topo: 99.57, Assm: 95.64, Steo: 100.00\nKL: 1114.6, Word: 97.14, Topo: 99.62, Assm: 94.54, Steo: 100.00\nKL: 1141.2, Word: 97.45, Topo: 99.59, Assm: 95.71, Steo: 100.00\nKL: 1151.3, Word: 97.50, Topo: 99.71, Assm: 95.40, Steo: 100.00\nKL: 1158.5, Word: 97.08, Topo: 99.68, Assm: 95.78, Steo: 100.00\nKL: 1201.9, Word: 97.56, Topo: 99.63, Assm: 95.59, Steo: 100.00\nKL: 1116.0, Word: 97.72, Topo: 99.74, Assm: 95.13, Steo: 100.00\nlearning rate: 0.000590\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/pretrain-vae_model.iter-5\n\nKL: 1141.4, Word: 98.25, Topo: 99.56, Assm: 96.95, Steo: 100.00\nKL: 1137.8, Word: 98.23, Topo: 99.63, Assm: 97.46, Steo: 100.00\nKL: 1147.3, Word: 98.55, Topo: 99.72, Assm: 96.46, Steo: 100.00\nKL: 1254.8, Word: 97.99, Topo: 99.76, Assm: 96.54, Steo: 100.00\nKL: 1200.0, Word: 98.26, Topo: 99.70, Assm: 96.31, Steo: 100.00\nKL: 1268.3, Word: 98.29, Topo: 99.77, Assm: 96.62, Steo: 100.00\nKL: 1233.5, Word: 98.45, Topo: 99.56, Assm: 95.89, Steo: 100.00\nKL: 1163.7, Word: 98.37, Topo: 99.77, Assm: 97.45, Steo: 100.00\nKL: 1121.3, Word: 98.29, Topo: 99.71, Assm: 95.73, Steo: 100.00\nKL: 1213.0, Word: 98.23, Topo: 99.74, Assm: 96.45, Steo: 100.00\nKL: 1170.6, Word: 98.43, Topo: 99.81, Assm: 97.26, Steo: 100.00\nKL: 1146.0, Word: 98.02, Topo: 99.82, Assm: 96.61, Steo: 100.00\nKL: 1164.1, Word: 98.34, Topo: 99.78, Assm: 97.47, Steo: 100.00\nKL: 1217.4, Word: 97.65, Topo: 99.76, Assm: 97.03, Steo: 100.00\nKL: 1214.3, Word: 98.12, Topo: 99.75, Assm: 96.21, Steo: 100.00\nKL: 1242.0, Word: 98.30, Topo: 99.67, Assm: 96.70, Steo: 100.00\nKL: 1233.9, Word: 98.08, Topo: 99.75, Assm: 96.37, Steo: 100.00\nKL: 1170.4, Word: 97.61, Topo: 99.63, Assm: 95.65, Steo: 100.00\nKL: 1196.3, Word: 97.89, Topo: 99.59, Assm: 95.63, Steo: 100.00\nKL: 1203.2, Word: 97.70, Topo: 99.69, Assm: 96.32, Steo: 100.00\nKL: 1252.5, Word: 97.74, Topo: 99.63, Assm: 95.80, Steo: 100.00\nKL: 1164.0, Word: 98.10, Topo: 99.70, Assm: 97.10, Steo: 100.00\nKL: 1163.3, Word: 98.37, Topo: 99.82, Assm: 97.10, Steo: 100.00\nKL: 1202.0, Word: 97.85, Topo: 99.78, Assm: 96.47, Steo: 100.00\nKL: 1152.4, Word: 97.85, Topo: 99.82, Assm: 96.90, Steo: 100.00\nKL: 1233.3, Word: 98.46, Topo: 99.77, Assm: 97.01, Steo: 100.00\nKL: 1195.1, Word: 98.03, Topo: 99.76, Assm: 96.62, Steo: 100.00\nKL: 1171.0, Word: 97.94, Topo: 99.70, Assm: 95.99, Steo: 100.00\nKL: 1215.2, Word: 97.90, Topo: 99.67, Assm: 96.47, Steo: 100.00\nKL: 1163.3, Word: 98.17, Topo: 99.68, Assm: 96.19, Steo: 100.00\nKL: 1255.6, Word: 98.11, Topo: 99.56, Assm: 96.49, Steo: 100.00\nKL: 1219.5, Word: 98.30, Topo: 99.73, Assm: 96.37, Steo: 100.00\nKL: 1165.4, Word: 97.97, Topo: 99.66, Assm: 95.99, Steo: 100.00\nKL: 1182.9, Word: 97.60, Topo: 99.45, Assm: 95.89, Steo: 100.00\nKL: 1161.4, Word: 97.54, Topo: 99.52, Assm: 96.56, Steo: 100.00\nKL: 1079.5, Word: 97.63, Topo: 99.56, Assm: 96.58, Steo: 100.00\nKL: 1187.8, Word: 97.78, Topo: 99.61, Assm: 96.02, Steo: 100.00\nKL: 1231.1, Word: 97.98, Topo: 99.68, Assm: 96.77, Steo: 100.00\nKL: 1169.7, Word: 98.31, Topo: 99.75, Assm: 96.89, Steo: 100.00\nKL: 1272.7, Word: 97.92, Topo: 99.80, Assm: 95.90, Steo: 100.00\n\n*** WARNING: skipped 81224 bytes of output ***\n\nKL: 1684.5, Word: 99.68, Topo: 99.97, Assm: 99.74, Steo: 100.00\nKL: 1654.3, Word: 99.76, Topo: 100.00, Assm: 99.75, Steo: 100.00\nKL: 1626.2, Word: 99.82, Topo: 99.99, Assm: 99.79, Steo: 100.00\nKL: 1704.7, Word: 99.81, Topo: 99.98, Assm: 99.95, Steo: 100.00\nKL: 1637.1, Word: 99.69, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1799.3, Word: 99.74, Topo: 99.99, Assm: 99.81, Steo: 100.00\nKL: 1577.4, Word: 99.77, Topo: 100.00, Assm: 99.58, Steo: 100.00\nKL: 1690.2, Word: 99.65, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1804.8, Word: 99.78, Topo: 99.98, Assm: 99.76, Steo: 100.00\nKL: 1660.5, Word: 99.77, Topo: 100.00, Assm: 99.75, Steo: 100.00\nKL: 1663.1, Word: 99.76, Topo: 99.98, Assm: 99.75, Steo: 100.00\nKL: 1692.8, Word: 99.78, Topo: 99.99, Assm: 99.90, Steo: 100.00\nKL: 1647.2, Word: 99.67, Topo: 100.00, Assm: 99.60, Steo: 100.00\nKL: 1690.7, Word: 99.74, Topo: 99.99, Assm: 99.51, Steo: 100.00\nKL: 1809.7, Word: 99.78, Topo: 100.00, Assm: 99.68, Steo: 100.00\nKL: 1639.2, Word: 99.71, Topo: 99.99, Assm: 99.39, Steo: 100.00\nKL: 1675.7, Word: 99.77, Topo: 100.00, Assm: 99.74, Steo: 100.00\nKL: 1683.4, Word: 99.81, Topo: 99.99, Assm: 99.31, Steo: 100.00\nKL: 1698.3, Word: 99.77, Topo: 99.99, Assm: 99.67, Steo: 100.00\nKL: 1714.3, Word: 99.78, Topo: 99.99, Assm: 99.75, Steo: 100.00\nKL: 1720.5, Word: 99.79, Topo: 99.99, Assm: 99.71, Steo: 100.00\nKL: 1785.5, Word: 99.75, Topo: 100.00, Assm: 99.61, Steo: 100.00\nKL: 1681.4, Word: 99.77, Topo: 99.98, Assm: 99.80, Steo: 100.00\nKL: 1681.4, Word: 99.81, Topo: 99.97, Assm: 99.65, Steo: 100.00\nKL: 1657.0, Word: 99.66, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1663.7, Word: 99.73, Topo: 99.99, Assm: 99.63, Steo: 100.00\nKL: 1766.4, Word: 99.86, Topo: 99.97, Assm: 99.68, Steo: 100.00\nKL: 1602.1, Word: 99.71, Topo: 99.97, Assm: 99.79, Steo: 100.00\nKL: 1867.5, Word: 99.75, Topo: 99.99, Assm: 99.76, Steo: 100.00\nKL: 1652.0, Word: 99.62, Topo: 100.00, Assm: 99.49, Steo: 100.00\nKL: 1702.3, Word: 99.83, Topo: 99.99, Assm: 99.57, Steo: 100.00\nKL: 1726.8, Word: 99.68, Topo: 99.99, Assm: 99.73, Steo: 100.00\nKL: 1713.3, Word: 99.69, Topo: 99.96, Assm: 99.61, Steo: 100.00\nKL: 1669.2, Word: 99.70, Topo: 99.99, Assm: 99.84, Steo: 100.00\nKL: 1674.1, Word: 99.83, Topo: 99.97, Assm: 99.80, Steo: 100.00\nKL: 1714.5, Word: 99.72, Topo: 100.00, Assm: 99.48, Steo: 100.00\nKL: 1705.6, Word: 99.72, Topo: 99.99, Assm: 99.70, Steo: 100.00\nKL: 1681.1, Word: 99.78, Topo: 99.98, Assm: 99.79, Steo: 100.00\nKL: 1664.2, Word: 99.79, Topo: 99.99, Assm: 99.59, Steo: 100.00\nKL: 1642.8, Word: 99.83, Topo: 99.97, Assm: 99.65, Steo: 100.00\nKL: 1706.2, Word: 99.65, Topo: 100.00, Assm: 99.49, Steo: 100.00\nKL: 1681.0, Word: 99.74, Topo: 100.00, Assm: 99.95, Steo: 100.00\nKL: 1847.2, Word: 99.76, Topo: 100.00, Assm: 99.50, Steo: 100.00\nKL: 1644.3, Word: 99.71, Topo: 99.98, Assm: 99.62, Steo: 100.00\nKL: 1657.7, Word: 99.82, Topo: 99.99, Assm: 99.79, Steo: 100.00\nKL: 1756.7, Word: 99.77, Topo: 99.96, Assm: 99.29, Steo: 100.00\nKL: 1607.5, Word: 99.79, Topo: 99.97, Assm: 99.57, Steo: 100.00\nlearning rate: 0.000072\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/pretrain-vae_model.iter-25\n\nKL: 1700.7, Word: 99.90, Topo: 99.99, Assm: 99.62, Steo: 100.00\nKL: 1731.3, Word: 99.88, Topo: 99.98, Assm: 99.45, Steo: 100.00\nKL: 1669.6, Word: 99.83, Topo: 99.96, Assm: 99.72, Steo: 100.00\nKL: 1721.3, Word: 99.79, Topo: 99.99, Assm: 99.71, Steo: 100.00\nKL: 1692.2, Word: 99.81, Topo: 99.99, Assm: 99.32, Steo: 100.00\nKL: 1678.3, Word: 99.81, Topo: 99.99, Assm: 99.74, Steo: 100.00\nKL: 1712.6, Word: 99.81, Topo: 99.97, Assm: 99.80, Steo: 100.00\nKL: 1767.4, Word: 99.74, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1713.7, Word: 99.72, Topo: 99.99, Assm: 99.75, Steo: 100.00\nKL: 1674.8, Word: 99.81, Topo: 100.00, Assm: 99.51, Steo: 100.00\nKL: 1708.4, Word: 99.82, Topo: 99.99, Assm: 99.84, Steo: 100.00\nKL: 1682.8, Word: 99.77, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1698.8, Word: 99.81, Topo: 100.00, Assm: 99.46, Steo: 100.00\nKL: 1708.7, Word: 99.80, Topo: 100.00, Assm: 99.70, Steo: 100.00\nKL: 1754.6, Word: 99.78, Topo: 100.00, Assm: 99.95, Steo: 100.00\nKL: 1750.9, Word: 99.83, Topo: 99.98, Assm: 99.74, Steo: 100.00\nKL: 1669.7, Word: 99.76, Topo: 99.98, Assm: 99.74, Steo: 100.00\nKL: 1832.7, Word: 99.70, Topo: 100.00, Assm: 99.90, Steo: 100.00\nKL: 1696.7, Word: 99.88, Topo: 99.99, Assm: 99.90, Steo: 100.00\nKL: 1643.1, Word: 99.81, Topo: 100.00, Assm: 99.63, Steo: 100.00\nKL: 1775.6, Word: 99.60, Topo: 99.99, Assm: 99.79, Steo: 100.00\nKL: 1630.5, Word: 99.73, Topo: 99.98, Assm: 99.65, Steo: 100.00\nKL: 1716.3, Word: 99.79, Topo: 99.98, Assm: 99.81, Steo: 100.00\nKL: 1801.1, Word: 99.80, Topo: 100.00, Assm: 99.28, Steo: 100.00\nKL: 1687.6, Word: 99.74, Topo: 100.00, Assm: 99.44, Steo: 100.00\nKL: 1665.1, Word: 99.74, Topo: 99.99, Assm: 99.72, Steo: 100.00\nKL: 1764.1, Word: 99.72, Topo: 99.98, Assm: 99.71, Steo: 100.00\nKL: 1793.3, Word: 99.76, Topo: 99.99, Assm: 99.74, Steo: 100.00\nKL: 1746.7, Word: 99.79, Topo: 99.96, Assm: 99.51, Steo: 100.00\nKL: 1685.1, Word: 99.76, Topo: 100.00, Assm: 99.74, Steo: 100.00\nKL: 1729.0, Word: 99.79, Topo: 99.96, Assm: 99.90, Steo: 100.00\nKL: 1675.9, Word: 99.72, Topo: 100.00, Assm: 99.81, Steo: 100.00\nKL: 1683.7, Word: 99.73, Topo: 99.99, Assm: 99.69, Steo: 100.00\nKL: 1648.9, Word: 99.66, Topo: 99.98, Assm: 99.67, Steo: 100.00\nKL: 1731.5, Word: 99.84, Topo: 99.99, Assm: 99.69, Steo: 100.00\nKL: 1710.0, Word: 99.77, Topo: 99.98, Assm: 99.55, Steo: 100.00\nKL: 1652.9, Word: 99.81, Topo: 100.00, Assm: 99.69, Steo: 100.00\nKL: 1737.0, Word: 99.76, Topo: 100.00, Assm: 99.72, Steo: 100.00\nKL: 1697.7, Word: 99.63, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1792.9, Word: 99.83, Topo: 99.98, Assm: 99.70, Steo: 100.00\nKL: 1648.2, Word: 99.67, Topo: 99.97, Assm: 99.61, Steo: 100.00\nKL: 1647.4, Word: 99.63, Topo: 100.00, Assm: 99.49, Steo: 100.00\nKL: 1684.8, Word: 99.72, Topo: 99.99, Assm: 99.86, Steo: 100.00\nKL: 1744.0, Word: 99.67, Topo: 99.97, Assm: 99.85, Steo: 100.00\nKL: 1627.2, Word: 99.73, Topo: 100.00, Assm: 99.74, Steo: 100.00\nKL: 1659.0, Word: 99.83, Topo: 99.97, Assm: 99.65, Steo: 100.00\nKL: 1709.8, Word: 99.67, Topo: 99.98, Assm: 99.61, Steo: 100.00\nKL: 1697.5, Word: 99.84, Topo: 99.98, Assm: 99.54, Steo: 100.00\nKL: 1737.0, Word: 99.74, Topo: 100.00, Assm: 99.48, Steo: 100.00\nKL: 1594.4, Word: 99.80, Topo: 100.00, Assm: 99.50, Steo: 100.00\nKL: 1724.7, Word: 99.73, Topo: 100.00, Assm: 99.95, Steo: 100.00\nKL: 1706.8, Word: 99.79, Topo: 100.00, Assm: 99.76, Steo: 100.00\nKL: 1783.3, Word: 99.72, Topo: 100.00, Assm: 99.70, Steo: 100.00\nKL: 1689.5, Word: 99.68, Topo: 99.99, Assm: 99.78, Steo: 100.00\nKL: 1807.3, Word: 99.73, Topo: 99.99, Assm: 99.64, Steo: 100.00\nKL: 1672.3, Word: 99.85, Topo: 100.00, Assm: 99.95, Steo: 100.00\nKL: 1850.4, Word: 99.72, Topo: 99.98, Assm: 99.58, Steo: 100.00\nKL: 1707.2, Word: 99.73, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1761.6, Word: 99.74, Topo: 99.99, Assm: 99.55, Steo: 100.00\nKL: 1643.1, Word: 99.65, Topo: 99.97, Assm: 99.59, Steo: 100.00\nKL: 1705.0, Word: 99.74, Topo: 99.99, Assm: 99.75, Steo: 100.00\nKL: 1662.8, Word: 99.73, Topo: 100.00, Assm: 99.40, Steo: 100.00\nKL: 1779.5, Word: 99.73, Topo: 100.00, Assm: 99.73, Steo: 100.00\nKL: 1667.0, Word: 99.75, Topo: 99.99, Assm: 99.84, Steo: 100.00\nKL: 1684.3, Word: 99.81, Topo: 100.00, Assm: 99.66, Steo: 100.00\nKL: 1660.8, Word: 99.79, Topo: 100.00, Assm: 99.75, Steo: 100.00\nlearning rate: 0.000065\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/pretrain-vae_model.iter-26\n\nKL: 1720.2, Word: 99.72, Topo: 99.99, Assm: 99.84, Steo: 100.00\nKL: 1678.1, Word: 99.90, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1730.5, Word: 99.72, Topo: 99.99, Assm: 99.75, Steo: 100.00\nKL: 1585.0, Word: 99.83, Topo: 99.99, Assm: 99.90, Steo: 100.00\nKL: 1733.1, Word: 99.84, Topo: 100.00, Assm: 99.59, Steo: 100.00\nKL: 1693.3, Word: 99.86, Topo: 99.99, Assm: 99.72, Steo: 100.00\nKL: 1763.7, Word: 99.89, Topo: 99.99, Assm: 99.70, Steo: 100.00\nKL: 1665.4, Word: 99.83, Topo: 99.99, Assm: 99.69, Steo: 100.00\nKL: 1591.8, Word: 99.78, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1685.4, Word: 99.77, Topo: 99.98, Assm: 99.86, Steo: 100.00\nKL: 1671.1, Word: 99.73, Topo: 99.99, Assm: 99.41, Steo: 100.00\nKL: 1714.0, Word: 99.78, Topo: 99.99, Assm: 99.90, Steo: 100.00\nKL: 1669.3, Word: 99.74, Topo: 99.98, Assm: 99.54, Steo: 100.00\nKL: 1820.6, Word: 99.71, Topo: 99.99, Assm: 99.74, Steo: 100.00\nKL: 1790.7, Word: 99.81, Topo: 99.99, Assm: 99.64, Steo: 100.00\nKL: 1740.6, Word: 99.81, Topo: 99.98, Assm: 99.52, Steo: 100.00\nKL: 1697.9, Word: 99.72, Topo: 100.00, Assm: 99.75, Steo: 100.00\nKL: 1597.6, Word: 99.83, Topo: 99.98, Assm: 99.53, Steo: 100.00\nKL: 1721.3, Word: 99.76, Topo: 100.00, Assm: 99.32, Steo: 100.00\nKL: 1878.1, Word: 99.73, Topo: 99.99, Assm: 99.53, Steo: 100.00\nKL: 1694.8, Word: 99.79, Topo: 100.00, Assm: 99.56, Steo: 100.00\nKL: 1725.1, Word: 99.75, Topo: 99.99, Assm: 99.50, Steo: 100.00\nKL: 1696.2, Word: 99.72, Topo: 100.00, Assm: 99.90, Steo: 100.00\nKL: 1744.3, Word: 99.78, Topo: 100.00, Assm: 99.84, Steo: 100.00\nKL: 1673.5, Word: 99.65, Topo: 99.98, Assm: 99.85, Steo: 100.00\nKL: 1573.4, Word: 99.75, Topo: 99.99, Assm: 99.24, Steo: 100.00\nKL: 1704.7, Word: 99.79, Topo: 99.99, Assm: 99.75, Steo: 100.00\nKL: 1660.6, Word: 99.89, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1620.9, Word: 99.88, Topo: 100.00, Assm: 99.60, Steo: 100.00\nKL: 1753.0, Word: 99.88, Topo: 100.00, Assm: 99.81, Steo: 100.00\nKL: 1716.2, Word: 99.74, Topo: 99.99, Assm: 99.70, Steo: 100.00\nKL: 1719.2, Word: 99.81, Topo: 99.99, Assm: 99.63, Steo: 100.00\nKL: 1631.9, Word: 99.88, Topo: 100.00, Assm: 99.57, Steo: 100.00\nKL: 1761.5, Word: 99.72, Topo: 99.98, Assm: 99.64, Steo: 100.00\nKL: 1645.5, Word: 99.85, Topo: 99.99, Assm: 99.60, Steo: 100.00\nKL: 1696.4, Word: 99.83, Topo: 99.99, Assm: 99.95, Steo: 100.00\nKL: 1612.9, Word: 99.69, Topo: 100.00, Assm: 99.59, Steo: 100.00\nKL: 1708.9, Word: 99.76, Topo: 99.99, Assm: 99.77, Steo: 100.00\nKL: 1818.8, Word: 99.76, Topo: 100.00, Assm: 99.81, Steo: 100.00\nKL: 1681.7, Word: 99.80, Topo: 99.99, Assm: 100.00, Steo: 100.00\nKL: 1707.2, Word: 99.73, Topo: 99.99, Assm: 99.76, Steo: 100.00\nKL: 1745.7, Word: 99.83, Topo: 99.99, Assm: 99.71, Steo: 100.00\nKL: 1704.4, Word: 99.75, Topo: 99.99, Assm: 99.89, Steo: 100.00\nKL: 1783.5, Word: 99.74, Topo: 100.00, Assm: 99.68, Steo: 100.00\nKL: 1758.7, Word: 99.67, Topo: 100.00, Assm: 99.59, Steo: 100.00\nKL: 1658.6, Word: 99.66, Topo: 99.99, Assm: 99.70, Steo: 100.00\nKL: 1785.8, Word: 99.79, Topo: 100.00, Assm: 99.81, Steo: 100.00\nKL: 1666.4, Word: 99.74, Topo: 99.98, Assm: 99.43, Steo: 100.00\nKL: 1730.9, Word: 99.79, Topo: 99.98, Assm: 99.57, Steo: 100.00\nKL: 1700.4, Word: 99.68, Topo: 100.00, Assm: 99.67, Steo: 100.00\nKL: 1633.1, Word: 99.81, Topo: 99.97, Assm: 99.79, Steo: 100.00\nKL: 1690.7, Word: 99.71, Topo: 99.98, Assm: 99.54, Steo: 100.00\nKL: 1707.4, Word: 99.71, Topo: 99.99, Assm: 99.68, Steo: 100.00\nKL: 1633.0, Word: 99.60, Topo: 99.99, Assm: 99.50, Steo: 100.00\nKL: 1711.7, Word: 99.75, Topo: 100.00, Assm: 99.69, Steo: 100.00\nKL: 1738.9, Word: 99.70, Topo: 99.98, Assm: 99.75, Steo: 100.00\nKL: 1635.4, Word: 99.81, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1637.4, Word: 99.75, Topo: 99.99, Assm: 99.45, Steo: 100.00\nKL: 1726.9, Word: 99.68, Topo: 99.95, Assm: 99.77, Steo: 100.00\nKL: 1715.1, Word: 99.76, Topo: 99.99, Assm: 99.48, Steo: 100.00\nKL: 1699.9, Word: 99.74, Topo: 100.00, Assm: 99.65, Steo: 100.00\nKL: 1774.4, Word: 99.83, Topo: 99.99, Assm: 99.89, Steo: 100.00\nKL: 1677.9, Word: 99.79, Topo: 99.98, Assm: 99.85, Steo: 100.00\nKL: 1760.2, Word: 99.69, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1753.3, Word: 99.69, Topo: 99.98, Assm: 99.69, Steo: 100.00\nKL: 1669.7, Word: 99.84, Topo: 100.00, Assm: 99.85, Steo: 100.00\nlearning rate: 0.000058\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/pretrain-vae_model.iter-27\n\nKL: 1784.5, Word: 99.76, Topo: 100.00, Assm: 99.52, Steo: 100.00\nKL: 1756.9, Word: 99.77, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1778.1, Word: 99.81, Topo: 99.99, Assm: 99.59, Steo: 100.00\nKL: 1746.5, Word: 99.79, Topo: 99.98, Assm: 99.69, Steo: 100.00\nKL: 1592.2, Word: 99.81, Topo: 100.00, Assm: 99.85, Steo: 100.00\nKL: 1662.2, Word: 99.80, Topo: 100.00, Assm: 99.46, Steo: 100.00\nKL: 1667.7, Word: 99.77, Topo: 100.00, Assm: 99.75, Steo: 100.00\nKL: 1791.3, Word: 99.75, Topo: 99.99, Assm: 99.74, Steo: 100.00\nKL: 1719.9, Word: 99.78, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1629.5, Word: 99.79, Topo: 99.98, Assm: 99.89, Steo: 100.00\nKL: 1814.1, Word: 99.79, Topo: 99.98, Assm: 99.50, Steo: 100.00\nKL: 1801.0, Word: 99.78, Topo: 99.99, Assm: 99.81, Steo: 100.00\nKL: 1698.4, Word: 99.83, Topo: 100.00, Assm: 99.59, Steo: 100.00\nKL: 1632.9, Word: 99.81, Topo: 100.00, Assm: 99.59, Steo: 100.00\nKL: 1712.2, Word: 99.79, Topo: 99.98, Assm: 99.90, Steo: 100.00\nKL: 1750.7, Word: 99.88, Topo: 99.99, Assm: 99.95, Steo: 100.00\nKL: 1710.3, Word: 99.85, Topo: 99.98, Assm: 99.61, Steo: 100.00\nKL: 1842.7, Word: 99.75, Topo: 99.99, Assm: 99.64, Steo: 100.00\nKL: 1740.0, Word: 99.71, Topo: 99.99, Assm: 99.69, Steo: 100.00\nKL: 1772.9, Word: 99.88, Topo: 100.00, Assm: 99.61, Steo: 100.00\nKL: 1756.5, Word: 99.68, Topo: 99.98, Assm: 99.74, Steo: 100.00\nKL: 1732.1, Word: 99.84, Topo: 100.00, Assm: 99.90, Steo: 100.00\nKL: 1728.7, Word: 99.76, Topo: 100.00, Assm: 99.62, Steo: 100.00\nKL: 1693.6, Word: 99.74, Topo: 99.98, Assm: 99.80, Steo: 100.00\nKL: 1693.4, Word: 99.66, Topo: 100.00, Assm: 99.75, Steo: 100.00\nKL: 1808.6, Word: 99.76, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1718.8, Word: 99.72, Topo: 99.99, Assm: 99.69, Steo: 100.00\nKL: 1721.6, Word: 99.83, Topo: 99.98, Assm: 99.58, Steo: 100.00\nKL: 1672.3, Word: 99.76, Topo: 99.98, Assm: 99.64, Steo: 100.00\nKL: 1692.1, Word: 99.69, Topo: 99.99, Assm: 99.59, Steo: 100.00\nKL: 1727.8, Word: 99.78, Topo: 99.99, Assm: 99.69, Steo: 100.00\nKL: 1800.4, Word: 99.86, Topo: 100.00, Assm: 99.66, Steo: 100.00\nKL: 1701.6, Word: 99.84, Topo: 100.00, Assm: 99.69, Steo: 100.00\nKL: 1769.9, Word: 99.87, Topo: 99.98, Assm: 99.80, Steo: 100.00\nKL: 1704.0, Word: 99.76, Topo: 99.99, Assm: 99.85, Steo: 100.00\nKL: 1677.5, Word: 99.81, Topo: 99.99, Assm: 99.51, Steo: 100.00\nKL: 1787.9, Word: 99.77, Topo: 99.99, Assm: 99.80, Steo: 100.00\nKL: 1746.7, Word: 99.76, Topo: 100.00, Assm: 99.84, Steo: 100.00\nKL: 1709.3, Word: 99.68, Topo: 99.99, Assm: 99.58, Steo: 100.00\nKL: 1765.2, Word: 99.82, Topo: 99.99, Assm: 99.71, Steo: 100.00\nKL: 1729.4, Word: 99.78, Topo: 99.99, Assm: 99.63, Steo: 100.00\nKL: 1786.7, Word: 99.83, Topo: 99.98, Assm: 99.73, Steo: 100.00\nKL: 1677.9, Word: 99.79, Topo: 99.99, Assm: 99.80, Steo: 100.00\nKL: 1742.9, Word: 99.73, Topo: 99.98, Assm: 99.64, Steo: 100.00\nKL: 1719.1, Word: 99.93, Topo: 99.99, Assm: 99.89, Steo: 100.00\nKL: 1823.5, Word: 99.72, Topo: 99.99, Assm: 99.75, Steo: 100.00\nKL: 1599.9, Word: 99.70, Topo: 99.98, Assm: 99.71, Steo: 100.00\nKL: 1820.9, Word: 99.85, Topo: 99.99, Assm: 99.54, Steo: 100.00\nKL: 1772.0, Word: 99.72, Topo: 100.00, Assm: 99.73, Steo: 100.00\nKL: 1759.9, Word: 99.88, Topo: 99.95, Assm: 99.71, Steo: 100.00\nKL: 1750.7, Word: 99.74, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1770.0, Word: 99.73, Topo: 100.00, Assm: 99.60, Steo: 100.00\nKL: 1707.4, Word: 99.71, Topo: 99.98, Assm: 99.85, Steo: 100.00\nKL: 1725.4, Word: 99.84, Topo: 99.98, Assm: 99.81, Steo: 100.00\nKL: 1732.6, Word: 99.66, Topo: 100.00, Assm: 99.73, Steo: 100.00\nKL: 1724.3, Word: 99.65, Topo: 100.00, Assm: 99.89, Steo: 100.00\nKL: 1728.7, Word: 99.82, Topo: 100.00, Assm: 99.85, Steo: 100.00\nKL: 1629.5, Word: 99.71, Topo: 100.00, Assm: 99.24, Steo: 100.00\nKL: 1645.0, Word: 99.79, Topo: 99.98, Assm: 99.85, Steo: 100.00\nKL: 1749.5, Word: 99.69, Topo: 99.99, Assm: 99.55, Steo: 100.00\nKL: 1756.2, Word: 99.78, Topo: 99.99, Assm: 99.90, Steo: 100.00\nKL: 1741.7, Word: 99.79, Topo: 99.99, Assm: 99.57, Steo: 100.00\nKL: 1621.8, Word: 99.58, Topo: 100.00, Assm: 99.51, Steo: 100.00\nKL: 1688.0, Word: 99.83, Topo: 99.98, Assm: 99.50, Steo: 100.00\nKL: 1710.4, Word: 99.79, Topo: 100.00, Assm: 99.43, Steo: 100.00\nKL: 1714.1, Word: 99.75, Topo: 100.00, Assm: 99.39, Steo: 100.00\nlearning rate: 0.000052\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/pretrain-vae_model.iter-28\n\nKL: 1688.1, Word: 99.81, Topo: 99.98, Assm: 99.80, Steo: 100.00\nKL: 1776.9, Word: 99.76, Topo: 100.00, Assm: 99.70, Steo: 100.00\nKL: 1725.7, Word: 99.84, Topo: 100.00, Assm: 99.54, Steo: 100.00\nKL: 1744.8, Word: 99.79, Topo: 100.00, Assm: 99.65, Steo: 100.00\nKL: 1635.2, Word: 99.83, Topo: 100.00, Assm: 99.85, Steo: 100.00\nKL: 1779.7, Word: 99.74, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1686.9, Word: 99.90, Topo: 99.99, Assm: 99.50, Steo: 100.00\nKL: 1779.2, Word: 99.83, Topo: 99.97, Assm: 99.79, Steo: 100.00\nKL: 1707.9, Word: 99.83, Topo: 99.97, Assm: 99.74, Steo: 100.00\nKL: 1711.5, Word: 99.77, Topo: 99.99, Assm: 99.56, Steo: 100.00\nKL: 1765.1, Word: 99.74, Topo: 100.00, Assm: 99.74, Steo: 100.00\nKL: 1689.1, Word: 99.86, Topo: 100.00, Assm: 99.65, Steo: 100.00\nKL: 1703.3, Word: 99.74, Topo: 100.00, Assm: 99.70, Steo: 100.00\nKL: 1704.8, Word: 99.86, Topo: 99.98, Assm: 99.58, Steo: 100.00\nKL: 1735.5, Word: 99.78, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1714.0, Word: 99.67, Topo: 100.00, Assm: 99.33, Steo: 100.00\nKL: 1749.5, Word: 99.72, Topo: 100.00, Assm: 99.69, Steo: 100.00\nKL: 1857.9, Word: 99.70, Topo: 99.97, Assm: 99.57, Steo: 100.00\nKL: 1719.5, Word: 99.80, Topo: 99.99, Assm: 99.59, Steo: 100.00\nKL: 1693.4, Word: 99.83, Topo: 99.99, Assm: 99.85, Steo: 100.00\nKL: 1685.2, Word: 99.76, Topo: 99.99, Assm: 99.37, Steo: 100.00\nKL: 1795.5, Word: 99.79, Topo: 99.99, Assm: 99.64, Steo: 100.00\nKL: 1703.3, Word: 99.81, Topo: 99.98, Assm: 99.55, Steo: 100.00\nKL: 1703.6, Word: 99.74, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1630.1, Word: 99.87, Topo: 100.00, Assm: 99.73, Steo: 100.00\nKL: 1724.3, Word: 99.76, Topo: 99.99, Assm: 99.56, Steo: 100.00\nKL: 1753.9, Word: 99.84, Topo: 99.99, Assm: 99.84, Steo: 100.00\nKL: 1676.5, Word: 99.65, Topo: 100.00, Assm: 99.45, Steo: 100.00\nKL: 1735.7, Word: 99.83, Topo: 99.99, Assm: 99.84, Steo: 100.00\nKL: 1752.8, Word: 99.80, Topo: 99.98, Assm: 99.59, Steo: 100.00\nKL: 1812.4, Word: 99.80, Topo: 99.99, Assm: 99.59, Steo: 100.00\nKL: 1734.1, Word: 99.81, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1621.7, Word: 99.83, Topo: 99.99, Assm: 99.67, Steo: 100.00\nKL: 1674.5, Word: 99.84, Topo: 99.99, Assm: 99.79, Steo: 100.00\nKL: 1705.2, Word: 99.75, Topo: 100.00, Assm: 99.55, Steo: 100.00\nKL: 1704.3, Word: 99.66, Topo: 99.97, Assm: 99.72, Steo: 100.00\nKL: 1774.7, Word: 99.70, Topo: 100.00, Assm: 99.60, Steo: 100.00\nKL: 1896.8, Word: 99.72, Topo: 100.00, Assm: 99.59, Steo: 100.00\nKL: 1730.1, Word: 99.68, Topo: 99.96, Assm: 99.53, Steo: 100.00\nKL: 1718.5, Word: 99.75, Topo: 99.98, Assm: 99.80, Steo: 100.00\nKL: 1749.5, Word: 99.77, Topo: 100.00, Assm: 99.68, Steo: 100.00\nKL: 1748.4, Word: 99.80, Topo: 99.97, Assm: 99.54, Steo: 100.00\nKL: 1798.7, Word: 99.83, Topo: 100.00, Assm: 99.90, Steo: 100.00\nKL: 1662.6, Word: 99.75, Topo: 99.98, Assm: 99.64, Steo: 100.00\nKL: 1724.7, Word: 99.88, Topo: 100.00, Assm: 99.76, Steo: 100.00\nKL: 1718.3, Word: 99.83, Topo: 100.00, Assm: 99.84, Steo: 100.00\nKL: 1768.6, Word: 99.73, Topo: 99.99, Assm: 99.75, Steo: 100.00\nKL: 1687.5, Word: 99.86, Topo: 99.99, Assm: 99.74, Steo: 100.00\nKL: 1670.2, Word: 99.88, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1537.1, Word: 99.82, Topo: 99.98, Assm: 99.47, Steo: 100.00\nKL: 1802.0, Word: 99.72, Topo: 99.97, Assm: 99.95, Steo: 100.00\nKL: 1732.3, Word: 99.76, Topo: 99.99, Assm: 99.75, Steo: 100.00\nKL: 1767.9, Word: 99.80, Topo: 100.00, Assm: 99.75, Steo: 100.00\nKL: 1659.9, Word: 99.78, Topo: 99.99, Assm: 99.89, Steo: 100.00\nKL: 1745.4, Word: 99.67, Topo: 100.00, Assm: 99.70, Steo: 100.00\nKL: 1687.4, Word: 99.67, Topo: 99.99, Assm: 99.55, Steo: 100.00\nKL: 1829.9, Word: 99.78, Topo: 99.98, Assm: 99.75, Steo: 100.00\nKL: 1730.3, Word: 99.71, Topo: 99.99, Assm: 99.91, Steo: 100.00\nKL: 1713.7, Word: 99.83, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1800.5, Word: 99.77, Topo: 99.97, Assm: 99.89, Steo: 100.00\nKL: 1724.1, Word: 99.80, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1700.1, Word: 99.72, Topo: 99.96, Assm: 99.71, Steo: 100.00\nKL: 1724.7, Word: 99.72, Topo: 99.98, Assm: 99.66, Steo: 100.00\nKL: 1780.4, Word: 99.74, Topo: 99.99, Assm: 99.69, Steo: 100.00\nKL: 1735.2, Word: 99.82, Topo: 100.00, Assm: 99.59, Steo: 100.00\nKL: 1757.2, Word: 99.72, Topo: 100.00, Assm: 99.55, Steo: 100.00\nlearning rate: 0.000047\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/pretrain-vae_model.iter-29\n\nKL: 1703.0, Word: 99.80, Topo: 100.00, Assm: 99.58, Steo: 100.00\nKL: 1760.5, Word: 99.83, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1808.8, Word: 99.84, Topo: 99.99, Assm: 99.45, Steo: 100.00\nKL: 1811.9, Word: 99.83, Topo: 99.99, Assm: 99.95, Steo: 100.00\nKL: 1671.7, Word: 99.78, Topo: 99.99, Assm: 99.85, Steo: 100.00\nKL: 1751.6, Word: 99.83, Topo: 100.00, Assm: 99.90, Steo: 100.00\nKL: 1745.4, Word: 99.86, Topo: 99.98, Assm: 99.74, Steo: 100.00\nKL: 1735.8, Word: 99.88, Topo: 99.99, Assm: 99.73, Steo: 100.00\nKL: 1734.8, Word: 99.77, Topo: 99.99, Assm: 99.80, Steo: 100.00\nKL: 1710.6, Word: 99.84, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1737.4, Word: 99.77, Topo: 100.00, Assm: 99.34, Steo: 100.00\nKL: 1673.5, Word: 99.79, Topo: 99.99, Assm: 99.78, Steo: 100.00\nKL: 1779.0, Word: 99.76, Topo: 99.99, Assm: 99.50, Steo: 100.00\nKL: 1749.7, Word: 99.85, Topo: 100.00, Assm: 99.54, Steo: 100.00\nKL: 1723.9, Word: 99.75, Topo: 99.99, Assm: 99.50, Steo: 100.00\nKL: 1813.8, Word: 99.81, Topo: 99.99, Assm: 99.58, Steo: 100.00\nKL: 1750.6, Word: 99.85, Topo: 99.99, Assm: 99.42, Steo: 100.00\nKL: 1744.5, Word: 99.86, Topo: 100.00, Assm: 99.83, Steo: 100.00\nKL: 1809.9, Word: 99.75, Topo: 100.00, Assm: 99.80, Steo: 100.00\nKL: 1832.8, Word: 99.80, Topo: 99.99, Assm: 99.85, Steo: 100.00\nKL: 1701.8, Word: 99.81, Topo: 100.00, Assm: 99.35, Steo: 100.00\nKL: 1847.7, Word: 99.81, Topo: 99.99, Assm: 99.86, Steo: 100.00\nKL: 1693.0, Word: 99.75, Topo: 99.98, Assm: 99.65, Steo: 100.00\nKL: 1697.3, Word: 99.79, Topo: 99.98, Assm: 99.18, Steo: 100.00\nKL: 1730.4, Word: 99.73, Topo: 100.00, Assm: 99.79, Steo: 100.00\nKL: 1735.0, Word: 99.81, Topo: 99.99, Assm: 99.75, Steo: 100.00\nKL: 1672.2, Word: 99.75, Topo: 99.99, Assm: 99.66, Steo: 100.00\nKL: 1806.0, Word: 99.74, Topo: 100.00, Assm: 99.77, Steo: 100.00\nKL: 1819.3, Word: 99.85, Topo: 99.98, Assm: 99.80, Steo: 100.00\nKL: 1788.4, Word: 99.79, Topo: 99.98, Assm: 99.69, Steo: 100.00\nKL: 1730.7, Word: 99.72, Topo: 100.00, Assm: 99.64, Steo: 100.00\nKL: 1780.5, Word: 99.72, Topo: 100.00, Assm: 99.65, Steo: 100.00\nKL: 1701.0, Word: 99.69, Topo: 99.98, Assm: 99.50, Steo: 100.00\nKL: 1711.4, Word: 99.78, Topo: 100.00, Assm: 99.64, Steo: 100.00\nKL: 1754.9, Word: 99.87, Topo: 100.00, Assm: 99.63, Steo: 100.00\nKL: 1729.2, Word: 99.70, Topo: 100.00, Assm: 99.77, Steo: 100.00\nKL: 1726.7, Word: 99.63, Topo: 100.00, Assm: 99.75, Steo: 100.00\nKL: 1777.0, Word: 99.86, Topo: 99.99, Assm: 99.75, Steo: 100.00\nKL: 1776.9, Word: 99.70, Topo: 99.99, Assm: 99.55, Steo: 100.00\nKL: 1753.3, Word: 99.83, Topo: 99.99, Assm: 99.95, Steo: 100.00\nKL: 1769.8, Word: 99.78, Topo: 99.99, Assm: 99.72, Steo: 100.00\nKL: 1730.4, Word: 99.76, Topo: 100.00, Assm: 99.65, Steo: 100.00\nKL: 1776.5, Word: 99.64, Topo: 99.99, Assm: 99.91, Steo: 100.00\nKL: 1798.4, Word: 99.86, Topo: 99.97, Assm: 99.74, Steo: 100.00\nKL: 1755.4, Word: 99.76, Topo: 99.96, Assm: 99.85, Steo: 100.00\nKL: 1714.8, Word: 99.84, Topo: 99.99, Assm: 99.71, Steo: 100.00\nKL: 1681.8, Word: 99.79, Topo: 99.99, Assm: 99.64, Steo: 100.00\nKL: 1758.4, Word: 99.76, Topo: 99.99, Assm: 99.66, Steo: 100.00\nKL: 1637.2, Word: 99.81, Topo: 99.99, Assm: 99.68, Steo: 100.00\nKL: 1683.9, Word: 99.66, Topo: 99.98, Assm: 99.90, Steo: 100.00\nKL: 1709.0, Word: 99.86, Topo: 100.00, Assm: 99.90, Steo: 100.00\nKL: 1803.8, Word: 99.66, Topo: 99.99, Assm: 99.74, Steo: 100.00\nKL: 1730.7, Word: 99.73, Topo: 100.00, Assm: 99.63, Steo: 100.00\nKL: 1758.3, Word: 99.85, Topo: 100.00, Assm: 99.47, Steo: 100.00\nKL: 1746.6, Word: 99.71, Topo: 99.99, Assm: 99.75, Steo: 100.00\nKL: 1659.3, Word: 99.79, Topo: 99.98, Assm: 99.85, Steo: 100.00\nKL: 1790.2, Word: 99.74, Topo: 99.97, Assm: 99.73, Steo: 100.00\nKL: 1678.1, Word: 99.66, Topo: 99.99, Assm: 99.79, Steo: 100.00\nKL: 1711.9, Word: 99.66, Topo: 100.00, Assm: 99.70, Steo: 100.00\nKL: 1777.8, Word: 99.73, Topo: 99.97, Assm: 99.74, Steo: 100.00\nKL: 1764.4, Word: 99.86, Topo: 99.98, Assm: 99.90, Steo: 100.00\nKL: 1710.0, Word: 99.82, Topo: 99.98, Assm: 99.70, Steo: 100.00\nKL: 1750.5, Word: 99.76, Topo: 99.99, Assm: 99.46, Steo: 100.00\nKL: 1769.8, Word: 99.76, Topo: 100.00, Assm: 99.61, Steo: 100.00\nKL: 1725.7, Word: 99.70, Topo: 99.97, Assm: 99.85, Steo: 100.00\nKL: 1652.5, Word: 99.83, Topo: 99.99, Assm: 99.61, Steo: 100.00\nlearning rate: 0.000042\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/pretrain-vae_model.iter-30\n\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":[""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: &#39;/dbfs/FileStore/pickles/jtvae_model/13t09_filt&#39;\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["# Train w/ KL regularization"],"metadata":{}},{"cell_type":"code","source":["%sh ls /dbfs/FileStore/tables/JAK*"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/dbfs/FileStore/tables/JAK1_20190311_cids.csv\n/dbfs/FileStore/tables/JAK1_20190311.csv\n/dbfs/FileStore/tables/JAK1_20190311_sdf-d4409.gz\n/dbfs/FileStore/tables/JAK1 EC50 nM 1027-full.txt\n/dbfs/FileStore/tables/JAK1 EC50 nM 1027.txt\n/dbfs/FileStore/tables/JAK1 EC50 nM 1027-y_test.txt\n/dbfs/FileStore/tables/JAK1 EC50 nM 1027-y_train.txt\n/dbfs/FileStore/tables/JAK2_20190311.csv\n/dbfs/FileStore/tables/JAK2_20190311_sdf-3d49e.gz\n/dbfs/FileStore/tables/JAK2 EC50 nM 1024-full.txt\n/dbfs/FileStore/tables/JAK2 EC50 nM 1024.txt\n/dbfs/FileStore/tables/JAK2 EC50 nM 1024-y_test.txt\n/dbfs/FileStore/tables/JAK2 EC50 nM 1024-y_train.txt\n/dbfs/FileStore/tables/JAK3_20190311.csv\n/dbfs/FileStore/tables/JAK3_20190311_sdf-08df5.gz\n/dbfs/FileStore/tables/JAK3 EC50 nM 1026-full.txt\n/dbfs/FileStore/tables/JAK3 EC50 nM 1026.txt\n/dbfs/FileStore/tables/JAK3 EC50 nM 1026-y_test.txt\n/dbfs/FileStore/tables/JAK3 EC50 nM 1026-y_train.txt\n</div>"]}}],"execution_count":31},{"cell_type":"code","source":["%sh head /dbfs/FileStore/tables/X_train_smiles.txt #Cc1c[nH]c(C(=O)N2CCCN(c3ncnc4[nH]ccc34)CC23CC3)c1"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Cc1c[nH]c(C(=O)N2CCCN(c3ncnc4[nH]ccc34)CC23CC3)c1\nO=S(=O)(N(CCN1CCOCC1)C1CCC1)N1CCN(c2ncnc3[nH]ccc23)CC12CC2\nCN(C[C@@H]1CCCN1S(C)(=O)=O)S(=O)(=O)N1CCN(c2ncnc3[nH]ccc23)CC12CC2\nCC(=O)N1CC[C@H]1COC(=O)N1C2CCC1CN(c1ncnc3[nH]ccc13)C2\nN#Cc1ccc(CC(=O)N2CCN(c3ncnc4[nH]ccc34)C3(CC3)C2)cc1\nO=C(OC1CCC(O)C1)N1C2CCC1CN(c1ncnc3[nH]ccc13)C2\nCC(C)COC(=O)N1CCC[C@@H]1CN(C)S(=O)(=O)N1CCN(c2ncnc3[nH]ccc23)CC12CC2\nN#CCCNC(=O)N1C2CCC1CN(c1ncnc3[nH]ccc13)C2\nC[C@@H](OC(=O)N1C2CCC1CN(c1ncnc3[nH]ccc13)C2)c1c(F)cccc1F\nCN(C[C@H]1CC(F)(F)CN1C(=O)CCO)S(=O)(=O)N1CCN(c2ncnc3[nH]ccc23)CC12CC2\n</div>"]}}],"execution_count":32},{"cell_type":"code","source":["vocab = pickle.load(open(os.path.join(PICKLES_DIR,'Vocab-full_internal-ZINC_13t09_filt.p'),'rb'))\n\nbatch_size = int(40)\nhidden_size = int(420)\nlatent_size = int(56)\ndepth = int(3)\nbeta = 0.005\nlr = 0.0007\nweight_dir = os.path.join(MODEL_DIR,'13t09_filt')\n\nsave_dir = os.path.join(weight_dir,'focused')\nif not os.path.exists(save_dir):\n  os.mkdir(save_dir)\nout_file = os.path.join(save_dir,'vae_log-13t09_filt.csv')\n\nmodel = JTNNVAE(vocab, hidden_size, latent_size, depth)\ntrain_vae(model=model, \n          lr=lr, \n          beta=beta, \n          batch_size=batch_size, \n          MAX_EPOCH=30, \n          SAVE_DIR=save_dir, \n          SMILES_DIR=os.path.join(PARENT_DIR,'X_train_smiles.txt'), \n          pretrain=False, \n          model_load=os.path.join(weight_dir,'pretrain-vae_model.iter-30'), \n          PRINT_ITER=20,\n          log_file=out_file,\n          last_epoch=30)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction=&#39;sum&#39; instead.\n  warnings.warn(warning.format(ret))\nModel #Params: 4377K\n/local_disk0/spark-41dad439-a6be-4357-a6a3-aea4033f8c06/userFiles-b1cf8888-098a-40dc-89af-a69600ffcaa0/addedFile8926062983386895532dbfs__FileStore_jars_23c5a07d_a093_423e_97a9_a303ec5f6ff5_icml18_jtnn_0_1_py3_7_3fd5e-93fb9.egg/icml18_jtnn/jtnn/jtnn_vae.py:166: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\nKL: 1801.7, Word: 73.35, Topo: 95.88, Assm: 93.37, Steo: 100.00\nlearning rate: 0.000630\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-31\n\nKL: 1077.7, Word: 92.98, Topo: 99.15, Assm: 99.06, Steo: 100.00\nlearning rate: 0.000567\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-32\n\nKL: 778.5, Word: 96.35, Topo: 99.49, Assm: 99.60, Steo: 100.00\nlearning rate: 0.000510\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-33\n\nKL: 552.7, Word: 97.70, Topo: 99.76, Assm: 99.57, Steo: 100.00\nlearning rate: 0.000459\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-34\n\nKL: 464.8, Word: 98.24, Topo: 99.77, Assm: 99.67, Steo: 100.00\nlearning rate: 0.000413\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-35\n\nKL: 474.1, Word: 98.78, Topo: 99.84, Assm: 99.62, Steo: 100.00\nlearning rate: 0.000372\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-36\n\nKL: 377.1, Word: 99.00, Topo: 99.88, Assm: 99.81, Steo: 100.00\nlearning rate: 0.000335\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-37\n\nKL: 382.1, Word: 99.26, Topo: 99.88, Assm: 99.93, Steo: 100.00\nlearning rate: 0.000301\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-38\n\nKL: 340.4, Word: 99.37, Topo: 99.92, Assm: 99.76, Steo: 100.00\nlearning rate: 0.000271\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-39\n\nKL: 347.6, Word: 99.36, Topo: 99.94, Assm: 99.88, Steo: 100.00\nlearning rate: 0.000244\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-40\n\nKL: 287.7, Word: 99.54, Topo: 99.95, Assm: 99.84, Steo: 100.00\nlearning rate: 0.000220\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-41\n\nKL: 303.1, Word: 99.53, Topo: 99.95, Assm: 99.93, Steo: 100.00\nlearning rate: 0.000198\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-42\n\nKL: 313.9, Word: 99.60, Topo: 99.97, Assm: 99.95, Steo: 100.00\nlearning rate: 0.000178\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-43\n\nKL: 292.3, Word: 99.51, Topo: 99.98, Assm: 99.93, Steo: 100.00\nlearning rate: 0.000160\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-44\n\nKL: 257.5, Word: 99.53, Topo: 99.98, Assm: 99.90, Steo: 100.00\nlearning rate: 0.000144\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-45\n\nKL: 227.5, Word: 99.67, Topo: 99.97, Assm: 99.93, Steo: 100.00\nlearning rate: 0.000130\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-46\n\nKL: 246.9, Word: 99.80, Topo: 99.97, Assm: 99.90, Steo: 100.00\nlearning rate: 0.000117\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-47\n\nKL: 250.1, Word: 99.64, Topo: 99.98, Assm: 99.88, Steo: 100.00\nlearning rate: 0.000105\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-48\n\nKL: 228.2, Word: 99.70, Topo: 99.98, Assm: 99.86, Steo: 100.00\nlearning rate: 0.000095\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-49\n\nKL: 218.8, Word: 99.72, Topo: 99.98, Assm: 99.90, Steo: 100.00\nlearning rate: 0.000085\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-50\n\nKL: 235.2, Word: 99.73, Topo: 99.98, Assm: 99.86, Steo: 100.00\nlearning rate: 0.000077\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-51\n\nKL: 228.6, Word: 99.83, Topo: 99.97, Assm: 99.98, Steo: 100.00\nlearning rate: 0.000069\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-52\n\nKL: 233.0, Word: 99.84, Topo: 99.97, Assm: 99.95, Steo: 100.00\nlearning rate: 0.000062\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-53\n\nKL: 201.6, Word: 99.80, Topo: 99.99, Assm: 99.90, Steo: 100.00\nlearning rate: 0.000056\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-54\n\nKL: 202.3, Word: 99.71, Topo: 99.99, Assm: 99.84, Steo: 100.00\nlearning rate: 0.000050\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-55\n\nKL: 222.1, Word: 99.82, Topo: 100.00, Assm: 99.88, Steo: 100.00\nlearning rate: 0.000045\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-56\n\nKL: 215.1, Word: 99.84, Topo: 99.99, Assm: 99.95, Steo: 100.00\nlearning rate: 0.000041\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-57\n\nKL: 204.5, Word: 99.84, Topo: 99.99, Assm: 99.93, Steo: 99.69\nlearning rate: 0.000037\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-58\n\nKL: 214.7, Word: 99.87, Topo: 99.98, Assm: 99.86, Steo: 100.00\nlearning rate: 0.000033\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-59\n\nKL: 193.5, Word: 99.84, Topo: 99.99, Assm: 99.98, Steo: 100.00\nlearning rate: 0.000030\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused/vae_model.iter-60\n\n</div>"]}}],"execution_count":33},{"cell_type":"code","source":["vocab = pickle.load(open(os.path.join(PICKLES_DIR,'Vocab-full_internal-ZINC_13t09_filt.p'),'rb'))\n\nbatch_size = int(40)\nhidden_size = int(420)\nlatent_size = int(56)\ndepth = int(3)\nbeta = 0.01\nlr = 0.0007\nweight_dir = os.path.join(MODEL_DIR,'13t09_filt')\n\nsave_dir = os.path.join(weight_dir,'focused_b001')\nif not os.path.exists(save_dir):\n  os.mkdir(save_dir)\nout_file = os.path.join(save_dir,'vae_log-13t09_filt.csv')\n\nmodel = JTNNVAE(vocab, hidden_size, latent_size, depth)\ntrain_vae(model=model, \n          lr=lr, \n          beta=beta, \n          batch_size=batch_size, \n          MAX_EPOCH=30, \n          SAVE_DIR=save_dir, \n          SMILES_DIR=os.path.join(PARENT_DIR,'X_train_smiles.txt'), \n          pretrain=False, \n          model_load=os.path.join(weight_dir,'pretrain-vae_model.iter-30'), \n          PRINT_ITER=20,\n          log_file=out_file,\n          last_epoch=30)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction=&#39;sum&#39; instead.\n  warnings.warn(warning.format(ret))\nModel #Params: 4377K\n/local_disk0/spark-0e1affbf-99b0-4288-a9e5-c37f4c8c2f7c/userFiles-df225366-cfbb-4df8-8c09-aefd7bf68229/addedFile7677603073080092539dbfs__FileStore_jars_23c5a07d_a093_423e_97a9_a303ec5f6ff5_icml18_jtnn_0_1_py3_7_3fd5e-93fb9.egg/icml18_jtnn/jtnn/jtnn_vae.py:166: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\nKL: 1720.3, Word: 72.09, Topo: 95.75, Assm: 93.17, Steo: 100.00\nlearning rate: 0.000630\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused_b001/vae_model.iter-31\n\nKL: 831.3, Word: 91.82, Topo: 99.23, Assm: 98.53, Steo: 99.67\nlearning rate: 0.000567\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused_b001/vae_model.iter-32\n\nKL: 572.1, Word: 95.72, Topo: 99.51, Assm: 99.13, Steo: 100.00\nlearning rate: 0.000510\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused_b001/vae_model.iter-33\n\nKL: 414.3, Word: 97.45, Topo: 99.64, Assm: 99.57, Steo: 100.00\nlearning rate: 0.000459\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused_b001/vae_model.iter-34\n\nKL: 350.7, Word: 97.84, Topo: 99.72, Assm: 99.46, Steo: 100.00\nlearning rate: 0.000413\nModel saved to:  /dbfs/FileStore/pickles/jtvae_model/13t09_filt/focused_b001/vae_model.iter-35\n\n</div>"]}}],"execution_count":34},{"cell_type":"code","source":["vocab = Vocab(list(cset))\n\nbatch_size = int(40)\nhidden_size = int(420)\nlatent_size = int(56)\ndepth = int(3)\nbeta = 0.005\nlr = 0.0007\n\nmodel = JTNNVAE(vocab, hidden_size, latent_size, depth)\n#os.mkdir(os.path.join(MODEL_DIR,'E30E30'))\ntrain_vae(model=model, \n          lr=lr, \n          beta=beta, \n          batch_size=batch_size, \n          MAX_EPOCH=30, \n          SAVE_DIR=os.path.join(MODEL_DIR,'E30E90'), \n          SMILES_DIR=os.path.join(PARENT_DIR,'X_train_smiles.txt'), \n          pretrain=False, \n          model_load=os.path.join(MODEL_DIR,'E30E30/vae_model.iter-59'), \n          PRINT_ITER=20,\n          last_epoch=59)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: \n[&#39;JT_VAE_generated-no_KL-30E.smi&#39;,\n &#39;JT_VAE_generated-no_KL-E30E30.smi&#39;,\n &#39;JT_VAE_generated.smi&#39;,\n &#39;JT_VAE_generated.txt&#39;,\n &#39;X_test_smiles.txt&#39;,\n &#39;X_train_smiles.txt&#39;,\n &#39;aae.config&#39;,\n &#39;aae.mo_000.pt&#39;,\n &#39;aae.mo_020.pt&#39;,\n &#39;aae.mo_040.pt&#39;,\n &#39;aae.mo_060.pt&#39;,\n &#39;aae.mo_080.pt&#39;,\n &#39;aae.model&#39;,\n &#39;aae.vocab&#39;,\n &#39;aae_generated.smi&#39;,\n &#39;char_rnn.config&#39;,\n &#39;char_rnn.mo_000.pt&#39;,\n &#39;char_rnn.mo_020.pt&#39;,\n &#39;char_rnn.mo_040.pt&#39;,\n &#39;char_rnn.mo_060.pt&#39;,\n &#39;char_rnn.mo_080.pt&#39;,\n &#39;char_rnn.mo_100.pt&#39;,\n &#39;char_rnn.mo_120.pt&#39;,\n &#39;char_rnn.mo_140.pt&#39;,\n &#39;char_rnn.mo_160.pt&#39;,\n &#39;char_rnn.mo_180.pt&#39;,\n &#39;char_rnn.model&#39;,\n &#39;char_rnn.vocab&#39;,\n &#39;char_rnn_generated.smi&#39;,\n &#39;metrics.p&#39;,\n &#39;metrics20190411.p&#39;,\n &#39;organ.config&#39;,\n &#39;organ.mo_000.pt&#39;,\n &#39;organ.mo_020.pt&#39;,\n &#39;organ.mo_040.pt&#39;,\n &#39;organ.mo_060.pt&#39;,\n &#39;organ.mo_080.pt&#39;,\n &#39;organ.mo_100.pt&#39;,\n &#39;organ.mo_120.pt&#39;,\n &#39;organ.mo_140.pt&#39;,\n &#39;organ.mo_160.pt&#39;,\n &#39;organ.mo_180.pt&#39;,\n &#39;organ.mo_200.pt&#39;,\n &#39;organ.mo_220.pt&#39;,\n &#39;organ.mo_240.pt&#39;,\n &#39;organ.mo_260.pt&#39;,\n &#39;organ.mo_280.pt&#39;,\n &#39;organ.mo_300.pt&#39;,\n &#39;organ.mo_320.pt&#39;,\n &#39;organ.mo_340.pt&#39;,\n &#39;organ.mo_360.pt&#39;,\n &#39;organ.mo_380.pt&#39;,\n &#39;organ.mo_400.pt&#39;,\n &#39;organ.mo_420.pt&#39;,\n &#39;organ.mo_440.pt&#39;,\n &#39;organ.mo_460.pt&#39;,\n &#39;organ.mo_480.pt&#39;,\n &#39;organ.mo_500.pt&#39;,\n &#39;organ.mo_discriminator_000.pt&#39;,\n &#39;organ.mo_discriminator_020.pt&#39;,\n &#39;organ.mo_discriminator_040.pt&#39;,\n &#39;organ.mo_generator_000.pt&#39;,\n &#39;organ.mo_generator_020.pt&#39;,\n &#39;organ.mo_generator_040.pt&#39;,\n &#39;organ.vocab&#39;,\n &#39;vae.config&#39;,\n &#39;vae.mo_000.pt&#39;,\n &#39;vae.mo_020.pt&#39;,\n &#39;vae.mo_040.pt&#39;,\n &#39;vae.model&#39;,\n &#39;vae.vocab&#39;,\n &#39;vae_generated.smi&#39;]\n</div>"]}}],"execution_count":35},{"cell_type":"code","source":["import os\nG2G = '/dbfs/FileStore/g2g'\n\nTENSORS = os.path.join(G2G,'tensors')\ndest = 'median-train_pairs'\nos.listdir(os.path.join(TENSORS,dest,'JAK1'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: [&#39;median-train_pairs-941-JAK1-tensors-0.pkl&#39;]\n</div>"]}}],"execution_count":36},{"cell_type":"code","source":["vocab = pickle.load(open(os.path.join(PICKLES_DIR,'Vocab-full_internal-ZINC_13t09_filt.p'),'rb'))\n\nbatch_size = int(40)\nhidden_size = int(420)\nlatent_size = int(56)\ndepth = int(3)\nbeta = 0.005\nlr = 0.0007\nweight_dir = os.path.join(MODEL_DIR,'13t09_filt')\n\nsave_dir = os.path.join(weight_dir,'focused-prop')\nif not os.path.exists(save_dir):\n  os.mkdir(save_dir)\nout_file = os.path.join(save_dir,'vae_log-13t09_filt.csv')\n\nmodel = JTNNVAE(vocab, hidden_size, latent_size, depth)\ntrain_prop(model=model, \n          lr=lr, \n          beta=beta, \n          batch_size=batch_size, \n          MAX_EPOCH=30, \n          SAVE_DIR=save_dir, \n          SMILES_DIR=os.path.join(PARENT_DIR,'X_train_smiles.txt'), \n          PROP_DIR='/dbfs/FileStore/tables/JAK1 EC50 nM 1027-y_train.txt',\n          pretrain=False, \n          model_path=os.path.join(weight_dir,'pretrain-vae_model.iter-30'), \n          PRINT_ITER=20,\n          log_file=out_file,\n          last_epoch=30)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2358522239419970&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     27</span>           PRINT_ITER<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">20</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span>           log_file<span class=\"ansi-blue-fg\">=</span>out_file<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">---&gt; 29</span><span class=\"ansi-red-fg\">           last_epoch=30)\n</span>\n<span class=\"ansi-green-fg\">&lt;command-2586525794889037&gt;</span> in <span class=\"ansi-cyan-fg\">train_prop</span><span class=\"ansi-blue-fg\">(model, lr, beta, batch_size, MAX_EPOCH, SAVE_DIR, SMILES_DIR, PROP_DIR, pretrain, model_path, PRINT_ITER, last_epoch, log_file)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     38</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     39</span>             model<span class=\"ansi-blue-fg\">.</span>zero_grad<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 40</span><span class=\"ansi-red-fg\">             </span>loss<span class=\"ansi-blue-fg\">,</span> kl_div<span class=\"ansi-blue-fg\">,</span> wacc<span class=\"ansi-blue-fg\">,</span> tacc<span class=\"ansi-blue-fg\">,</span> sacc<span class=\"ansi-blue-fg\">,</span> dacc<span class=\"ansi-blue-fg\">,</span> pacc <span class=\"ansi-blue-fg\">=</span> model<span class=\"ansi-blue-fg\">(</span>batch<span class=\"ansi-blue-fg\">,</span> beta<span class=\"ansi-blue-fg\">=</span>beta<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     41</span>             loss<span class=\"ansi-blue-fg\">.</span>backward<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     42</span>             optimizer<span class=\"ansi-blue-fg\">.</span>step<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.6/site-packages/torch/nn/modules/module.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *input, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    475</span>             result <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_slow_forward<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>input<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    476</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 477</span><span class=\"ansi-red-fg\">             </span>result <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>forward<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>input<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    478</span>         <span class=\"ansi-green-fg\">for</span> hook <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>_forward_hooks<span class=\"ansi-blue-fg\">.</span>values<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    479</span>             hook_result <span class=\"ansi-blue-fg\">=</span> hook<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> input<span class=\"ansi-blue-fg\">,</span> result<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-62a56c90-ff56-4b9b-9981-c1095d9e33aa/userFiles-bcdd8d3f-fe6c-4925-8134-e8b5e775d79f/addedFile6045101444694054779dbfs__FileStore_jars_23c5a07d_a093_423e_97a9_a303ec5f6ff5_icml18_jtnn_0_1_py3_7_3fd5e-93fb9.egg/icml18_jtnn/jtnn/jtnn_vae.py</span> in <span class=\"ansi-cyan-fg\">forward</span><span class=\"ansi-blue-fg\">(self, mol_batch, beta)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     70</span>         batch_size <span class=\"ansi-blue-fg\">=</span> len<span class=\"ansi-blue-fg\">(</span>mol_batch<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span> \n<span class=\"ansi-green-fg\">---&gt; 72</span><span class=\"ansi-red-fg\">         </span>tree_mess<span class=\"ansi-blue-fg\">,</span> tree_vec<span class=\"ansi-blue-fg\">,</span> mol_vec <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>encode<span class=\"ansi-blue-fg\">(</span>mol_batch<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     73</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>         tree_mean <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>T_mean<span class=\"ansi-blue-fg\">(</span>tree_vec<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-62a56c90-ff56-4b9b-9981-c1095d9e33aa/userFiles-bcdd8d3f-fe6c-4925-8134-e8b5e775d79f/addedFile6045101444694054779dbfs__FileStore_jars_23c5a07d_a093_423e_97a9_a303ec5f6ff5_icml18_jtnn_0_1_py3_7_3fd5e-93fb9.egg/icml18_jtnn/jtnn/jtnn_vae.py</span> in <span class=\"ansi-cyan-fg\">encode</span><span class=\"ansi-blue-fg\">(self, mol_batch)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     49</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     50</span>     <span class=\"ansi-green-fg\">def</span> encode<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> mol_batch<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 51</span><span class=\"ansi-red-fg\">         </span>set_batch_nodeID<span class=\"ansi-blue-fg\">(</span>mol_batch<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>vocab<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     52</span>         root_batch <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>mol_tree<span class=\"ansi-blue-fg\">.</span>nodes<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">for</span> mol_tree <span class=\"ansi-green-fg\">in</span> mol_batch<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     53</span>         tree_mess<span class=\"ansi-blue-fg\">,</span>tree_vec <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>jtnn<span class=\"ansi-blue-fg\">(</span>root_batch<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-62a56c90-ff56-4b9b-9981-c1095d9e33aa/userFiles-bcdd8d3f-fe6c-4925-8134-e8b5e775d79f/addedFile6045101444694054779dbfs__FileStore_jars_23c5a07d_a093_423e_97a9_a303ec5f6ff5_icml18_jtnn_0_1_py3_7_3fd5e-93fb9.egg/icml18_jtnn/jtnn/jtnn_vae.py</span> in <span class=\"ansi-cyan-fg\">set_batch_nodeID</span><span class=\"ansi-blue-fg\">(mol_batch, vocab)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     18</span>     tot <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-cyan-fg\">0</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     19</span>     <span class=\"ansi-green-fg\">for</span> mol_tree <span class=\"ansi-green-fg\">in</span> mol_batch<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 20</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> mol_tree<span class=\"ansi-blue-fg\">.</span>nodes<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     21</span>             node<span class=\"ansi-blue-fg\">.</span>idx <span class=\"ansi-blue-fg\">=</span> tot\n<span class=\"ansi-green-intense-fg ansi-bold\">     22</span>             node<span class=\"ansi-blue-fg\">.</span>wid <span class=\"ansi-blue-fg\">=</span> vocab<span class=\"ansi-blue-fg\">.</span>get_index<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">.</span>smiles<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;tuple&#39; object has no attribute &#39;nodes&#39;</div>"]}}],"execution_count":37},{"cell_type":"code","source":[""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":38},{"cell_type":"markdown","source":["# Generation"],"metadata":{}},{"cell_type":"code","source":["pd.Series(X_train).str.contains('@').any()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: True\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["from icml18_jtnn.jtnn import *\nvocab = Vocab(list(cset))\n\nhidden_size = int(420)\nlatent_size = int(56)\ndepth = int(3)\nnsample = int(500)\n#stereo=False\n\nmodel = JTNNVAE(vocab, hidden_size, latent_size, depth)#, stereo=stereo\nload_dict = torch.load(os.path.join(MODEL_DIR,'E30E90/vae_model.iter-89'))\nmissing = {k: v for k, v in model.state_dict().items() if k not in load_dict}\nload_dict.update(missing) \nmodel.load_state_dict(load_dict)\nmodel = model.cuda()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction=&#39;sum&#39; instead.\n  warnings.warn(warning.format(ret))\n</div>"]}}],"execution_count":41},{"cell_type":"code","source":["torch.manual_seed(1)\ngen_mols = []\nfor i in range(nsample):\n  new_smi = model.sample_prior()#prob_decode=False\n  print(new_smi)\n  gen_mols.append(new_smi)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">IndexError</span>                                Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1253470162612490&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> gen_mols <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> <span class=\"ansi-green-fg\">for</span> i <span class=\"ansi-green-fg\">in</span> range<span class=\"ansi-blue-fg\">(</span>nsample<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\">   </span>new_smi <span class=\"ansi-blue-fg\">=</span> model<span class=\"ansi-blue-fg\">.</span>sample_prior<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">#prob_decode=False</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>   print<span class=\"ansi-blue-fg\">(</span>new_smi<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span>   gen_mols<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span>new_smi<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-5fe59e76-d66f-48b1-b5b6-e83803aad525/userFiles-52245eb6-9608-4fb4-8479-d240d40f4677/addedFile731834288441370575dbfs__FileStore_jars_23c5a07d_a093_423e_97a9_a303ec5f6ff5_icml18_jtnn_0_1_py3_7_3fd5e-93fb9.egg/icml18_jtnn/jtnn/jtnn_vae.py</span> in <span class=\"ansi-cyan-fg\">sample_prior</span><span class=\"ansi-blue-fg\">(self, prob_decode)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    213</span>         tree_vec <span class=\"ansi-blue-fg\">=</span> create_var<span class=\"ansi-blue-fg\">(</span>torch<span class=\"ansi-blue-fg\">.</span>randn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>latent_size <span class=\"ansi-blue-fg\">//</span> <span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    214</span>         mol_vec <span class=\"ansi-blue-fg\">=</span> create_var<span class=\"ansi-blue-fg\">(</span>torch<span class=\"ansi-blue-fg\">.</span>randn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>latent_size <span class=\"ansi-blue-fg\">//</span> <span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 215</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>decode<span class=\"ansi-blue-fg\">(</span>tree_vec<span class=\"ansi-blue-fg\">,</span> mol_vec<span class=\"ansi-blue-fg\">,</span> prob_decode<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    216</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    217</span>     <span class=\"ansi-green-fg\">def</span> sample_eval<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-5fe59e76-d66f-48b1-b5b6-e83803aad525/userFiles-52245eb6-9608-4fb4-8479-d240d40f4677/addedFile731834288441370575dbfs__FileStore_jars_23c5a07d_a093_423e_97a9_a303ec5f6ff5_icml18_jtnn_0_1_py3_7_3fd5e-93fb9.egg/icml18_jtnn/jtnn/jtnn_vae.py</span> in <span class=\"ansi-cyan-fg\">decode</span><span class=\"ansi-blue-fg\">(self, tree_vec, mol_vec, prob_decode)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    259</span>         scores <span class=\"ansi-blue-fg\">=</span> nn<span class=\"ansi-blue-fg\">.</span>CosineSimilarity<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">(</span>stereo_vecs<span class=\"ansi-blue-fg\">,</span> mol_vec<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    260</span>         _<span class=\"ansi-blue-fg\">,</span>max_id <span class=\"ansi-blue-fg\">=</span> scores<span class=\"ansi-blue-fg\">.</span>max<span class=\"ansi-blue-fg\">(</span>dim<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 261</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> stereo_cands<span class=\"ansi-blue-fg\">[</span>max_id<span class=\"ansi-blue-fg\">.</span>data<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    262</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    263</span>     <span class=\"ansi-green-fg\">def</span> dfs_assemble<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> tree_mess<span class=\"ansi-blue-fg\">,</span> mol_vec<span class=\"ansi-blue-fg\">,</span> all_nodes<span class=\"ansi-blue-fg\">,</span> cur_mol<span class=\"ansi-blue-fg\">,</span> global_amap<span class=\"ansi-blue-fg\">,</span> fa_amap<span class=\"ansi-blue-fg\">,</span> cur_node<span class=\"ansi-blue-fg\">,</span> fa_node<span class=\"ansi-blue-fg\">,</span> prob_decode<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">IndexError</span>: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number</div>"]}}],"execution_count":42},{"cell_type":"code","source":["MOSES_DIR = '/dbfs/FileStore/moses'\n#pd.DataFrame({name:pd.read_csv(os.path.join(MOSES_DIR,name+'_generated.smi'),squeeze=True) for name in names})\npd.DataFrame({'SMILES':gen_mols}).to_csv(os.path.join(MOSES_DIR,'JT_VAE_generated-no_KL-E30E30.smi'), index=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":43},{"cell_type":"code","source":["vocab = pickle.load(open(os.path.join(PICKLES_DIR,'Vocab-full_internal-ZINC_13t09_filt.p'),'rb'))\n\nbatch_size = int(40)\nhidden_size = int(420)\nlatent_size = int(56)\ndepth = int(3)\nnsample=int(500)\nmodel = JTNNVAE(vocab, hidden_size, latent_size, depth)\nload_dict = torch.load(os.path.join(weight_dir,'focused/vae_model.iter-60'))\nmissing = {k: v for k, v in model.state_dict().items() if k not in load_dict}\nload_dict.update(missing) \nmodel.load_state_dict(load_dict)\nmodel = model.cuda()\ntorch.manual_seed(1)\ngen_mols = []\nfor i in range(nsample):\n  new_smi = model.sample_prior()#prob_decode=False\n  print(new_smi)\n  gen_mols.append(new_smi)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1253470162612493&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     18</span>   print<span class=\"ansi-blue-fg\">(</span>new_smi<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     19</span>   gen_mols<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span>new_smi<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 20</span><span class=\"ansi-red-fg\"> </span>pd<span class=\"ansi-blue-fg\">.</span>DataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#39;SMILES&#39;</span><span class=\"ansi-blue-fg\">:</span>gen_mols<span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>to_csv<span class=\"ansi-blue-fg\">(</span>os<span class=\"ansi-blue-fg\">.</span>path<span class=\"ansi-blue-fg\">.</span>join<span class=\"ansi-blue-fg\">(</span>MOSES_DIR<span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;JT_VAE_generated-pretrain_filt-focused-E30E30.smi&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> index<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;MOSES_DIR&#39; is not defined</div>"]}}],"execution_count":44},{"cell_type":"code","source":["pd.DataFrame({'SMILES':gen_mols}).to_csv(os.path.join(MOSES_DIR,'JT_VAE_generated-pretrain_filt-focused-E30E30.smi'), index=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":45},{"cell_type":"markdown","source":["# Bayesian Optimization"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":["# Constrained Molecule Optimization - Training"],"metadata":{}},{"cell_type":"code","source":[" train_prop(model, lr, beta, batch_size, MAX_EPOCH, MODEL_DIR, SMILES_DIR, PROP_DIR, pretrain=True, model_path=None, PRINT_ITER=20)"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nimport math, random, sys\nfrom optparse import OptionParser\nfrom collections import deque\n\nimport rdkit\nimport rdkit.Chem as Chem\nfrom rdkit.Chem import Descriptors\nfrom icml18_jtnn.molopt import sascorer\n\nfrom icml18_jtnn.jtnn import *"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":50},{"cell_type":"code","source":["import timeit\ndef timer(start, ind, obj):\n    stop = timeit.default_timer()\n    if (ind/len(obj)*100) < 5:\n        expected_time = \"Calculating...\"\n    else:\n        time_perc = timeit.default_timer()\n        expected_time = np.round(((time_perc-start)/(ind/len(obj)))/60,2)\n    print(\"Current progress:\",np.round(ind/len(obj)*100,2),\"%\")\n    print(\"Current run time:\",np.round((stop-start)/60,2),\"minutes\")\n    print(\"Expected Run Time:\",expected_time,\"minutes\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":51},{"cell_type":"code","source":["vocab = Vocab(list(cset))\nhidden_size = int(420)\nlatent_size = int(56)\ndepth = int(3)\nsim_cutoff = 0.0\nmodel = JTPropVAE(vocab, hidden_size, latent_size, depth)\nmodel.load_state_dict(torch.load('/dbfs/FileStore/pickles/jtvae_model/JAK1 EC50 nM 1027/prop_model.iter-5'))\nmodel = model.cuda()\nres = []\nimport GPUtil\nfrom IPython.display import clear_output\n\nstart = timeit.default_timer()\n\nfor i, smiles in enumerate(X_test):\n    mol = Chem.MolFromSmiles(smiles)\n    #score = Descriptors.MolLogP(mol) - sascorer.calculateScore(mol, path_to_fpscores=os.path.join(PARENT_DIR,'fpscores_pkl.gz'))\n    print(i)\n    new_smiles,sim = model.optimize(smiles, sim_cutoff=sim_cutoff, lr=2, num_iter=80)\n    new_mol = Chem.MolFromSmiles(new_smiles)\n    #new_score = Descriptors.MolLogP(new_mol) - sascorer.calculateScore(new_mol,path_to_fpscores=os.path.join(PARENT_DIR,'fpscores_pkl.gz'))\n    #GPUtil.showUtilization()\n    clear_output(wait=True)\n\n    timer(start, i, X_test)\n    #res.append( (new_score - score, sim, score, new_score, smiles, new_smiles) )\n    #print(new_score - score, sim, score, new_score, smiles, new_smiles)\n    res.append(new_smiles)\n\n#print(sum([x[0] for x in res]), sum([x[1] for x in res]))\n"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["len(X_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: 365\n</div>"]}}],"execution_count":53},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["\n#vocab = [x.strip(\"\\r\\n \") for x in open(opts.vocab_path)] \nvocab = Vocab(list(cset))\n\nbatch_size = int(40)\nhidden_size = int(420)\nlatent_size = int(56)\ndepth = int(3)\n\nmodel = JTPropVAE(vocab, hidden_size, latent_size, depth)\n\nfor param in model.parameters():\n    if param.dim() == 1:\n        nn.init.constant(param, 0)\n    else:\n        nn.init.xavier_normal(param)\n\nmodel = model.cuda()\nprint( \"Model #Params: %dK\" % (sum([x.nelement() for x in model.parameters()]) / 1000,))\n\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\nscheduler = lr_scheduler.ExponentialLR(optimizer, 0.9)\nscheduler.step()\n\ndataset = PropDataset(os.path.join(PARENT_DIR,'full_smiles.txt'), os.path.join(PARENT_DIR,names[0]+'.txt'))\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=lambda x:x)\n\nMAX_EPOCH = int(3)\nPRINT_ITER = 20\n\nfor epoch in range(MAX_EPOCH):\n    word_acc,topo_acc,assm_acc,steo_acc,prop_acc = 0,0,0,0,0\n\n    for it, batch in enumerate(dataloader):\n        for mol_tree,_ in batch:\n            for node in mol_tree.nodes:\n                if node.label not in node.cands:\n                    node.cands.append(node.label)\n                    node.cand_mols.append(node.label_mol)\n\n        model.zero_grad()\n        loss, kl_div, wacc, tacc, sacc, dacc, pacc = model(batch, beta=0)\n        loss.backward()\n        optimizer.step()\n\n        word_acc += wacc\n        topo_acc += tacc\n        assm_acc += sacc\n        steo_acc += dacc\n        prop_acc += pacc\n\n        if (it + 1) % PRINT_ITER == 0:\n            word_acc = word_acc / PRINT_ITER * 100\n            topo_acc = topo_acc / PRINT_ITER * 100\n            assm_acc = assm_acc / PRINT_ITER * 100\n            steo_acc = steo_acc / PRINT_ITER * 100\n            prop_acc = prop_acc / PRINT_ITER\n\n            print(\"KL: %.1f, Word: %.2f, Topo: %.2f, Assm: %.2f, Steo: %.2f, Prop: %.4f\" % (kl_div, word_acc, topo_acc, assm_acc, steo_acc, prop_acc))\n            word_acc,topo_acc,assm_acc,steo_acc,prop_acc = 0,0,0,0,0\n            sys.stdout.flush()\n\n    scheduler.step()\n    print( \"learning rate: %.6f\" % scheduler.get_lr()[0])\n    torch.save(model.state_dict(), MODEL_DIR + \"/model.iter-\" + str(epoch))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction=&#39;sum&#39; instead.\n  warnings.warn(warning.format(ret))\n/local_disk0/tmp/1553963390297-0/PythonShell.py:16: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n  from collections import OrderedDict\n/local_disk0/tmp/1553963390297-0/PythonShell.py:14: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n  import traceback\nModel #Params: 3946K\n/local_disk0/spark-a376ed6f-69b7-4b67-a8b6-ad6533452811/userFiles-945a78dc-e7a7-4b49-94ef-db7ed43d9f4a/addedFile6238721892749691038dbfs__FileStore_jars_ba628ba6_8186_4e38_ab41_1e8a42751426_icml18_jtnn_0_1_py3_7_3fd5e-6964d.egg/icml18_jtnn/jtnn/jtprop_vae.py:134: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n/local_disk0/spark-a376ed6f-69b7-4b67-a8b6-ad6533452811/userFiles-945a78dc-e7a7-4b49-94ef-db7ed43d9f4a/addedFile6238721892749691038dbfs__FileStore_jars_ba628ba6_8186_4e38_ab41_1e8a42751426_icml18_jtnn_0_1_py3_7_3fd5e-6964d.egg/icml18_jtnn/jtnn/jtprop_vae.py:168: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n/local_disk0/spark-a376ed6f-69b7-4b67-a8b6-ad6533452811/userFiles-945a78dc-e7a7-4b49-94ef-db7ed43d9f4a/addedFile6238721892749691038dbfs__FileStore_jars_ba628ba6_8186_4e38_ab41_1e8a42751426_icml18_jtnn_0_1_py3_7_3fd5e-6964d.egg/icml18_jtnn/jtnn/jtprop_vae.py:101: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\nKL: 37620.8, Word: 22.18, Topo: 73.31, Assm: 74.06, Steo: 54.70, Prop: 42284376.0000\nKL: 89176.5, Word: 45.06, Topo: 88.63, Assm: 80.86, Steo: 43.97, Prop: 26170828.0000\nlearning rate: 0.000900\nKL: 83814.9, Word: 57.50, Topo: 94.04, Assm: 84.79, Steo: 48.30, Prop: 38363532.0000\nKL: 73418.0, Word: 65.03, Topo: 95.40, Assm: 85.70, Steo: 47.59, Prop: 36652696.0000\nlearning rate: 0.000810\nKL: 48555.5, Word: 71.37, Topo: 96.14, Assm: 88.75, Steo: 54.01, Prop: 22451174.0000\nKL: 32698.0, Word: 71.91, Topo: 96.23, Assm: 87.99, Steo: 55.97, Prop: 34842292.0000\n</div>"]}}],"execution_count":56},{"cell_type":"code","source":["beta = 0.005\nlr = 0.0007\n\nmodel = JTPropVAE(vocab, hidden_size, latent_size, depth)\n\nif opts.model_path is not None:\n    model.load_state_dict(torch.load(opts.model_path))\nelse:\n    for param in model.parameters():\n        if param.dim() == 1:\n            nn.init.constant(param, 0)\n        else:\n            nn.init.xavier_normal(param)\n\nmodel = model.cuda()\nprint( \"Model #Params: %dK\" % (sum([x.nelement() for x in model.parameters()]) / 1000,))\n\noptimizer = optim.Adam(model.parameters(), lr=lr)\nscheduler = lr_scheduler.ExponentialLR(optimizer, 0.9)\nscheduler.step()\n\nMAX_EPOCH = 6\nPRINT_ITER = 20\n\nfor epoch in range(MAX_EPOCH):\n    word_acc,topo_acc,assm_acc,steo_acc,prop_acc = 0,0,0,0,0\n\n    for it, batch in enumerate(dataloader):\n        for mol_tree,_ in batch:\n            for node in mol_tree.nodes:\n                if node.label not in node.cands:\n                    node.cands.append(node.label)\n                    node.cand_mols.append(node.label_mol)\n\n        model.zero_grad()\n        loss, kl_div, wacc, tacc, sacc, dacc, pacc = model(batch, beta)\n        loss.backward()\n        optimizer.step()\n\n        word_acc += wacc\n        topo_acc += tacc\n        assm_acc += sacc\n        steo_acc += dacc\n        prop_acc += pacc\n\n        if (it + 1) % PRINT_ITER == 0:\n            word_acc = word_acc / PRINT_ITER * 100\n            topo_acc = topo_acc / PRINT_ITER * 100\n            assm_acc = assm_acc / PRINT_ITER * 100\n            steo_acc = steo_acc / PRINT_ITER * 100\n            prop_acc /= PRINT_ITER\n\n            print(\"KL: %.1f, Word: %.2f, Topo: %.2f, Assm: %.2f, Steo: %.2f, Prop: %.4f\" % (kl_div, word_acc, topo_acc, assm_acc, steo_acc, prop_acc))\n            word_acc,topo_acc,assm_acc,steo_acc,prop_acc = 0,0,0,0,0\n            sys.stdout.flush()\n\n        if (it + 1) % 1500 == 0: #Fast annealing\n            scheduler.step()\n            print \"learning rate: %.6f\" % scheduler.get_lr()[0]\n            torch.save(model.state_dict(), opts.save_path + \"/model.iter-%d-%d\" % (epoch, it + 1))\n\n    scheduler.step()\n    print(\"learning rate: \", scheduler.get_lr()[0])\n    torch.save(model.state_dict(), MODEL_DIR + \"/prop_model.iter-\" + str(epoch))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[19]: 2.0\n</div>"]}}],"execution_count":57},{"cell_type":"code","source":["from icml18_jtnn.fast_molvae.preprocess import *"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":58},{"cell_type":"code","source":["import torch\nimport torch.nn as nn\nfrom multiprocessing import Pool\n\nimport math, random, sys\nfrom optparse import OptionParser\nimport _pickle as pickle\n\nfrom icml18_jtnn.fast_jtnn import *\nimport rdkit\n\ndef tensorize(smiles, assm=True):\n    mol_tree = MolTree(smiles)\n    mol_tree.recover()\n    if assm:\n        mol_tree.assemble()\n        for node in mol_tree.nodes:\n            if node.label not in node.cands:\n                node.cands.append(node.label)\n\n    del mol_tree.mol\n    #for node in mol_tree.nodes:\n        #del node.mol\n\n    return mol_tree"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":59},{"cell_type":"code","source":["PROCESSED_DIR = os.path.join(PICKLES_DIR, \"jtvae_processed\")\nos.mkdir(PROCESSED_DIR)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">FileExistsError</span>                           Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1531239716267171&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> PROCESSED_DIR <span class=\"ansi-blue-fg\">=</span> os<span class=\"ansi-blue-fg\">.</span>path<span class=\"ansi-blue-fg\">.</span>join<span class=\"ansi-blue-fg\">(</span>PICKLES_DIR<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;jtvae_processed&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>os<span class=\"ansi-blue-fg\">.</span>mkdir<span class=\"ansi-blue-fg\">(</span>PROCESSED_DIR<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">FileExistsError</span>: [Errno 17] File exists: &#39;/dbfs/FileStore/pickles/jtvae_processed&#39;</div>"]}}],"execution_count":60},{"cell_type":"code","source":["pool = Pool(1)\nnum_splits = int(20)\n\ndata = full_internal['Isomeric_canon'].tolist()\n\nall_data = [tensorize(x) for x in data]\n\nle = (len(all_data) + num_splits - 1) / num_splits\n\nfor split_id in xrange(num_splits):\n    st = split_id * le\n    sub_data = all_data[st : st + le]\n\n    with open(os.path.join(PROCESSED_DIR, 'tensors-%d.pkl' % split_id), 'wb') as f:\n        pickle.dump(sub_data, f, pickle.HIGHEST_PROTOCOL)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1531239716267170&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> data <span class=\"ansi-blue-fg\">=</span> full_internal<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;Isomeric_canon&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">.</span>tolist<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> \n<span class=\"ansi-green-fg\">----&gt; 6</span><span class=\"ansi-red-fg\"> </span>all_data <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>tensorize<span class=\"ansi-blue-fg\">(</span>x<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> x <span class=\"ansi-green-fg\">in</span> data<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> le <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">(</span>len<span class=\"ansi-blue-fg\">(</span>all_data<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">+</span> num_splits <span class=\"ansi-blue-fg\">-</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">/</span> num_splits\n\n<span class=\"ansi-green-fg\">&lt;command-1531239716267170&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;listcomp&gt;</span><span class=\"ansi-blue-fg\">(.0)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> data <span class=\"ansi-blue-fg\">=</span> full_internal<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;Isomeric_canon&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">.</span>tolist<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> \n<span class=\"ansi-green-fg\">----&gt; 6</span><span class=\"ansi-red-fg\"> </span>all_data <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>tensorize<span class=\"ansi-blue-fg\">(</span>x<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> x <span class=\"ansi-green-fg\">in</span> data<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> le <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">(</span>len<span class=\"ansi-blue-fg\">(</span>all_data<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">+</span> num_splits <span class=\"ansi-blue-fg\">-</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">/</span> num_splits\n\n<span class=\"ansi-green-fg\">&lt;command-1531239716267172&gt;</span> in <span class=\"ansi-cyan-fg\">tensorize</span><span class=\"ansi-blue-fg\">(smiles, assm)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     14</span>     mol_tree<span class=\"ansi-blue-fg\">.</span>recover<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     15</span>     <span class=\"ansi-green-fg\">if</span> assm<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 16</span><span class=\"ansi-red-fg\">         </span>mol_tree<span class=\"ansi-blue-fg\">.</span>assemble<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     17</span>         <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> mol_tree<span class=\"ansi-blue-fg\">.</span>nodes<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     18</span>             <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>label <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">in</span> node<span class=\"ansi-blue-fg\">.</span>cands<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-7176e284-af06-40fc-ab93-e4b8a755b275/userFiles-e8ecb9fb-3024-4bea-a8e3-4cb2e829c1ab/addedFile3453741836193570924dbfs__FileStore_jars_b3d80b5a_617a_4ce0_81da_c4868ab12bac_icml18_jtnn_0_1_py3_7_3fd5e-aba95.egg/icml18_jtnn/fast_jtnn/mol_tree.py</span> in <span class=\"ansi-cyan-fg\">assemble</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    101</span>     <span class=\"ansi-green-fg\">def</span> assemble<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    102</span>         <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>nodes<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 103</span><span class=\"ansi-red-fg\">             </span>node<span class=\"ansi-blue-fg\">.</span>assemble<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    104</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    105</span> <span class=\"ansi-green-fg\">def</span> dfs<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">,</span> fa_idx<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-7176e284-af06-40fc-ab93-e4b8a755b275/userFiles-e8ecb9fb-3024-4bea-a8e3-4cb2e829c1ab/addedFile3453741836193570924dbfs__FileStore_jars_b3d80b5a_617a_4ce0_81da_c4868ab12bac_icml18_jtnn_0_1_py3_7_3fd5e-aba95.egg/icml18_jtnn/fast_jtnn/mol_tree.py</span> in <span class=\"ansi-cyan-fg\">assemble</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     48</span>         neighbors <span class=\"ansi-blue-fg\">=</span> singletons <span class=\"ansi-blue-fg\">+</span> neighbors\n<span class=\"ansi-green-intense-fg ansi-bold\">     49</span> \n<span class=\"ansi-green-fg\">---&gt; 50</span><span class=\"ansi-red-fg\">         </span>cands<span class=\"ansi-blue-fg\">,</span>aroma <span class=\"ansi-blue-fg\">=</span> enum_assemble<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> neighbors<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     51</span>         new_cands <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>cand <span class=\"ansi-green-fg\">for</span> i<span class=\"ansi-blue-fg\">,</span>cand <span class=\"ansi-green-fg\">in</span> enumerate<span class=\"ansi-blue-fg\">(</span>cands<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">if</span> aroma<span class=\"ansi-blue-fg\">[</span>i<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">&gt;=</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     52</span>         <span class=\"ansi-green-fg\">if</span> len<span class=\"ansi-blue-fg\">(</span>new_cands<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span> cands <span class=\"ansi-blue-fg\">=</span> new_cands\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-7176e284-af06-40fc-ab93-e4b8a755b275/userFiles-e8ecb9fb-3024-4bea-a8e3-4cb2e829c1ab/addedFile3453741836193570924dbfs__FileStore_jars_b3d80b5a_617a_4ce0_81da_c4868ab12bac_icml18_jtnn_0_1_py3_7_3fd5e-aba95.egg/icml18_jtnn/fast_jtnn/chemutils.py</span> in <span class=\"ansi-cyan-fg\">enum_assemble</span><span class=\"ansi-blue-fg\">(node, neighbors, prev_nodes, prev_amap)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    297</span>         cand_smiles<span class=\"ansi-blue-fg\">.</span>add<span class=\"ansi-blue-fg\">(</span>smiles<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    298</span>         candidates<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span> <span class=\"ansi-blue-fg\">(</span>smiles<span class=\"ansi-blue-fg\">,</span>amap<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 299</span><span class=\"ansi-red-fg\">         </span>aroma_score<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span> check_aroma<span class=\"ansi-blue-fg\">(</span>cand_mol<span class=\"ansi-blue-fg\">,</span> node<span class=\"ansi-blue-fg\">,</span> neighbors<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    300</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    301</span>     <span class=\"ansi-green-fg\">return</span> candidates<span class=\"ansi-blue-fg\">,</span> aroma_score\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-7176e284-af06-40fc-ab93-e4b8a755b275/userFiles-e8ecb9fb-3024-4bea-a8e3-4cb2e829c1ab/addedFile3453741836193570924dbfs__FileStore_jars_b3d80b5a_617a_4ce0_81da_c4868ab12bac_icml18_jtnn_0_1_py3_7_3fd5e-aba95.egg/icml18_jtnn/fast_jtnn/chemutils.py</span> in <span class=\"ansi-cyan-fg\">check_aroma</span><span class=\"ansi-blue-fg\">(cand_mol, ctr_node, nei_nodes)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    319</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    320</span>     get_nid <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">0</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>is_leaf <span class=\"ansi-green-fg\">else</span> node<span class=\"ansi-blue-fg\">.</span>nid\n<span class=\"ansi-green-fg\">--&gt; 321</span><span class=\"ansi-red-fg\">     </span>benzynes <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>get_nid<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> nei_nodes <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">[</span>ctr_node<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>smiles <span class=\"ansi-green-fg\">in</span> Vocab<span class=\"ansi-blue-fg\">.</span>benzynes<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    322</span>     penzynes <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>get_nid<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> nei_nodes <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">[</span>ctr_node<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>smiles <span class=\"ansi-green-fg\">in</span> Vocab<span class=\"ansi-blue-fg\">.</span>penzynes<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    323</span>     <span class=\"ansi-green-fg\">if</span> len<span class=\"ansi-blue-fg\">(</span>benzynes<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">+</span> len<span class=\"ansi-blue-fg\">(</span>penzynes<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-7176e284-af06-40fc-ab93-e4b8a755b275/userFiles-e8ecb9fb-3024-4bea-a8e3-4cb2e829c1ab/addedFile3453741836193570924dbfs__FileStore_jars_b3d80b5a_617a_4ce0_81da_c4868ab12bac_icml18_jtnn_0_1_py3_7_3fd5e-aba95.egg/icml18_jtnn/fast_jtnn/chemutils.py</span> in <span class=\"ansi-cyan-fg\">&lt;listcomp&gt;</span><span class=\"ansi-blue-fg\">(.0)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    319</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    320</span>     get_nid <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">0</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>is_leaf <span class=\"ansi-green-fg\">else</span> node<span class=\"ansi-blue-fg\">.</span>nid\n<span class=\"ansi-green-fg\">--&gt; 321</span><span class=\"ansi-red-fg\">     </span>benzynes <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>get_nid<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> nei_nodes <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">[</span>ctr_node<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>smiles <span class=\"ansi-green-fg\">in</span> Vocab<span class=\"ansi-blue-fg\">.</span>benzynes<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    322</span>     penzynes <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>get_nid<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> nei_nodes <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">[</span>ctr_node<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>smiles <span class=\"ansi-green-fg\">in</span> Vocab<span class=\"ansi-blue-fg\">.</span>penzynes<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    323</span>     <span class=\"ansi-green-fg\">if</span> len<span class=\"ansi-blue-fg\">(</span>benzynes<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">+</span> len<span class=\"ansi-blue-fg\">(</span>penzynes<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-7176e284-af06-40fc-ab93-e4b8a755b275/userFiles-e8ecb9fb-3024-4bea-a8e3-4cb2e829c1ab/addedFile3453741836193570924dbfs__FileStore_jars_b3d80b5a_617a_4ce0_81da_c4868ab12bac_icml18_jtnn_0_1_py3_7_3fd5e-aba95.egg/icml18_jtnn/fast_jtnn/chemutils.py</span> in <span class=\"ansi-cyan-fg\">&lt;lambda&gt;</span><span class=\"ansi-blue-fg\">(x)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    318</span>     <span class=\"ansi-green-fg\">if</span> len<span class=\"ansi-blue-fg\">(</span>rings<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&lt;</span> <span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-green-fg\">return</span> <span class=\"ansi-cyan-fg\">0</span> <span class=\"ansi-red-fg\">#Only multi-ring system needs to be checked</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    319</span> \n<span class=\"ansi-green-fg\">--&gt; 320</span><span class=\"ansi-red-fg\">     </span>get_nid <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">0</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>is_leaf <span class=\"ansi-green-fg\">else</span> node<span class=\"ansi-blue-fg\">.</span>nid\n<span class=\"ansi-green-intense-fg ansi-bold\">    321</span>     benzynes <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>get_nid<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> nei_nodes <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">[</span>ctr_node<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>smiles <span class=\"ansi-green-fg\">in</span> Vocab<span class=\"ansi-blue-fg\">.</span>benzynes<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    322</span>     penzynes <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>get_nid<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> nei_nodes <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">[</span>ctr_node<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>smiles <span class=\"ansi-green-fg\">in</span> Vocab<span class=\"ansi-blue-fg\">.</span>penzynes<span class=\"ansi-blue-fg\">]</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;node&#39; is not defined</div>"]}}],"execution_count":61},{"cell_type":"code","source":["mol_tree = MolTree('CN(CC1CC(F)CN1S(N)(=O)=O)S(=O)(=O)N1CCCN(c2ncnc3[nH]ccc23)CC12CC2')\nmol_tree.recover()\n\nmol_tree.assemble()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1531239716267173&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> mol_tree<span class=\"ansi-blue-fg\">.</span>recover<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\"> </span>mol_tree<span class=\"ansi-blue-fg\">.</span>assemble<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-7176e284-af06-40fc-ab93-e4b8a755b275/userFiles-e8ecb9fb-3024-4bea-a8e3-4cb2e829c1ab/addedFile3453741836193570924dbfs__FileStore_jars_b3d80b5a_617a_4ce0_81da_c4868ab12bac_icml18_jtnn_0_1_py3_7_3fd5e-aba95.egg/icml18_jtnn/fast_jtnn/mol_tree.py</span> in <span class=\"ansi-cyan-fg\">assemble</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    101</span>     <span class=\"ansi-green-fg\">def</span> assemble<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    102</span>         <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>nodes<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 103</span><span class=\"ansi-red-fg\">             </span>node<span class=\"ansi-blue-fg\">.</span>assemble<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    104</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    105</span> <span class=\"ansi-green-fg\">def</span> dfs<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">,</span> fa_idx<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-7176e284-af06-40fc-ab93-e4b8a755b275/userFiles-e8ecb9fb-3024-4bea-a8e3-4cb2e829c1ab/addedFile3453741836193570924dbfs__FileStore_jars_b3d80b5a_617a_4ce0_81da_c4868ab12bac_icml18_jtnn_0_1_py3_7_3fd5e-aba95.egg/icml18_jtnn/fast_jtnn/mol_tree.py</span> in <span class=\"ansi-cyan-fg\">assemble</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     48</span>         neighbors <span class=\"ansi-blue-fg\">=</span> singletons <span class=\"ansi-blue-fg\">+</span> neighbors\n<span class=\"ansi-green-intense-fg ansi-bold\">     49</span> \n<span class=\"ansi-green-fg\">---&gt; 50</span><span class=\"ansi-red-fg\">         </span>cands<span class=\"ansi-blue-fg\">,</span>aroma <span class=\"ansi-blue-fg\">=</span> enum_assemble<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> neighbors<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     51</span>         new_cands <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>cand <span class=\"ansi-green-fg\">for</span> i<span class=\"ansi-blue-fg\">,</span>cand <span class=\"ansi-green-fg\">in</span> enumerate<span class=\"ansi-blue-fg\">(</span>cands<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">if</span> aroma<span class=\"ansi-blue-fg\">[</span>i<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">&gt;=</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     52</span>         <span class=\"ansi-green-fg\">if</span> len<span class=\"ansi-blue-fg\">(</span>new_cands<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span> cands <span class=\"ansi-blue-fg\">=</span> new_cands\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-7176e284-af06-40fc-ab93-e4b8a755b275/userFiles-e8ecb9fb-3024-4bea-a8e3-4cb2e829c1ab/addedFile3453741836193570924dbfs__FileStore_jars_b3d80b5a_617a_4ce0_81da_c4868ab12bac_icml18_jtnn_0_1_py3_7_3fd5e-aba95.egg/icml18_jtnn/fast_jtnn/chemutils.py</span> in <span class=\"ansi-cyan-fg\">enum_assemble</span><span class=\"ansi-blue-fg\">(node, neighbors, prev_nodes, prev_amap)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    297</span>         cand_smiles<span class=\"ansi-blue-fg\">.</span>add<span class=\"ansi-blue-fg\">(</span>smiles<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    298</span>         candidates<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span> <span class=\"ansi-blue-fg\">(</span>smiles<span class=\"ansi-blue-fg\">,</span>amap<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 299</span><span class=\"ansi-red-fg\">         </span>aroma_score<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span> check_aroma<span class=\"ansi-blue-fg\">(</span>cand_mol<span class=\"ansi-blue-fg\">,</span> node<span class=\"ansi-blue-fg\">,</span> neighbors<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    300</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    301</span>     <span class=\"ansi-green-fg\">return</span> candidates<span class=\"ansi-blue-fg\">,</span> aroma_score\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-7176e284-af06-40fc-ab93-e4b8a755b275/userFiles-e8ecb9fb-3024-4bea-a8e3-4cb2e829c1ab/addedFile3453741836193570924dbfs__FileStore_jars_b3d80b5a_617a_4ce0_81da_c4868ab12bac_icml18_jtnn_0_1_py3_7_3fd5e-aba95.egg/icml18_jtnn/fast_jtnn/chemutils.py</span> in <span class=\"ansi-cyan-fg\">check_aroma</span><span class=\"ansi-blue-fg\">(cand_mol, ctr_node, nei_nodes)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    319</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    320</span>     get_nid <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">0</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>is_leaf <span class=\"ansi-green-fg\">else</span> node<span class=\"ansi-blue-fg\">.</span>nid\n<span class=\"ansi-green-fg\">--&gt; 321</span><span class=\"ansi-red-fg\">     </span>benzynes <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>get_nid<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> nei_nodes <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">[</span>ctr_node<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>smiles <span class=\"ansi-green-fg\">in</span> Vocab<span class=\"ansi-blue-fg\">.</span>benzynes<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    322</span>     penzynes <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>get_nid<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> nei_nodes <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">[</span>ctr_node<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>smiles <span class=\"ansi-green-fg\">in</span> Vocab<span class=\"ansi-blue-fg\">.</span>penzynes<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    323</span>     <span class=\"ansi-green-fg\">if</span> len<span class=\"ansi-blue-fg\">(</span>benzynes<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">+</span> len<span class=\"ansi-blue-fg\">(</span>penzynes<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-7176e284-af06-40fc-ab93-e4b8a755b275/userFiles-e8ecb9fb-3024-4bea-a8e3-4cb2e829c1ab/addedFile3453741836193570924dbfs__FileStore_jars_b3d80b5a_617a_4ce0_81da_c4868ab12bac_icml18_jtnn_0_1_py3_7_3fd5e-aba95.egg/icml18_jtnn/fast_jtnn/chemutils.py</span> in <span class=\"ansi-cyan-fg\">&lt;listcomp&gt;</span><span class=\"ansi-blue-fg\">(.0)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    319</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    320</span>     get_nid <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">0</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>is_leaf <span class=\"ansi-green-fg\">else</span> node<span class=\"ansi-blue-fg\">.</span>nid\n<span class=\"ansi-green-fg\">--&gt; 321</span><span class=\"ansi-red-fg\">     </span>benzynes <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>get_nid<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> nei_nodes <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">[</span>ctr_node<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>smiles <span class=\"ansi-green-fg\">in</span> Vocab<span class=\"ansi-blue-fg\">.</span>benzynes<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    322</span>     penzynes <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>get_nid<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> nei_nodes <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">[</span>ctr_node<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>smiles <span class=\"ansi-green-fg\">in</span> Vocab<span class=\"ansi-blue-fg\">.</span>penzynes<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    323</span>     <span class=\"ansi-green-fg\">if</span> len<span class=\"ansi-blue-fg\">(</span>benzynes<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">+</span> len<span class=\"ansi-blue-fg\">(</span>penzynes<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-7176e284-af06-40fc-ab93-e4b8a755b275/userFiles-e8ecb9fb-3024-4bea-a8e3-4cb2e829c1ab/addedFile3453741836193570924dbfs__FileStore_jars_b3d80b5a_617a_4ce0_81da_c4868ab12bac_icml18_jtnn_0_1_py3_7_3fd5e-aba95.egg/icml18_jtnn/fast_jtnn/chemutils.py</span> in <span class=\"ansi-cyan-fg\">&lt;lambda&gt;</span><span class=\"ansi-blue-fg\">(x)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    318</span>     <span class=\"ansi-green-fg\">if</span> len<span class=\"ansi-blue-fg\">(</span>rings<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&lt;</span> <span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-green-fg\">return</span> <span class=\"ansi-cyan-fg\">0</span> <span class=\"ansi-red-fg\">#Only multi-ring system needs to be checked</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    319</span> \n<span class=\"ansi-green-fg\">--&gt; 320</span><span class=\"ansi-red-fg\">     </span>get_nid <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">0</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>is_leaf <span class=\"ansi-green-fg\">else</span> node<span class=\"ansi-blue-fg\">.</span>nid\n<span class=\"ansi-green-intense-fg ansi-bold\">    321</span>     benzynes <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>get_nid<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> nei_nodes <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">[</span>ctr_node<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>smiles <span class=\"ansi-green-fg\">in</span> Vocab<span class=\"ansi-blue-fg\">.</span>benzynes<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    322</span>     penzynes <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>get_nid<span class=\"ansi-blue-fg\">(</span>node<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> node <span class=\"ansi-green-fg\">in</span> nei_nodes <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">[</span>ctr_node<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">if</span> node<span class=\"ansi-blue-fg\">.</span>smiles <span class=\"ansi-green-fg\">in</span> Vocab<span class=\"ansi-blue-fg\">.</span>penzynes<span class=\"ansi-blue-fg\">]</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;node&#39; is not defined</div>"]}}],"execution_count":62},{"cell_type":"code","source":["from icml18_jtnn.fast_jtnn.chemutils import get_clique_mol, tree_decomp, get_mol, get_smiles, set_atommap, enum_assemble, decode_stereo\n\nsmiles = 'CN(CC1CC(F)CN1S(N)(=O)=O)S(=O)(=O)N1CCCN(c2ncnc3[nH]ccc23)CC12CC2'\n\nmol = get_mol(smiles)\ncliques, edges = tree_decomp(mol)\nfor i,c in enumerate(cliques):\n  cmol = get_clique_mol(mol, c)\n  print(MolTreeNode(get_smiles(cmol), c))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f405278&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f405a90&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f405a90&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f405a90&gt;\n&lt;icml18_jtnn.fast_jtnn.mol_tree.MolTreeNode object at 0x7fbf4f4057f0&gt;\n</div>"]}}],"execution_count":63},{"cell_type":"code","source":["full_internal['Isomeric_canon'].str.contains('@').any()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[25]: False\n</div>"]}}],"execution_count":64},{"cell_type":"code","source":["%run -m icml18_jtnn.fast_jtnn.mol_tree -i "],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["%sh pip freeze"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">absl-py==0.6.1\nasn1crypto==0.24.0\nastor==0.7.1\nbackports-abc==0.5\nbackports.functools-lru-cache==1.5\nbackports.shutil-get-terminal-size==1.0.0\nbackports.weakref==1.0.post1\nbcrypt==3.1.5\nbleach==2.1.3\nboto==2.48.0\nboto3==1.7.62\nbotocore==1.10.62\ncertifi==2018.4.16\ncffi==1.11.5\nchardet==3.0.4\ncloudpickle==0.5.3\ncolorama==0.3.9\nconfigparser==3.5.0\ncryptography==2.2.2\ncycler==0.10.0\nCython==0.28.2\ndecorator==4.3.0\ndocutils==0.14\nentrypoints==0.2.3\nenum34==1.1.6\net-xmlfile==1.0.1\nfuncsigs==1.0.2\nfunctools32==3.2.3.post2\nfusepy==2.0.4\nfutures==3.2.0\ngast==0.2.0\ngrpcio==1.12.1\nh5py==2.8.0\nhorovod==0.15.2\nhtml5lib==1.0.1\nidna==2.6\nipaddress==1.0.22\nipython==5.7.0\nipython-genutils==0.2.0\njdcal==1.4\nJinja2==2.10\njmespath==0.9.3\njsonschema==2.6.0\njupyter-client==5.2.3\njupyter-core==4.4.0\nKeras==2.2.4\nKeras-Applications==1.0.6\nKeras-Preprocessing==1.0.5\nkiwisolver==1.0.1\nlinecache2==1.0.0\nllvmlite==0.23.1\nlxml==4.2.1\nMarkdown==3.0.1\nMarkupSafe==1.0\nmatplotlib==2.2.2\nmistune==0.8.3\nmleap==0.8.1\nmock==2.0.0\nmsgpack==0.5.6\nnbconvert==5.3.1\nnbformat==4.4.0\nnose==1.3.7\nnose-exclude==0.5.0\nnumba==0.38.0+0.g2a2b772fc.dirty\nnumpy==1.14.3\nolefile==0.45.1\nopenpyxl==2.5.3\npandas==0.23.0\npandocfilters==1.4.2\nparamiko==2.4.1\npathlib2==2.3.2\npatsy==0.5.0\npbr==5.1.1\npexpect==4.5.0\npickleshare==0.7.4\nPillow==5.1.0\nply==3.11\nprompt-toolkit==1.0.15\nprotobuf==3.6.1\npsycopg2==2.7.5\nptyprocess==0.5.2\npyarrow==0.8.0\npyasn1==0.4.4\npycparser==2.18\nPygments==2.2.0\nPyNaCl==1.3.0\npyOpenSSL==18.0.0\npyparsing==2.2.0\nPySocks==1.6.8\npython-dateutil==2.7.3\npytz==2018.4\nPyYAML==3.12\npyzmq==17.0.0\nrequests==2.18.4\ns3transfer==0.1.13\nscandir==1.7\nscikit-learn==0.19.1\nscipy==1.1.0\nseaborn==0.8.1\nsimplegeneric==0.8.1\nsingledispatch==3.4.0.3\nsix==1.11.0\nstatsmodels==0.9.0\nsubprocess32==3.5.3\ntensorboard==1.12.2\ntensorboardX==1.4\ntensorflow==1.12.0\ntermcolor==1.1.0\ntestpath==0.3.1\ntorch==0.4.1\ntorchvision==0.2.1\ntornado==5.0.2\ntraceback2==1.4.0\ntraitlets==4.3.2\nunittest2==1.1.0\nurllib3==1.22\nvirtualenv==16.0.0\nwcwidth==0.1.7\nwebencodings==0.5.1\nWerkzeug==0.14.1\nwrapt==1.10.11\n</div>"]}}],"execution_count":66}],"metadata":{"name":"JT_VAE","notebookId":2687669254791636},"nbformat":4,"nbformat_minor":0}

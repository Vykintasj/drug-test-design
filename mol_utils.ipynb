{"cells":[{"cell_type":"code","source":["from argparse import ArgumentParser, Namespace\nimport os\nimport glob\nimport gzip\nimport numpy as np\nimport pandas as pd\nimport pickle, sys\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom rdkit.Chem import DataStructs\nfrom rdkit.Chem import PandasTools\n#from rdkit.ML.Cluster import Butina\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.manifold import MDS\nfrom sklearn.manifold import Isomap\nfrom sklearn.manifold import TSNE\nimport sklearn.feature_extraction\nfrom sklearn.feature_selection import VarianceThreshold\nimport threading\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nimport pubchempy as pcp\nfrom boruta import boruta_py\nfrom mordred import Calculator, descriptors\nimport umap"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["def getMorganAsDict(mol,size=2):\n    d = {}\n    d.update(AllChem.GetMorganFingerprint(mol,size).GetNonzeroElements())\n    return d\n  \ndef get_fps(drugs, morgan=False, bit=False,size=2):\n    fps=[]\n    errors = 0\n    for moli in range(len(drugs)):\n        try:\n            mol = drugs[moli]\n            if morgan:\n                d = getMorganAsDict(mol,size)\n            elif bit:\n                d = AllChem.GetMorganFingerprintAsBitVect(mol,size,nBits=2048)\n            else:\n                d = Chem.RDKFingerprint(mol)\n            fps.append(d)\n        except:\n            errors+=1\n    print('Errors in conversion:',errors)\n    return fps\n  \ndef fps_distances(fps):\n    dist_mat = []\n    for i,fp in enumerate(fps):\n        try:\n            dist_mat.append(DataStructs.BulkTanimotoSimilarity(fps[i],fps,returnDistance=1))\n        except:\n            print('Failed molecule nr:',i)\n            continue\n    return np.array(dist_mat)\n  \ndef fps_similarities(fps):\n    dist_mat = []\n    for i,fp in enumerate(fps):\n        try:\n            dist_mat.append(DataStructs.BulkTanimotoSimilarity(fps[i],fps,returnDistance=False))\n        except:\n            print('Failed molecule nr:',i)\n            continue\n    return np.array(dist_mat)\n\ndef get_embedding(model, components, adist):\n    if model == 'mds':\n        print('Selected transformation: MDS')\n        mds = MDS(n_components=components, dissimilarity=\"precomputed\", random_state=6)\n        results = mds.fit(adist)\n        coords = results.embedding_\n    if model == 'isomap':\n        print('Selected transformation: IsoMap')\n        iso = Isomap(n_components=components, random_state=6)\n        coords = iso.fit_transform(adist)\n        #coords = results.embedding_\n    if model == 'tsne':\n        print('Selected transformation: T-SNE')\n        tsne = TSNE(n_components=components, verbose=1, perplexity=40, n_iter=300, random_state = 158984,metric='precomputed')\n        coords = tsne.fit_transform(adist)\n    if model == 'pca':\n        print('Selected transformation: PCA')\n        pca = PCA(n_components=components, random_state=6)\n        coords = pca.fit_transform(adist)\n    if model == 'pls':\n        print('Selected transformation: PLS')\n        pls = PLSRegression(n_components=components, random_state=6)\n        coords = pls.fit_transform(adist)\n    if model=='umap':\n        print('Selected transformation: UMAP')\n        print('Selected transformation: MDS')\n        mds = MDS(n_components=adist.shape()[0], dissimilarity=\"precomputed\", random_state=6)\n        results = mds.fit(adist)\n        adist = results.embedding_\n        umap_ = umap.UMAP(n_neighbors=5, min_dist=0.3, n_components=components)\n        coords = umap_.fit_transform(adist)\n    return coords\n\ndef plot_transformation_2D(coords, coloring=None, figure=None, scale=None, color_correction=None,marker='.',s=None):\n    if figure:\n        fig, ax = figure\n    else:\n        fig = plt.figure(figsize = (8,8))\n        ax = fig.add_subplot(111)\n        ax.set_aspect('equal',adjustable='box')\n\n    if coloring is not None:\n        if scale == 'log':\n            coloring = np.log10(np.array(coloring).astype(float))\n        if scale == 'p':\n            coloring = -np.log10(np.array(coloring).astype(float)*1e-9)\n        coloring = np.around(np.array(coloring).astype(float), decimals = 1)\n        #ax.scatter(coords[trainsize:, 0], coords[trainsize:, 1], marker = '.', c=gensize#,cmap=colors.Colormap('jet'))\n        if color_correction is not None:\n            norm = colors.Normalize(vmin=color_correction[0],vmax=color_correction[1])\n        sc = ax.scatter(coords[:, 0], \n                        coords[:, 1], \n                        marker = marker, \n                        c=coloring, \n                        cmap=plt.get_cmap('jet'), \n                        norm=norm, s=s\n                  )\n    else:\n        ax.scatter(coords[:, 0], \n                   coords[:, 1], \n                   marker = marker, \n                   c='k',s=s\n                )\n        #plt.colorbar(sc)\n    return fig, ax, sc\n\ndef external_prep(incsv, insdf):\n    ext_df = pd.read_csv(incsv)\n    ext_sdf = Chem.ForwardSDMolSupplier(gzip.open(insdf))\n    ext_mols = [x for x in ext_sdf if x is not None]\n    ext_mol_df = pd.DataFrame({'Molecule':ext_mols,\n                               'cid':[int(mol.GetProp('PUBCHEM_COMPOUND_CID')) for mol in ext_mols]})\n    ext_mol_df.drop_duplicates(subset='cid', inplace=True)\n    ext_mol_df.reset_index(drop=True, inplace=True)\n    ext_df = ext_df.merge(ext_mol_df, on='cid', how='inner')\n    return ext_df\n  \ndef ClusterFps(fps,cutoff=0.2):\n    from rdkit import DataStructs\n    from rdkit.ML.Cluster import Butina\n\n    # first generate the distance matrix:\n    dists = []\n    nfps = len(fps)\n    for i in range(1,nfps):\n        sims = DataStructs.BulkTanimotoSimilarity(fps[i],fps[:i])\n        dists.extend([1-x for x in sims])\n\n    # now cluster the data:\n    cs = Butina.ClusterData(dists,nfps,cutoff,isDistData=True)\n    return cs\n  \n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["def moses_parser_train():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(\n        title='Models trainer script', description='available models'\n    )\n    for model in MODELS.get_model_names():\n        add_train_args(\n            MODELS.get_model_train_parser(model)(\n                subparsers.add_parser(model)\n            )\n        )\n    return parser\ndef moses_train(model, config, model_state = None):\n    set_seed(config.seed)\n    device = torch.device(config.device)\n\n    if config.config_save is not None:\n        torch.save(config, config.config_save)\n\n    # For CUDNN to work properly\n    if device.type.startswith('cuda'):\n        torch.cuda.set_device(device.index or 0)\n\n    train_data = read_smiles_csv(config.train_load)\n    if config.val_load:\n        val_data = read_smiles_csv(config.val_load)\n    else:\n        val_data = None\n    trainer = MODELS.get_model_trainer(model)(config)\n\n    if config.vocab_load is not None:\n        assert os.path.exists(config.vocab_load), \\\n            'vocab_load path does not exist!'\n        vocab = torch.load(config.vocab_load)\n    else:\n        vocab = trainer.get_vocabulary(train_data)\n\n    if config.vocab_save is not None:\n        torch.save(vocab, config.vocab_save)\n    \n    model = MODELS.get_model_class(model)(vocab, config)\n    #print(model)\n    if model_state:\n      model.load_state_dict(model_state)\n#       model_config = torch.load(config.config_load)\n#     model_vocab = torch.load(config.vocab_load)\n#     model_state = torch.load(config.model_load)\n\n#     model = MODELS.get_model_class(model)(model_vocab, model_config)\n#     model.load_state_dict(model_state)\n#     model = model.to(device)\n    \n    #print(model)\n    model = model.to(device)\n    model.eval()\n    trainer.fit(model, train_data, val_data)\n    \n    model = model.to('cpu')\n    torch.save(model.state_dict(), config.model_save)\ndef moses_parser_generate():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(\n        title='Models sampler script', description='available models')\n    for model in MODELS.get_model_names():\n        add_sample_args(subparsers.add_parser(model))\n    return parser\ndef moses_generate(model, config):\n    set_seed(config.seed)\n    device = torch.device(config.device)\n\n    # For CUDNN to work properly:\n    if device.type.startswith('cuda'):\n        torch.cuda.set_device(device.index or 0)\n\n    model_config = torch.load(config.config_load)\n    model_vocab = torch.load(config.vocab_load)\n    model_state = torch.load(config.model_load)\n\n    model = MODELS.get_model_class(model)(model_vocab, model_config)\n    model.load_state_dict(model_state)\n    model = model.to(device)\n    model.eval()\n\n    samples = []\n    n = config.n_samples\n    with tqdm(total=config.n_samples, desc='Generating samples') as T:\n        while n > 0:\n            current_samples = model.sample(\n                min(n, config.n_batch), config.max_len\n            )\n            samples.extend(current_samples)\n\n            n -= len(current_samples)\n            T.update(len(current_samples))\n\n    samples = pd.DataFrame(samples, columns=['SMILES'])\n    samples.to_csv(config.gen_save, index=False)\ndef moses_parser_eval():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--test_path',\n                        type=str, required=True,\n                        help='Path to test molecules csv')\n    parser.add_argument('--test_scaffolds_path',\n                        type=str, required=False,\n                        help='Path to scaffold test molecules csv')\n    parser.add_argument('--gen_path',\n                        type=str, required=True,\n                        help='Path to generated molecules csv')\n    parser.add_argument('--ks',\n                        nargs='+', default=[1000, 10000],\n                        help='Prefixes to calc uniqueness at')\n    parser.add_argument('--n_jobs',\n                        type=int, default=1,\n                        help='Number of processes to run metrics')\n    parser.add_argument('--device',\n                        type=str, default='cpu',\n                        help='GPU device id (`cpu` or `cuda:n`)')\n\n    return parser\ndef moses_evaluate(config, print_metrics=True):\n    test = read_smiles_csv(config.test_path)\n    test_scaffolds = None\n    ptest = None\n    ptest_scaffolds = None\n    if config.test_scaffolds_path is not None:\n        test_scaffolds = read_smiles_csv(config.test_scaffolds_path)\n    gen = read_smiles_csv(config.gen_path)\n    metrics = get_all_metrics(test, gen, k=config.ks, n_jobs=config.n_jobs,\n                              device=config.device,\n                              test_scaffolds=test_scaffolds,\n                              ptest=ptest, ptest_scaffolds=ptest_scaffolds)\n\n    if print_metrics:\n        for name, value in metrics.items():\n            print('{},{}'.format(name, value))\n    else:\n        return metrics"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["def chemprop_grid_search(args: Namespace):\n    # Create loggers\n    logger = create_logger(name='hyperparameter_optimization', save_dir=args.log_dir, quiet=True)\n    train_logger = create_logger(name='train', save_dir=args.save_dir, quiet=args.quiet)\n\n    # Run grid search\n    results = []\n\n    # Define hyperparameter optimization\n    def objective(hyperparams: Dict[str, Union[int, float]]) -> float:\n        # Convert hyperparams from float to int when necessary\n        for key in INT_KEYS:\n            hyperparams[key] = int(hyperparams[key])\n\n        # Update args with hyperparams\n        hyper_args = deepcopy(args)\n        if args.save_dir is not None:\n            folder_name = '_'.join(f'{key}_{value}' for key, value in hyperparams.items())\n            hyper_args.save_dir = os.path.join(hyper_args.save_dir, folder_name)\n        for key, value in hyperparams.items():\n            setattr(hyper_args, key, value)\n\n        # Record hyperparameters\n        logger.info(hyperparams)\n\n        # Cross validate\n        mean_score, std_score = cross_validate(hyper_args, train_logger)\n\n        # Record results\n        temp_model = build_model(hyper_args)\n        num_params = param_count(temp_model)\n        logger.info(f'num params: {num_params:,}')\n        logger.info(f'{mean_score} +/- {std_score} {hyper_args.metric}')\n\n        results.append({\n            'mean_score': mean_score,\n            'std_score': std_score,\n            'hyperparams': hyperparams,\n            'num_params': num_params\n        })\n\n        # Deal with nan\n        if np.isnan(mean_score):\n            if hyper_args.dataset_type == 'classification':\n                mean_score = 0\n            else:\n                raise ValueError('Can\\'t handle nan score for non-classification dataset.')\n\n        return (1 if hyper_args.minimize_score else -1) * mean_score\n\n    fmin(objective, SPACE, algo=tpe.suggest, max_evals=args.num_iters)\n\n    # Report best result\n    results = [result for result in results if not np.isnan(result['mean_score'])]\n    best_result = min(results, key=lambda result: (1 if args.minimize_score else -1) * result['mean_score'])\n    logger.info('best')\n    logger.info(best_result['hyperparams'])\n    logger.info(f'num params: {best_result[\"num_params\"]:,}')\n    logger.info(f'{best_result[\"mean_score\"]} +/- {best_result[\"std_score\"]} {args.metric}')\n\n    # Save best hyperparameter settings as JSON config file\n    makedirs(args.config_save_path, isfile=True)\n\n    with open(args.config_save_path, 'w') as f:\n        json.dump(best_result['hyperparams'], f, indent=4, sort_keys=True)"],"metadata":{},"outputs":[],"execution_count":4}],"metadata":{"name":"mol_utils","notebookId":2588730331001674},"nbformat":4,"nbformat_minor":0}

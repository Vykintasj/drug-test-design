{"cells":[{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nimport pickle, sys, csv, gzip, glob, os, threading\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom rdkit.Chem import DataStructs\nfrom rdkit.Chem import PandasTools\nimport sklearn.feature_extraction\nfrom sklearn.feature_selection import VarianceThreshold \nfrom sklearn.metrics import roc_auc_score\nfrom boruta import boruta_py\nfrom mordred import Calculator, descriptors\nfrom timeit import default_timer as timer\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier\nfrom collections import defaultdict\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import explained_variance_score\nfrom hyperopt import hp\nfrom hyperopt.pyll.stochastic import sample\nfrom pyspark import SparkContext, SparkConf\nfrom spark_sklearn import GridSearchCV\nfrom sklearn import cross_validation, metrics   \nimport matplotlib.pylab as plt\nfrom matplotlib.pylab import rcParams\nfrom hyperopt import STATUS_OK\nfrom timeit import default_timer as timer\nimport lightgbm as lgb\nfrom hyperopt import tpe\nfrom hyperopt import Trials\nfrom hyperopt import fmin\nfrom sklearn.model_selection import KFold"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["datasets = [\"Homopiperazines\",\"Piperazines\",\"Piperidines\",\"Sulphamides\"]\nnames = [\"JAK1 EC50 nM 1027\",\"JAK2 EC50 nM 1024\",\"JAK3 EC50 nM 1026\"]\nnames = names + ['TYK2 EC50 nM 1025']\nfiles = [\"/dbfs/FileStore/tables/Homopiperazines_cleaned_Feb_2019.sdf\",\n         \"/dbfs/FileStore/tables/Piperazines_cleaned_Feb_2019.sdf\",\n         \"/dbfs/FileStore/tables/Piperidines_cleaned_Feb_2019.sdf\",\n         \"/dbfs/FileStore/tables/Sulphamides_cleaned_Feb_2019.sdf\",\n        ]\nPARENT_DIR = '/dbfs/FileStore/tables'\nPICKLES_DIR = '/dbfs/FileStore/pickles'\nMOSES_DIR = '/dbfs/FileStore/moses'\nCHEMPROP_DIR = '/dbfs/FileStore/chemprop'\nXGB_DIR = '/dbfs/FileStore/XGB-Hopt/'\ntargets=['JAK1','JAK2','JAK3','TYK2']\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["def getMorganAsDict(mol):\n    d = {}\n    d.update(AllChem.GetMorganFingerprint(mol,2).GetNonzeroElements())\n    return d\ndef get_fps(drugs, morgan=False, bit=False):\n    fps=[]\n    errors = 0\n    for moli in range(len(drugs)):\n        try:\n            mol = drugs[moli]\n            if morgan:\n                d = getMorganAsDict(mol)\n            elif bit:\n                d = AllChem.GetMorganFingerprintAsBitVect(mol,2,nBits=2048)\n            else:\n                d = Chem.RDKFingerprint(mol)\n            fps.append(d)\n        except:\n            errors+=1\n    print('Errors in conversion:',errors)\n    return fps"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["# Classification Hyperparameter Optimization"],"metadata":{}},{"cell_type":"code","source":["Train_4y = pd.read_csv(os.path.join(CHEMPROP_DIR,'JAK','train-1460_bin76.csv'))\nVal_4y = pd.read_csv(os.path.join(CHEMPROP_DIR,'JAK','val-182_bin76.csv'))\nTest_4y = pd.read_csv(os.path.join(CHEMPROP_DIR,'JAK','test-183_bin76.csv'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["All_4y = Train_4y.append(Val_4y).append(Test_4y)\nall_fps = [Chem.MolFromSmiles(smi) for smi in All_4y['smiles']]\nfps = get_fps(all_fps, morgan=True)\nv = sklearn.feature_extraction.DictVectorizer(sparse=True, dtype=float)\nv.fit(fps)\nprint(len(v.feature_names_))\nprint(len(v.vocabulary_))\n\nX = v.transform(fps)\n\nX = X.toarray()\nTrain_X = X[:1460]\nVal_X = X[1460:1460+182]\nTest_X = X[1460+182:1460+182+183]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Errors in conversion: 0\n3689\n3689\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["Train_X = np.concatenate((Train_X,Val_X))\nTrain_4y = Train_4y.append(Val_4y)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["\ntpe_algorithm = tpe.suggest\nbayes_trials = Trials()\niter=0\nMAX_EVALS = 100\nN_FOLDS = 10\ndef objective(params, n_folds = N_FOLDS):\n    global iter\n    iter += 1\n    \n    subsample = params['boosting_type'].get('subsample', 1.0)\n    \n    params['boosting_type'] = params['boosting_type']['boosting_type']\n    params['subsample'] = subsample\n    \n    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n        params[parameter_name] = int(params[parameter_name])\n    \n    start = timer()\n    \n    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, nfold = n_folds, \n                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n    \n    run_time = timer() - start\n    \n    best_score = np.max(cv_results['auc-mean'])\n    \n    loss = 1 - best_score\n    \n    n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n\n    logfile = open(out_file, 'a')\n    writer = csv.writer(logfile)\n    writer.writerow([loss, params, iter, n_estimators, run_time])\n    \n    return {'loss': loss, 'params': params, 'iteration': iter,\n            'estimators': n_estimators, \n            'train_time': run_time, 'status': STATUS_OK}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["# Define the search space\nspace = {\n    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n                                                 {'boosting_type': 'goss', 'subsample': 1.0}]),\n    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n}\n\nout_file = os.path.join(XGB_DIR,'gbm_trials_binary.csv')\nlogfile = open(out_file, 'w')\nwriter = csv.writer(logfile)\n\nwriter.writerow(['loss', 'params', 'iteration', 'estimators', 'train_time'])\nlogfile.close()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["global iter\niter=0\nlgbmodel = lgb.LGBMClassifier()\ntrain_set = lgb.Dataset(Train_X, label = Train_4y[targets[0]])\n# Run optimization\nbest = fmin(fn = objective, space = space, algo = tpe.suggest, \n            max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(13))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\r  0%|          | 0/100 [00:00&lt;?, ?it/s, best loss: ?]\r  1%|          | 1/100 [00:05&lt;09:41,  5.87s/it, best loss: 0.08996395691466108]\r  2%|▏         | 2/100 [00:09&lt;08:19,  5.09s/it, best loss: 0.08996395691466108]\r  3%|▎         | 3/100 [00:09&lt;05:59,  3.70s/it, best loss: 0.08996395691466108]\r  4%|▍         | 4/100 [00:13&lt;05:48,  3.63s/it, best loss: 0.08996395691466108]\r  5%|▌         | 5/100 [00:13&lt;04:19,  2.73s/it, best loss: 0.08996395691466108]\r  6%|▌         | 6/100 [00:20&lt;06:19,  4.04s/it, best loss: 0.08996395691466108]\r  7%|▋         | 7/100 [00:30&lt;08:56,  5.77s/it, best loss: 0.08996395691466108]\r  8%|▊         | 8/100 [00:34&lt;08:09,  5.32s/it, best loss: 0.08996395691466108]\r  9%|▉         | 9/100 [00:35&lt;05:50,  3.86s/it, best loss: 0.08996395691466108]\r 10%|█         | 10/100 [00:41&lt;06:56,  4.63s/it, best loss: 0.08996395691466108]\r 11%|█         | 11/100 [00:45&lt;06:22,  4.30s/it, best loss: 0.08996395691466108]\r 12%|█▏        | 12/100 [00:50&lt;06:31,  4.45s/it, best loss: 0.08996395691466108]\r 13%|█▎        | 13/100 [00:51&lt;05:19,  3.67s/it, best loss: 0.08996395691466108]\r 14%|█▍        | 14/100 [00:52&lt;03:51,  2.70s/it, best loss: 0.08996395691466108]\r 15%|█▌        | 15/100 [00:54&lt;03:36,  2.55s/it, best loss: 0.08646747099211893]\r 16%|█▌        | 16/100 [00:56&lt;03:27,  2.47s/it, best loss: 0.08646747099211893]\r 17%|█▋        | 17/100 [01:03&lt;04:57,  3.58s/it, best loss: 0.08623936260203868]\r 18%|█▊        | 18/100 [01:11&lt;06:46,  4.95s/it, best loss: 0.08623936260203868]\r 19%|█▉        | 19/100 [01:11&lt;04:56,  3.66s/it, best loss: 0.08623936260203868]\r 20%|██        | 20/100 [01:15&lt;04:49,  3.62s/it, best loss: 0.08623936260203868]\r 21%|██        | 21/100 [01:28&lt;08:24,  6.39s/it, best loss: 0.08409435139364729]\r 22%|██▏       | 22/100 [01:39&lt;10:10,  7.83s/it, best loss: 0.0825135311367704] \r 23%|██▎       | 23/100 [01:48&lt;10:34,  8.25s/it, best loss: 0.0825135311367704]\r 24%|██▍       | 24/100 [02:01&lt;12:21,  9.76s/it, best loss: 0.0825135311367704]\r 25%|██▌       | 25/100 [02:13&lt;12:49, 10.26s/it, best loss: 0.0825135311367704]\r 26%|██▌       | 26/100 [02:14&lt;09:17,  7.54s/it, best loss: 0.0825135311367704]\r 27%|██▋       | 27/100 [02:24&lt;10:08,  8.33s/it, best loss: 0.0825135311367704]\r 28%|██▊       | 28/100 [02:34&lt;10:23,  8.66s/it, best loss: 0.0825135311367704]\r 29%|██▉       | 29/100 [02:39&lt;08:56,  7.55s/it, best loss: 0.0825135311367704]\r 30%|███       | 30/100 [02:40&lt;06:46,  5.81s/it, best loss: 0.0825135311367704]\r 31%|███       | 31/100 [02:49&lt;07:50,  6.82s/it, best loss: 0.0825135311367704]\r 32%|███▏      | 32/100 [03:02&lt;09:40,  8.54s/it, best loss: 0.0825135311367704]\r 33%|███▎      | 33/100 [03:16&lt;11:21, 10.17s/it, best loss: 0.0825135311367704]\r 34%|███▍      | 34/100 [03:17&lt;08:05,  7.35s/it, best loss: 0.0825135311367704]\r 35%|███▌      | 35/100 [03:20&lt;06:36,  6.09s/it, best loss: 0.0825135311367704]\r 36%|███▌      | 36/100 [03:31&lt;08:03,  7.56s/it, best loss: 0.0825135311367704]\r 37%|███▋      | 37/100 [03:32&lt;05:55,  5.64s/it, best loss: 0.0825135311367704]\r 38%|███▊      | 38/100 [03:41&lt;06:49,  6.60s/it, best loss: 0.0825135311367704]\r 39%|███▉      | 39/100 [03:51&lt;07:49,  7.70s/it, best loss: 0.0825135311367704]\r 40%|████      | 40/100 [03:57&lt;07:14,  7.23s/it, best loss: 0.0825135311367704]\r 41%|████      | 41/100 [03:58&lt;05:08,  5.23s/it, best loss: 0.0825135311367704]\r 42%|████▏     | 42/100 [04:05&lt;05:28,  5.66s/it, best loss: 0.0825135311367704]\r 43%|████▎     | 43/100 [04:16&lt;07:03,  7.42s/it, best loss: 0.0825135311367704]\r 44%|████▍     | 44/100 [04:19&lt;05:47,  6.21s/it, best loss: 0.0825135311367704]\r 45%|████▌     | 45/100 [04:20&lt;04:06,  4.48s/it, best loss: 0.0825135311367704]\r 46%|████▌     | 46/100 [04:35&lt;06:49,  7.58s/it, best loss: 0.0825135311367704]\r 47%|████▋     | 47/100 [04:40&lt;06:12,  7.03s/it, best loss: 0.0825135311367704]\r 48%|████▊     | 48/100 [04:53&lt;07:27,  8.60s/it, best loss: 0.0825135311367704]\r 49%|████▉     | 49/100 [04:56&lt;05:52,  6.91s/it, best loss: 0.0825135311367704]\r 50%|█████     | 50/100 [05:07&lt;06:53,  8.27s/it, best loss: 0.0825135311367704]\r 51%|█████     | 51/100 [05:12&lt;05:58,  7.31s/it, best loss: 0.0825135311367704]\r 52%|█████▏    | 52/100 [05:18&lt;05:24,  6.76s/it, best loss: 0.0825135311367704]\r 53%|█████▎    | 53/100 [05:19&lt;04:03,  5.18s/it, best loss: 0.0825135311367704]\r 54%|█████▍    | 54/100 [05:25&lt;04:05,  5.33s/it, best loss: 0.0825135311367704]\r 55%|█████▌    | 55/100 [05:28&lt;03:35,  4.78s/it, best loss: 0.0825135311367704]\r 56%|█████▌    | 56/100 [05:35&lt;03:58,  5.41s/it, best loss: 0.0825135311367704]\r 57%|█████▋    | 57/100 [05:48&lt;05:26,  7.59s/it, best loss: 0.0825135311367704]\r 58%|█████▊    | 58/100 [05:48&lt;03:47,  5.42s/it, best loss: 0.0825135311367704]\r 59%|█████▉    | 59/100 [05:52&lt;03:25,  5.01s/it, best loss: 0.0825135311367704]\r 60%|██████    | 60/100 [06:03&lt;04:25,  6.63s/it, best loss: 0.0825135311367704]\r 61%|██████    | 61/100 [06:09&lt;04:15,  6.54s/it, best loss: 0.0825135311367704]\r 62%|██████▏   | 62/100 [06:10&lt;02:59,  4.73s/it, best loss: 0.0825135311367704]\r 63%|██████▎   | 63/100 [06:16&lt;03:09,  5.12s/it, best loss: 0.0825135311367704]\r 64%|██████▍   | 64/100 [06:25&lt;03:48,  6.35s/it, best loss: 0.0825135311367704]\r 65%|██████▌   | 65/100 [06:28&lt;03:07,  5.36s/it, best loss: 0.0825135311367704]\r 66%|██████▌   | 66/100 [06:46&lt;05:07,  9.05s/it, best loss: 0.0825135311367704]\r 67%|██████▋   | 67/100 [06:59&lt;05:44, 10.44s/it, best loss: 0.0825135311367704]\r 68%|██████▊   | 68/100 [07:15&lt;06:27, 12.10s/it, best loss: 0.0825135311367704]\r 69%|██████▉   | 69/100 [07:31&lt;06:53, 13.32s/it, best loss: 0.0825135311367704]\r 70%|███████   | 70/100 [07:53&lt;07:52, 15.74s/it, best loss: 0.0825135311367704]\r 71%|███████   | 71/100 [08:01&lt;06:34, 13.60s/it, best loss: 0.0825135311367704]\r 72%|███████▏  | 72/100 [08:13&lt;06:07, 13.11s/it, best loss: 0.0825135311367704]\r 73%|███████▎  | 73/100 [08:30&lt;06:20, 14.08s/it, best loss: 0.0825135311367704]\r 74%|███████▍  | 74/100 [08:39&lt;05:30, 12.71s/it, best loss: 0.0825135311367704]\r 75%|███████▌  | 75/100 [08:51&lt;05:08, 12.36s/it, best loss: 0.0825135311367704]\r 76%|███████▌  | 76/100 [09:02&lt;04:46, 11.93s/it, best loss: 0.0825135311367704]\r 77%|███████▋  | 77/100 [09:03&lt;03:23,  8.83s/it, best loss: 0.0825135311367704]\r 78%|███████▊  | 78/100 [09:16&lt;03:42, 10.11s/it, best loss: 0.0825135311367704]\r 79%|███████▉  | 79/100 [09:26&lt;03:28,  9.94s/it, best loss: 0.0825135311367704]\r 80%|████████  | 80/100 [09:40&lt;03:42, 11.11s/it, best loss: 0.0825135311367704]\r 81%|████████  | 81/100 [09:41&lt;02:36,  8.26s/it, best loss: 0.0825135311367704]\r 82%|████████▏ | 82/100 [09:43&lt;01:51,  6.19s/it, best loss: 0.0825135311367704]\r 83%|████████▎ | 83/100 [09:52&lt;02:01,  7.12s/it, best loss: 0.0825135311367704]\r 84%|████████▍ | 84/100 [10:12&lt;02:56, 11.06s/it, best loss: 0.0825135311367704]\r 85%|████████▌ | 85/100 [10:16&lt;02:13,  8.91s/it, best loss: 0.0825135311367704]\r 86%|████████▌ | 86/100 [10:17&lt;01:29,  6.40s/it, best loss: 0.0825135311367704]\r 87%|████████▋ | 87/100 [10:26&lt;01:35,  7.36s/it, best loss: 0.0825135311367704]\r 88%|████████▊ | 88/100 [10:31&lt;01:19,  6.60s/it, best loss: 0.0825135311367704]\r 89%|████████▉ | 89/100 [10:39&lt;01:15,  6.88s/it, best loss: 0.0825135311367704]\r 90%|█████████ | 90/100 [10:51&lt;01:24,  8.48s/it, best loss: 0.0825135311367704]\r 91%|█████████ | 91/100 [10:51&lt;00:54,  6.06s/it, best loss: 0.0825135311367704]\r 92%|█████████▏| 92/100 [11:08&lt;01:13,  9.18s/it, best loss: 0.0825135311367704]\r 93%|█████████▎| 93/100 [11:10&lt;00:49,  7.01s/it, best loss: 0.0825135311367704]\r 94%|█████████▍| 94/100 [11:21&lt;00:50,  8.42s/it, best loss: 0.0825135311367704]\r 95%|█████████▌| 95/100 [11:22&lt;00:30,  6.02s/it, best loss: 0.0825135311367704]\r 96%|█████████▌| 96/100 [11:36&lt;00:33,  8.49s/it, best loss: 0.0825135311367704]\r 97%|█████████▋| 97/100 [11:45&lt;00:25,  8.57s/it, best loss: 0.0825135311367704]\r 98%|█████████▊| 98/100 [11:55&lt;00:17,  8.98s/it, best loss: 0.0825135311367704]\r 99%|█████████▉| 99/100 [12:06&lt;00:09,  9.53s/it, best loss: 0.0825135311367704]\r100%|██████████| 100/100 [12:06&lt;00:00,  6.81s/it, best loss: 0.0825135311367704]\r100%|██████████| 100/100 [12:06&lt;00:00,  7.27s/it, best loss: 0.0825135311367704]\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["best"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[15]: \n{&#39;boosting_type&#39;: 0,\n &#39;class_weight&#39;: 0,\n &#39;colsample_by_tree&#39;: 0.8521732607849484,\n &#39;gdbt_subsample&#39;: 0.6680712282914405,\n &#39;learning_rate&#39;: 0.18857516048056255,\n &#39;min_child_samples&#39;: 25.0,\n &#39;num_leaves&#39;: 83.0,\n &#39;reg_alpha&#39;: 0.1704362270661588,\n &#39;reg_lambda&#39;: 0.4444416565086208,\n &#39;subsample_for_bin&#39;: 120000.0}\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["# Testing the optimal model"],"metadata":{}},{"cell_type":"code","source":["from copy import deepcopy\nimport lightgbm as lgb\n\nlgbmodel = lgb.LGBMClassifier(\n                             colsample_by_tree= 0.8521732607849484,\n                             gdbt_subsample= 0.6680712282914405,\n                             learning_rate= 0.18857516048056255,\n                             min_child_samples= 25,\n                             num_leaves= 83,\n                             reg_alpha= 0.1704362270661588,\n                             reg_lambda= 0.4444416565086208,\n                             subsample_for_bin= 120000,\n                             num_estimators = 100)\npredicts = deepcopy(Test_4y)\ntargets = [name[:4] for name in names]\nfor name in targets:\n  lgbmodel.fit(Train_X,Train_4y[name])\n\n  predicts[name]=lgbmodel.predict(Test_X)\npredicts.to_csv(os.path.join(XGB_DIR,'predicts20190501_bin76.csv'),index=None)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\nfor name in targets:\n  print(roc_auc_score(Test_4y[name], predicts[name]))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0.8400863102373531\n0.8168082524271845\n0.7012624172185431\n0.7867857142857144\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["roc_auc_score(Test_4y[targets], predicts[targets])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[17]: 0.801015385085865\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["# Classifying with external"],"metadata":{}},{"cell_type":"code","source":["Train_4y = pd.read_csv(os.path.join(CHEMPROP_DIR,'JAK','train-8396_bin76.csv')).dropna(subset=['JAK1'])\nVal_4y = pd.read_csv(os.path.join(CHEMPROP_DIR,'JAK','val-182_bin76.csv')).dropna(subset=['JAK1'])\nTest_4y = pd.read_csv(os.path.join(CHEMPROP_DIR,'JAK','test-183_bin76.csv')).dropna(subset=['JAK1'])\nnames = ['JAK1','JAK2','JAK3','TYK2']\n\nAll_4y = Train_4y.append(Val_4y).append(Test_4y)\nall_fps = [Chem.MolFromSmiles(smi) for smi in All_4y['smiles']]\nfps = get_fps(all_fps, morgan=True)\n#get_fps([Chem.MolFromSmiles('Cc1c[nH]c(C(=O)N2CCCN(c3ncnc4[nH]ccc34)CC23CC3)c1')],bit=True)\nv = sklearn.feature_extraction.DictVectorizer(sparse=True, dtype=float)\nv.fit(fps)\nprint(len(v.feature_names_))\nprint(len(v.vocabulary_))\n\nX = v.transform(fps)\n\nX = X.toarray()\nTrain_X = X[:len(Train_4y)]\nVal_X = X[len(Train_4y):len(Train_4y)+len(Val_4y)]\nTest_X = X[len(Train_4y)+len(Val_4y):len(Train_4y)+len(Val_4y)+len(Test_4y)]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["space = {\n    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n                                                 {'boosting_type': 'goss', 'subsample': 1.0}]),\n    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n}\n\ntpe_algorithm = tpe.suggest\n\nbayes_trials = Trials()\n\nout_file = os.path.join(XGB_DIR,'gbm_trials_binary_ext.csv')\nlogfile = open(out_file, 'w')\nwriter = csv.writer(logfile)\n\nwriter.writerow(['loss', 'params', 'iteration', 'estimators', 'train_time'])\nlogfile.close()\n\nglobal  iter\n\niter = 0\nlgbmodel = lgb.LGBMClassifier()\ntrain_set = lgb.Dataset(Train_X, label = Train_4y[names[0]])\nbest = fmin(fn = objective, space = space, algo = tpe.suggest, \n            max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(13))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\r  0%|          | 0/100 [00:00&lt;?, ?it/s, best loss: ?]\r  1%|          | 1/100 [00:19&lt;32:40, 19.80s/it, best loss: 0.038516282305466776]\r  2%|▏         | 2/100 [00:49&lt;37:21, 22.87s/it, best loss: 0.038516282305466776]\r  3%|▎         | 3/100 [00:54&lt;28:04, 17.37s/it, best loss: 0.038516282305466776]\r  4%|▍         | 4/100 [01:07&lt;25:53, 16.18s/it, best loss: 0.038516282305466776]\r  5%|▌         | 5/100 [01:12&lt;20:09, 12.73s/it, best loss: 0.038516282305466776]\r  6%|▌         | 6/100 [01:33&lt;23:42, 15.13s/it, best loss: 0.03774286701501084] \r  7%|▋         | 7/100 [02:40&lt;47:31, 30.66s/it, best loss: 0.03774286701501084]\r  8%|▊         | 8/100 [03:08&lt;46:07, 30.09s/it, best loss: 0.03774286701501084]\r  9%|▉         | 9/100 [03:12&lt;33:34, 22.14s/it, best loss: 0.03774286701501084]</div>"]}}],"execution_count":18},{"cell_type":"code","source":["res = pd.read_csv('/dbfs/FileStore/XGB-Hopt/gbm_trials_binary_ext.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"code","source":["display(res.sort_values('loss'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>loss</th><th>params</th><th>iteration</th><th>estimators</th><th>train_time</th></tr></thead><tbody><tr><td>0.03518170472841242</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.6444568404965568, 'learning_rate': 0.033170339942429246, 'min_child_samples': 25, 'num_leaves': 96, 'reg_alpha': 0.2800473375282556, 'reg_lambda': 0.8509243004571374, 'subsample_for_bin': 100000, 'subsample': 0.9157298770833132}</td><td>88</td><td>269</td><td>23.216553182999636</td></tr><tr><td>0.035550194663581884</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.6810810724555437, 'learning_rate': 0.05189020144801292, 'min_child_samples': 20, 'num_leaves': 96, 'reg_alpha': 0.335050267108593, 'reg_lambda': 0.781863798041295, 'subsample_for_bin': 160000, 'subsample': 0.8332272098874306}</td><td>96</td><td>135</td><td>15.148115986998164</td></tr><tr><td>0.036039255118631486</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7282933711143356, 'learning_rate': 0.022642460325559895, 'min_child_samples': 20, 'num_leaves': 104, 'reg_alpha': 0.5059671136057231, 'reg_lambda': 0.7640988911487885, 'subsample_for_bin': 140000, 'subsample': 0.8941408039269114}</td><td>83</td><td>414</td><td>32.23734414300088</td></tr><tr><td>0.03632876310502442</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.6758002656096727, 'learning_rate': 0.04738208343798852, 'min_child_samples': 30, 'num_leaves': 101, 'reg_alpha': 0.3780343611879261, 'reg_lambda': 0.7820309052243114, 'subsample_for_bin': 160000, 'subsample': 0.7658184241189976}</td><td>95</td><td>177</td><td>15.97161795500142</td></tr><tr><td>0.03660333356015999</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9823107708721153, 'learning_rate': 0.023306191871832152, 'min_child_samples': 35, 'num_leaves': 99, 'reg_alpha': 0.43395329328238774, 'reg_lambda': 0.6592580530881157, 'subsample_for_bin': 140000, 'subsample': 0.8598521562626836}</td><td>75</td><td>437</td><td>33.24361484200017</td></tr><tr><td>0.036643012822757386</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.6025123650190819, 'learning_rate': 0.10273137655295785, 'min_child_samples': 25, 'num_leaves': 112, 'reg_alpha': 0.020282432495463076, 'reg_lambda': 0.5856719744939707, 'subsample_for_bin': 80000, 'subsample': 0.5017532056524744}</td><td>23</td><td>77</td><td>13.364152792999446</td></tr><tr><td>0.036679600194762685</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9949941124663952, 'learning_rate': 0.03692724017845553, 'min_child_samples': 35, 'num_leaves': 87, 'reg_alpha': 0.6829828429191762, 'reg_lambda': 0.4539467910080274, 'subsample_for_bin': 180000, 'subsample': 0.57747789786517}</td><td>69</td><td>307</td><td>23.024926374000646</td></tr><tr><td>0.03669778817510405</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.998042500503178, 'learning_rate': 0.010921685572671265, 'min_child_samples': 35, 'num_leaves': 117, 'reg_alpha': 0.6198403059803564, 'reg_lambda': 0.3566920128198412, 'subsample_for_bin': 200000, 'subsample': 0.5895270869249793}</td><td>46</td><td>961</td><td>61.76514977200168</td></tr><tr><td>0.036712190571451364</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9994656071585971, 'learning_rate': 0.05703159053156296, 'min_child_samples': 30, 'num_leaves': 90, 'reg_alpha': 0.702083864804418, 'reg_lambda': 0.2937568732451366, 'subsample_for_bin': 200000, 'subsample': 0.520575442044964}</td><td>48</td><td>170</td><td>15.253554793000147</td></tr><tr><td>0.03672822479894455</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9926780687485904, 'learning_rate': 0.057003567638112394, 'min_child_samples': 20, 'num_leaves': 89, 'reg_alpha': 0.7232282823597782, 'reg_lambda': 0.2770302575991247, 'subsample_for_bin': 200000, 'subsample': 0.5124735224173583}</td><td>66</td><td>165</td><td>15.646668150999176</td></tr><tr><td>0.03674256112925356</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8111683776048115, 'learning_rate': 0.029342436470910997, 'min_child_samples': 45, 'num_leaves': 107, 'reg_alpha': 0.6053712556044082, 'reg_lambda': 0.3742246811921587, 'subsample_for_bin': 300000, 'subsample': 0.9479908006565759}</td><td>51</td><td>441</td><td>27.621756151000234</td></tr><tr><td>0.03674705361985742</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.6107384814444533, 'learning_rate': 0.015910650339490302, 'min_child_samples': 120, 'num_leaves': 149, 'reg_alpha': 0.001695982950676288, 'reg_lambda': 0.5958130589321023, 'subsample_for_bin': 180000, 'subsample': 0.6488208328588942}</td><td>39</td><td>1698</td><td>73.4404676209997</td></tr><tr><td>0.0369088031014041</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.6062843704743105, 'learning_rate': 0.014749812149048675, 'min_child_samples': 115, 'num_leaves': 149, 'reg_alpha': 0.015244284937689173, 'reg_lambda': 0.5935354361545403, 'subsample_for_bin': 120000, 'subsample': 0.6339282352136052}</td><td>38</td><td>1741</td><td>74.51799636099895</td></tr><tr><td>0.036990989253037454</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7017775764963763, 'learning_rate': 0.027426198178285746, 'min_child_samples': 140, 'num_leaves': 98, 'reg_alpha': 0.23664136554210582, 'reg_lambda': 0.6663975395869142, 'subsample_for_bin': 60000, 'subsample': 0.952283806115251}</td><td>79</td><td>1728</td><td>64.43233209400023</td></tr><tr><td>0.03724281317118972</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.925953157886914, 'learning_rate': 0.05084229536327419, 'min_child_samples': 40, 'num_leaves': 78, 'reg_alpha': 0.7015067403696833, 'reg_lambda': 0.3091450098600498, 'subsample_for_bin': 240000, 'subsample': 0.5175580874341129}</td><td>67</td><td>254</td><td>18.30009568099922</td></tr><tr><td>0.0373016912245141</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7587594794684582, 'learning_rate': 0.011926824854769449, 'min_child_samples': 65, 'num_leaves': 45, 'reg_alpha': 0.5159127875705927, 'reg_lambda': 0.6837749810425222, 'subsample_for_bin': 100000, 'subsample': 0.5009000098588792}</td><td>65</td><td>1413</td><td>70.66647896700124</td></tr><tr><td>0.03739185815357315</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7083058914333237, 'learning_rate': 0.03347355846454278, 'min_child_samples': 115, 'num_leaves': 83, 'reg_alpha': 0.2878734599085215, 'reg_lambda': 0.7330518785596524, 'subsample_for_bin': 100000, 'subsample': 0.9273169479113406}</td><td>89</td><td>1001</td><td>42.67686420499922</td></tr><tr><td>0.037560154779514576</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.7195708401878512, 'learning_rate': 0.1101339756755972, 'min_child_samples': 55, 'num_leaves': 133, 'reg_alpha': 0.15516149590474937, 'reg_lambda': 0.5228067822099494, 'subsample_for_bin': 40000, 'subsample': 0.550663662858578}</td><td>15</td><td>119</td><td>11.530589942000006</td></tr><tr><td>0.037570903723944234</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8409695280557282, 'learning_rate': 0.08868593080169042, 'min_child_samples': 30, 'num_leaves': 122, 'reg_alpha': 0.46780558985278115, 'reg_lambda': 0.5982706609800312, 'subsample_for_bin': 80000, 'subsample': 0.5002135862476771}</td><td>22</td><td>73</td><td>10.085418791000848</td></tr><tr><td>0.03763681120374307</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.6681774847176866, 'learning_rate': 0.19320760647421875, 'min_child_samples': 25, 'num_leaves': 108, 'reg_alpha': 0.001309740617576216, 'reg_lambda': 0.5642833235167768, 'subsample_for_bin': 20000, 'subsample': 0.6031769840095121}</td><td>24</td><td>23</td><td>10.365199720999952</td></tr><tr><td>0.03766806043985438</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.88252383888319, 'learning_rate': 0.16941677302387684, 'min_child_samples': 70, 'num_leaves': 125, 'reg_alpha': 0.7786410075407098, 'reg_lambda': 0.49104471267474653, 'subsample_for_bin': 220000, 'subsample': 0.6089886386790555}</td><td>54</td><td>135</td><td>9.84856328800015</td></tr><tr><td>0.03774286701501084</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8229660973513012, 'learning_rate': 0.07676368335189537, 'min_child_samples': 120, 'num_leaves': 127, 'reg_alpha': 0.47597356101780086, 'reg_lambda': 0.47652827743419424, 'subsample_for_bin': 280000, 'subsample': 0.5637598748577498}</td><td>6</td><td>454</td><td>20.59431562600002</td></tr><tr><td>0.037884089778460805</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.6696812846307486, 'learning_rate': 0.19488701034461622, 'min_child_samples': 135, 'num_leaves': 123, 'reg_alpha': 0.007838428673490496, 'reg_lambda': 0.5146176530784864, 'subsample_for_bin': 40000, 'subsample': 0.6504141111195602}</td><td>31</td><td>195</td><td>11.308569876000547</td></tr><tr><td>0.037908415293759434</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9644823507482697, 'learning_rate': 0.03695028748568234, 'min_child_samples': 125, 'num_leaves': 73, 'reg_alpha': 0.6798230529784066, 'reg_lambda': 0.34528432960376587, 'subsample_for_bin': 160000, 'subsample': 0.5795113079600186}</td><td>72</td><td>1309</td><td>52.166577944999524</td></tr><tr><td>0.03801206630123344</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8862808643208654, 'learning_rate': 0.07440835625405755, 'min_child_samples': 65, 'num_leaves': 144, 'reg_alpha': 0.39328880086967133, 'reg_lambda': 0.8222339421009777, 'subsample_for_bin': 240000, 'subsample': 0.8287237433708023}</td><td>17</td><td>266</td><td>18.024023269999816</td></tr><tr><td>0.03804965127041693</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.6193369773986505, 'learning_rate': 0.02147118373158478, 'min_child_samples': 90, 'num_leaves': 91, 'reg_alpha': 0.44495347354098697, 'reg_lambda': 0.7029812506363721, 'subsample_for_bin': 140000, 'subsample': 0.9740912946731677}</td><td>93</td><td>1170</td><td>49.312096933999776</td></tr><tr><td>0.03811156836150287</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.6721288274072659, 'learning_rate': 0.015481934206735057, 'min_child_samples': 155, 'num_leaves': 128, 'reg_alpha': 0.34585029204216017, 'reg_lambda': 0.06377701435404642, 'subsample_for_bin': 200000, 'subsample': 0.527376453341976}</td><td>44</td><td>3481</td><td>116.31109019999893</td></tr><tr><td>0.038208249401937344</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9713506001302877, 'learning_rate': 0.039398200598577494, 'min_child_samples': 140, 'num_leaves': 117, 'reg_alpha': 0.44620571727660746, 'reg_lambda': 0.5618161303795572, 'subsample_for_bin': 120000, 'subsample': 0.6963330303175594}</td><td>57</td><td>1007</td><td>41.15798217300107</td></tr><tr><td>0.038209114867038714</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.9785680239295227, 'learning_rate': 0.019570728962457446, 'min_child_samples': 110, 'num_leaves': 34, 'reg_alpha': 0.6673225518620548, 'reg_lambda': 0.1299521333263246, 'subsample_for_bin': 280000, 'subsample': 0.8832217735079414}</td><td>7</td><td>1589</td><td>66.72494428900063</td></tr><tr><td>0.03822158813506804</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.6031371803984236, 'learning_rate': 0.065024454435443, 'min_child_samples': 80, 'num_leaves': 99, 'reg_alpha': 0.34839753158508585, 'reg_lambda': 0.41575929717036164, 'subsample_for_bin': 180000, 'subsample': 0.5820812161170654}</td><td>29</td><td>444</td><td>22.07161873199948</td></tr><tr><td>0.03828935867714645</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.6435413031801376, 'learning_rate': 0.04271553146406113, 'min_child_samples': 95, 'num_leaves': 82, 'reg_alpha': 0.9014156179123303, 'reg_lambda': 0.6136587414190343, 'subsample_for_bin': 300000, 'subsample': 0.7698925624645431}</td><td>43</td><td>941</td><td>35.343024718000386</td></tr><tr><td>0.038340427724745</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7644310172845035, 'learning_rate': 0.05479856773222314, 'min_child_samples': 105, 'num_leaves': 94, 'reg_alpha': 0.7285149675153193, 'reg_lambda': 0.2788434969485545, 'subsample_for_bin': 260000, 'subsample': 0.7459614312871614}</td><td>55</td><td>531</td><td>23.11247168800037</td></tr><tr><td>0.038352570662582915</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9992951107418265, 'learning_rate': 0.017301663640363677, 'min_child_samples': 75, 'num_leaves': 114, 'reg_alpha': 0.5780406647574549, 'reg_lambda': 0.5236567124092644, 'subsample_for_bin': 180000, 'subsample': 0.554227646075392}</td><td>74</td><td>1134</td><td>58.803297835000194</td></tr><tr><td>0.03836160849662118</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.6090010104771815, 'learning_rate': 0.06327076361624229, 'min_child_samples': 155, 'num_leaves': 103, 'reg_alpha': 0.24272811647785006, 'reg_lambda': 0.5338368459270096, 'subsample_for_bin': 60000, 'subsample': 0.9909448649281941}</td><td>26</td><td>847</td><td>30.060521130000783</td></tr><tr><td>0.03845939283989497</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8973240043182537, 'learning_rate': 0.04522081258717539, 'min_child_samples': 105, 'num_leaves': 120, 'reg_alpha': 0.7545486302154772, 'reg_lambda': 0.4465646084538398, 'subsample_for_bin': 180000, 'subsample': 0.657829899748501}</td><td>70</td><td>756</td><td>32.400503730999844</td></tr><tr><td>0.03850091534496048</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.6890700814604936, 'learning_rate': 0.0252336265428407, 'min_child_samples': 180, 'num_leaves': 93, 'reg_alpha': 0.11505438022518, 'reg_lambda': 0.690745938607522, 'subsample_for_bin': 140000, 'subsample': 0.6138325314639916}</td><td>10</td><td>2533</td><td>85.58090529000037</td></tr><tr><td>0.038516282305466776</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.6497297356391579, 'learning_rate': 0.0643016501522136, 'min_child_samples': 85, 'num_leaves': 98, 'reg_alpha': 0.3152892199865768, 'reg_lambda': 0.14021039751036224, 'subsample_for_bin': 220000, 'subsample': 0.9104645412140487}</td><td>1</td><td>370</td><td>19.671473633999994</td></tr><tr><td>0.038616881061971815</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.782287058538602, 'learning_rate': 0.12449504826165128, 'min_child_samples': 95, 'num_leaves': 140, 'reg_alpha': 0.5527195620604701, 'reg_lambda': 0.0025111394352995142, 'subsample_for_bin': 40000, 'subsample': 0.5701827067632844}</td><td>36</td><td>257</td><td>13.733392005000493</td></tr><tr><td>0.0386390330046108</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.9780633301866448, 'learning_rate': 0.030160760179093093, 'min_child_samples': 90, 'num_leaves': 78, 'reg_alpha': 0.2739270765485392, 'reg_lambda': 0.5663077189997623, 'subsample_for_bin': 120000, 'subsample': 0.8568196966488625}</td><td>76</td><td>621</td><td>33.867201513001426</td></tr><tr><td>0.0386462804490112</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.6302641889404177, 'learning_rate': 0.04711682280977109, 'min_child_samples': 155, 'num_leaves': 37, 'reg_alpha': 0.7698141010011418, 'reg_lambda': 0.38060854708786984, 'subsample_for_bin': 20000, 'subsample': 0.7804834243241652}</td><td>18</td><td>1357</td><td>43.05113206699934</td></tr><tr><td>0.03881178908813665</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.9321910261400952, 'learning_rate': 0.03595932729968674, 'min_child_samples': 105, 'num_leaves': 44, 'reg_alpha': 0.8597311656848392, 'reg_lambda': 0.9664589581632947, 'subsample_for_bin': 40000, 'subsample': 0.8438681232525798}</td><td>80</td><td>836</td><td>35.8712145949994</td></tr><tr><td>0.03886477405084565</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9099157486537143, 'learning_rate': 0.11610174590085283, 'min_child_samples': 60, 'num_leaves': 93, 'reg_alpha': 0.9270121940527157, 'reg_lambda': 0.4784191271009915, 'subsample_for_bin': 140000, 'subsample': 0.5996672239045842}</td><td>73</td><td>169</td><td>11.446881648998895</td></tr><tr><td>0.03913386102480332</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.961686464757631, 'learning_rate': 0.08006055202802713, 'min_child_samples': 150, 'num_leaves': 109, 'reg_alpha': 0.5783914880586131, 'reg_lambda': 0.12003237040826864, 'subsample_for_bin': 200000, 'subsample': 0.7453939427467282}</td><td>64</td><td>668</td><td>26.61603305899916</td></tr><tr><td>0.039239533653048886</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.9752935043238538, 'learning_rate': 0.14480604247804024, 'min_child_samples': 95, 'num_leaves': 42, 'reg_alpha': 0.04213251415303454, 'reg_lambda': 0.46291412424967415, 'subsample_for_bin': 140000, 'subsample': 0.5410521442970198}</td><td>4</td><td>173</td><td>13.218845868999779</td></tr><tr><td>0.03936981588055788</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.8626222946410779, 'learning_rate': 0.16162935901320058, 'min_child_samples': 175, 'num_leaves': 54, 'reg_alpha': 0.04990768174583407, 'reg_lambda': 0.6685360356916707, 'subsample_for_bin': 80000, 'subsample': 0.5070712499404544}</td><td>35</td><td>326</td><td>15.589211434999015</td></tr><tr><td>0.03948176478244148</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9433296997170147, 'learning_rate': 0.013759217070482395, 'min_child_samples': 165, 'num_leaves': 85, 'reg_alpha': 0.6374435403014549, 'reg_lambda': 0.5024582783343546, 'subsample_for_bin': 220000, 'subsample': 0.6213833508006406}</td><td>71</td><td>3695</td><td>128.8700617529994</td></tr><tr><td>0.039508964170405385</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8248392746023525, 'learning_rate': 0.012977892397989486, 'min_child_samples': 180, 'num_leaves': 130, 'reg_alpha': 0.6006360645703701, 'reg_lambda': 0.1869061775356716, 'subsample_for_bin': 60000, 'subsample': 0.5599221625364345}</td><td>56</td><td>4410</td><td>142.00094020400138</td></tr><tr><td>0.040036580765401515</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8769397206981676, 'learning_rate': 0.06710007447001953, 'min_child_samples': 85, 'num_leaves': 102, 'reg_alpha': 0.6422887025319162, 'reg_lambda': 0.3948953696788494, 'subsample_for_bin': 280000, 'subsample': 0.5345009419487525}</td><td>68</td><td>389</td><td>20.322260179000292</td></tr><tr><td>0.040541239412091534</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8642527000601448, 'learning_rate': 0.10154486511370667, 'min_child_samples': 195, 'num_leaves': 102, 'reg_alpha': 0.9679158291809666, 'reg_lambda': 0.7982493305969646, 'subsample_for_bin': 220000, 'subsample': 0.6357111521405328}</td><td>60</td><td>1083</td><td>32.73009694600114</td></tr><tr><td>0.040572052612350314</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.7454918623622017, 'learning_rate': 0.18323510812599184, 'min_child_samples': 210, 'num_leaves': 120, 'reg_alpha': 0.07516175497230436, 'reg_lambda': 0.9210776609826817, 'subsample_for_bin': 100000, 'subsample': 0.5067464631495768}</td><td>27</td><td>384</td><td>15.007365211999057</td></tr><tr><td>0.040588152905881685</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7797769533739332, 'learning_rate': 0.01599217353053515, 'min_child_samples': 195, 'num_leaves': 121, 'reg_alpha': 0.31755213393807435, 'reg_lambda': 0.7694134164282858, 'subsample_for_bin': 60000, 'subsample': 0.8226796770420941}</td><td>86</td><td>3044</td><td>99.71691430699866</td></tr><tr><td>0.04075034502988506</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.6273380638806194, 'learning_rate': 0.061532539844943675, 'min_child_samples': 210, 'num_leaves': 116, 'reg_alpha': 0.5362678148680069, 'reg_lambda': 0.4300007781833795, 'subsample_for_bin': 120000, 'subsample': 0.5388327380508403}</td><td>33</td><td>1463</td><td>42.6992941389999</td></tr><tr><td>0.040815994852134496</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8524059116230525, 'learning_rate': 0.02477884141194438, 'min_child_samples': 210, 'num_leaves': 58, 'reg_alpha': 0.1466714201842226, 'reg_lambda': 0.7586502740078339, 'subsample_for_bin': 80000, 'subsample': 0.9970702299589544}</td><td>77</td><td>2193</td><td>75.0321124559996</td></tr><tr><td>0.041283887748515546</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.7162142475366648, 'learning_rate': 0.01106787248927761, 'min_child_samples': 20, 'num_leaves': 128, 'reg_alpha': 0.1863033047008117, 'reg_lambda': 0.8981051533595322, 'subsample_for_bin': 180000, 'subsample': 1.0}</td><td>34</td><td>170</td><td>14.63627778099908</td></tr><tr><td>0.04138278200123291</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.693384774923023, 'learning_rate': 0.01947284564878375, 'min_child_samples': 235, 'num_leaves': 54, 'reg_alpha': 0.41997682430625044, 'reg_lambda': 0.7035381710132743, 'subsample_for_bin': 160000, 'subsample': 0.7233105356931485}</td><td>42</td><td>4323</td><td>124.07320395399984</td></tr><tr><td>0.041815507945432095</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.6352520513356581, 'learning_rate': 0.062215836901504666, 'min_child_samples': 245, 'num_leaves': 79, 'reg_alpha': 0.12446909302192916, 'reg_lambda': 0.9305050355317291, 'subsample_for_bin': 60000, 'subsample': 0.8326381930624827}</td><td>98</td><td>1464</td><td>43.96844522299944</td></tr><tr><td>0.04235302123296414</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.7565247881411324, 'learning_rate': 0.014045986114782819, 'min_child_samples': 230, 'num_leaves': 73, 'reg_alpha': 0.4930364425702049, 'reg_lambda': 0.9096340742669555, 'subsample_for_bin': 120000, 'subsample': 0.8020114733071352}</td><td>91</td><td>3787</td><td>112.45301279400157</td></tr><tr><td>0.04284950090411377</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7471547750564617, 'learning_rate': 0.012463505459074901, 'min_child_samples': 275, 'num_leaves': 112, 'reg_alpha': 0.19974194967514625, 'reg_lambda': 0.33308524540376144, 'subsample_for_bin': 100000, 'subsample': 0.6728643157742487}</td><td>21</td><td>5524</td><td>156.39283984299982</td></tr><tr><td>0.04295422878801192</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.795948611012971, 'learning_rate': 0.03293051484658929, 'min_child_samples': 260, 'num_leaves': 31, 'reg_alpha': 0.8951605892321404, 'reg_lambda': 0.8558297145753182, 'subsample_for_bin': 80000, 'subsample': 0.5421311409971281}</td><td>61</td><td>2872</td><td>78.28666874199916</td></tr><tr><td>0.04360556725291465</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7418164566530671, 'learning_rate': 0.10079938189354284, 'min_child_samples': 295, 'num_leaves': 137, 'reg_alpha': 0.27790159132617653, 'reg_lambda': 0.23573426934291686, 'subsample_for_bin': 40000, 'subsample': 0.6755607929800204}</td><td>28</td><td>1289</td><td>36.89768363700023</td></tr><tr><td>0.04367545851482224</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.6423216397773776, 'learning_rate': 0.030875668573056212, 'min_child_samples': 320, 'num_leaves': 96, 'reg_alpha': 0.22280426057586816, 'reg_lambda': 0.960650654675037, 'subsample_for_bin': 160000, 'subsample': 0.8748829956367108}</td><td>90</td><td>3307</td><td>86.00565742300024</td></tr><tr><td>0.043795844049795314</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7347611667814294, 'learning_rate': 0.026626520473790258, 'min_child_samples': 285, 'num_leaves': 93, 'reg_alpha': 0.43984733099897844, 'reg_lambda': 0.8693154041842703, 'subsample_for_bin': 20000, 'subsample': 0.8837684369603714}</td><td>84</td><td>3010</td><td>83.14577620499948</td></tr><tr><td>0.04400339711568901</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8364322811173676, 'learning_rate': 0.02247902454904776, 'min_child_samples': 300, 'num_leaves': 136, 'reg_alpha': 0.8415228482372752, 'reg_lambda': 0.05306771874316041, 'subsample_for_bin': 140000, 'subsample': 0.9019779056796593}</td><td>59</td><td>4133</td><td>111.3366640969998</td></tr><tr><td>0.04485587033086525</td><td>{'boosting_type': 'goss', 'class_weight': 'balanced', 'colsample_bytree': 0.6444363956332486, 'learning_rate': 0.028597442543919042, 'min_child_samples': 20, 'num_leaves': 96, 'reg_alpha': 0.08630834449949931, 'reg_lambda': 0.8781312096176667, 'subsample_for_bin': 80000, 'subsample': 1.0}</td><td>97</td><td>34</td><td>7.039124795999669</td></tr><tr><td>0.04512962487042793</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.6573102961660144, 'learning_rate': 0.01771373965597131, 'min_child_samples': 315, 'num_leaves': 70, 'reg_alpha': 0.9970519427176547, 'reg_lambda': 0.8886453590640018, 'subsample_for_bin': 180000, 'subsample': 0.6881954431468811}</td><td>40</td><td>5128</td><td>125.82877759799885</td></tr><tr><td>0.04517281223965841</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7055076733040826, 'learning_rate': 0.14382642660798406, 'min_child_samples': 340, 'num_leaves': 149, 'reg_alpha': 0.8008143884623098, 'reg_lambda': 0.9650176411299378, 'subsample_for_bin': 40000, 'subsample': 0.8553890305186072}</td><td>8</td><td>1109</td><td>28.617668236998725</td></tr><tr><td>0.04528700738684388</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9869427886969102, 'learning_rate': 0.09500157119733078, 'min_child_samples': 390, 'num_leaves': 133, 'reg_alpha': 0.3600999430929331, 'reg_lambda': 0.5503114864739945, 'subsample_for_bin': 160000, 'subsample': 0.5916273759049129}</td><td>63</td><td>1759</td><td>48.29015027300011</td></tr><tr><td>0.045566057119375336</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.6966537196962382, 'learning_rate': 0.023616217816785367, 'min_child_samples': 360, 'num_leaves': 111, 'reg_alpha': 0.2955498078483676, 'reg_lambda': 0.8034851739221661, 'subsample_for_bin': 100000, 'subsample': 0.8746465037357964}</td><td>94</td><td>5356</td><td>132.4371480789996</td></tr><tr><td>0.046188729530263865</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.6644776993010958, 'learning_rate': 0.04321352830712949, 'min_child_samples': 405, 'num_leaves': 130, 'reg_alpha': 0.3409123712169878, 'reg_lambda': 0.7496994158007391, 'subsample_for_bin': 160000, 'subsample': 0.8887370821513056}</td><td>99</td><td>3596</td><td>84.39575398599845</td></tr><tr><td>0.046247534910946235</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7701677517905978, 'learning_rate': 0.08753547155929584, 'min_child_samples': 350, 'num_leaves': 90, 'reg_alpha': 0.309727110852123, 'reg_lambda': 0.2544944779891997, 'subsample_for_bin': 60000, 'subsample': 0.7181281377848985}</td><td>32</td><td>1783</td><td>47.35045202100083</td></tr><tr><td>0.04629092047829153</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8623190770729122, 'learning_rate': 0.022179069435706328, 'min_child_samples': 340, 'num_leaves': 99, 'reg_alpha': 0.8825470042922836, 'reg_lambda': 0.3441583693242663, 'subsample_for_bin': 160000, 'subsample': 0.5644696212260143}</td><td>50</td><td>3750</td><td>98.58182455099994</td></tr><tr><td>0.04649983450457407</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.77466250703065, 'learning_rate': 0.15101212387806648, 'min_child_samples': 395, 'num_leaves': 32, 'reg_alpha': 0.8214600071869739, 'reg_lambda': 0.8104123354444183, 'subsample_for_bin': 60000, 'subsample': 0.5343613734789786}</td><td>2</td><td>1210</td><td>29.88332839500072</td></tr><tr><td>0.047018882334403884</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.9469382237454942, 'learning_rate': 0.1563521023777783, 'min_child_samples': 470, 'num_leaves': 134, 'reg_alpha': 0.1993653530123487, 'reg_lambda': 0.17231284621839504, 'subsample_for_bin': 140000, 'subsample': 0.6215598430566133}</td><td>13</td><td>1144</td><td>30.74035314899993</td></tr><tr><td>0.04721340717754663</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9114661464358558, 'learning_rate': 0.03585131264121078, 'min_child_samples': 420, 'num_leaves': 81, 'reg_alpha': 0.6601530905197156, 'reg_lambda': 0.9933561200737052, 'subsample_for_bin': 220000, 'subsample': 0.7234740910849327}</td><td>20</td><td>4156</td><td>103.5768358589994</td></tr><tr><td>0.0476420964868064</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9535057135250811, 'learning_rate': 0.03966170308501442, 'min_child_samples': 455, 'num_leaves': 116, 'reg_alpha': 0.6092374763017805, 'reg_lambda': 0.1666996382752922, 'subsample_for_bin': 280000, 'subsample': 0.5886798621515806}</td><td>47</td><td>3679</td><td>90.63690479599971</td></tr><tr><td>0.04768828986077911</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9059810508054694, 'learning_rate': 0.11843680138550504, 'min_child_samples': 435, 'num_leaves': 38, 'reg_alpha': 0.7672713726805797, 'reg_lambda': 0.8327866254803609, 'subsample_for_bin': 160000, 'subsample': 0.7894420515405993}</td><td>11</td><td>1311</td><td>33.18780655000046</td></tr><tr><td>0.0477236219780568</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.7149570641653147, 'learning_rate': 0.05328384803532478, 'min_child_samples': 500, 'num_leaves': 62, 'reg_alpha': 0.2652171835579442, 'reg_lambda': 0.8433817819406054, 'subsample_for_bin': 180000, 'subsample': 0.9238319751502219}</td><td>100</td><td>3235</td><td>72.74545477900028</td></tr><tr><td>0.048290481799797336</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.72197772553899, 'learning_rate': 0.02324985531477946, 'min_child_samples': 430, 'num_leaves': 103, 'reg_alpha': 0.3868685831583826, 'reg_lambda': 0.9358413154428598, 'subsample_for_bin': 140000, 'subsample': 0.9110809148605665}</td><td>85</td><td>4442</td><td>105.02607253300086</td></tr><tr><td>0.04917074569398072</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.9280225525474963, 'learning_rate': 0.04977454960835226, 'min_child_samples': 490, 'num_leaves': 40, 'reg_alpha': 0.6587308197863629, 'reg_lambda': 0.6323466857140498, 'subsample_for_bin': 260000, 'subsample': 0.9384488170457128}</td><td>12</td><td>2731</td><td>65.79059076399972</td></tr><tr><td>0.04934418225770098</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9522273168322383, 'learning_rate': 0.010465393832393432, 'min_child_samples': 375, 'num_leaves': 69, 'reg_alpha': 0.5435031793006015, 'reg_lambda': 0.23992911445320886, 'subsample_for_bin': 260000, 'subsample': 0.806631966973068}</td><td>52</td><td>5871</td><td>157.86839661500017</td></tr><tr><td>0.050460394401035336</td><td>{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.8920076127826956, 'learning_rate': 0.031578443041060236, 'min_child_samples': 490, 'num_leaves': 64, 'reg_alpha': 0.40160291147242655, 'reg_lambda': 0.7693236888614342, 'subsample_for_bin': 140000, 'subsample': 0.8569831325200756}</td><td>16</td><td>3136</td><td>76.66553449500134</td></tr><tr><td>0.05080335641900935</td><td>{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9427702228622006, 'learning_rate': 0.018660949305228828, 'min_child_samples': 475, 'num_leaves': 86, 'reg_alpha': 0.370430942715694, 'reg_lambda': 0.6433269409234372, 'subsample_for_bin': 120000, 'subsample': 0.9736731182430408}</td><td>81</td><td>4468</td><td>111.25510466400009</td></tr><tr><td>0.05210711683184266</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.6601567970388589, 'learning_rate': 0.016976667349117798, 'min_child_samples': 50, 'num_leaves': 106, 'reg_alpha': 0.5201908600718307, 'reg_lambda': 0.8506729971073816, 'subsample_for_bin': 120000, 'subsample': 1.0}</td><td>92</td><td>135</td><td>8.806359392998273</td></tr><tr><td>0.052131458863650885</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.7170415511763847, 'learning_rate': 0.12464286025208003, 'min_child_samples': 25, 'num_leaves': 65, 'reg_alpha': 0.6758970796348801, 'reg_lambda': 0.8201912804346394, 'subsample_for_bin': 140000, 'subsample': 1.0}</td><td>5</td><td>8</td><td>4.608058589999928</td></tr><tr><td>0.053537301215549116</td><td>{'boosting_type': 'goss', 'class_weight': 'balanced', 'colsample_bytree': 0.9220679047466146, 'learning_rate': 0.06985771384736719, 'min_child_samples': 20, 'num_leaves': 61, 'reg_alpha': 0.8043803989398854, 'reg_lambda': 0.3813038406963343, 'subsample_for_bin': 240000, 'subsample': 1.0}</td><td>62</td><td>14</td><td>5.343522357999973</td></tr><tr><td>0.05732616208509711</td><td>{'boosting_type': 'goss', 'class_weight': 'balanced', 'colsample_bytree': 0.6852764082135093, 'learning_rate': 0.08351734791061963, 'min_child_samples': 50, 'num_leaves': 105, 'reg_alpha': 0.24090575960962332, 'reg_lambda': 0.7227463802804965, 'subsample_for_bin': 20000, 'subsample': 1.0}</td><td>37</td><td>11</td><td>3.9694068190001417</td></tr><tr><td>0.059083974559290035</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.6543472689484024, 'learning_rate': 0.11123123212153825, 'min_child_samples': 55, 'num_leaves': 82, 'reg_alpha': 0.14496083580810093, 'reg_lambda': 0.6503669192218661, 'subsample_for_bin': 80000, 'subsample': 1.0}</td><td>30</td><td>8</td><td>3.9774264600000606</td></tr><tr><td>0.06180475239439843</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.9028154515035982, 'learning_rate': 0.13566767319920256, 'min_child_samples': 40, 'num_leaves': 76, 'reg_alpha': 0.49446411398982626, 'reg_lambda': 0.20954641412257463, 'subsample_for_bin': 100000, 'subsample': 1.0}</td><td>58</td><td>7</td><td>4.16004821199931</td></tr><tr><td>0.06339312530018759</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.6815336601825134, 'learning_rate': 0.020454141873133564, 'min_child_samples': 75, 'num_leaves': 124, 'reg_alpha': 0.1830708436013393, 'reg_lambda': 0.9999364463566918, 'subsample_for_bin': 140000, 'subsample': 1.0}</td><td>87</td><td>48</td><td>5.207936250000785</td></tr><tr><td>0.06419779313005702</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.915657316581308, 'learning_rate': 0.020763050182576823, 'min_child_samples': 55, 'num_leaves': 67, 'reg_alpha': 0.40978895100622825, 'reg_lambda': 0.6252302890662577, 'subsample_for_bin': 100000, 'subsample': 1.0}</td><td>78</td><td>48</td><td>5.851880160000293</td></tr><tr><td>0.06612184757640037</td><td>{'boosting_type': 'goss', 'class_weight': 'balanced', 'colsample_bytree': 0.7888619837165034, 'learning_rate': 0.050270990190806865, 'min_child_samples': 65, 'num_leaves': 145, 'reg_alpha': 0.9584260774724662, 'reg_lambda': 0.009799707242451494, 'subsample_for_bin': 240000, 'subsample': 1.0}</td><td>19</td><td>19</td><td>4.153350792999845</td></tr><tr><td>0.0716606920946038</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.619905835014453, 'learning_rate': 0.02750149836960949, 'min_child_samples': 130, 'num_leaves': 96, 'reg_alpha': 0.07487231609302325, 'reg_lambda': 0.4637631497608903, 'subsample_for_bin': 200000, 'subsample': 1.0}</td><td>41</td><td>36</td><td>4.131963395000639</td></tr><tr><td>0.07528098546745343</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.9787152802118427, 'learning_rate': 0.13709496408529942, 'min_child_samples': 80, 'num_leaves': 86, 'reg_alpha': 0.7198385261507722, 'reg_lambda': 0.0966695068355315, 'subsample_for_bin': 240000, 'subsample': 1.0}</td><td>49</td><td>7</td><td>3.543507532998774</td></tr><tr><td>0.07700025831820978</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.8086489128474942, 'learning_rate': 0.041742791972532806, 'min_child_samples': 165, 'num_leaves': 108, 'reg_alpha': 0.31992750565750233, 'reg_lambda': 0.8288687254790452, 'subsample_for_bin': 80000, 'subsample': 1.0}</td><td>82</td><td>80</td><td>5.191092002000005</td></tr><tr><td>0.08026038277341263</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.7307335436317216, 'learning_rate': 0.02522626167799342, 'min_child_samples': 185, 'num_leaves': 142, 'reg_alpha': 0.11155627463376579, 'reg_lambda': 0.7363632019815769, 'subsample_for_bin': 120000, 'subsample': 1.0}</td><td>45</td><td>134</td><td>6.568747266001082</td></tr><tr><td>0.09277807030351393</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.6319586803137608, 'learning_rate': 0.1018620761666999, 'min_child_samples': 260, 'num_leaves': 112, 'reg_alpha': 0.1062997092846022, 'reg_lambda': 0.3264456654489557, 'subsample_for_bin': 100000, 'subsample': 1.0}</td><td>25</td><td>9</td><td>2.8603980659991066</td></tr><tr><td>0.0979338705383126</td><td>{'boosting_type': 'goss', 'class_weight': 'balanced', 'colsample_bytree': 0.9965696074460387, 'learning_rate': 0.04875128711631531, 'min_child_samples': 225, 'num_leaves': 76, 'reg_alpha': 0.8425746719865637, 'reg_lambda': 0.7864295931914004, 'subsample_for_bin': 260000, 'subsample': 1.0}</td><td>9</td><td>20</td><td>3.4868867379991566</td></tr><tr><td>0.10144515164468104</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.9349930703082809, 'learning_rate': 0.07242152063581159, 'min_child_samples': 240, 'num_leaves': 112, 'reg_alpha': 0.47159971229712194, 'reg_lambda': 0.4245230926141041, 'subsample_for_bin': 140000, 'subsample': 1.0}</td><td>53</td><td>13</td><td>3.167339780000475</td></tr><tr><td>0.10937267323671396</td><td>{'boosting_type': 'goss', 'class_weight': 'balanced', 'colsample_bytree': 0.8450156245776252, 'learning_rate': 0.0224481264534776, 'min_child_samples': 420, 'num_leaves': 40, 'reg_alpha': 0.8293385331016342, 'reg_lambda': 0.7215340358795095, 'subsample_for_bin': 160000, 'subsample': 1.0}</td><td>3</td><td>85</td><td>4.4220333459998065</td></tr><tr><td>0.11201976761931698</td><td>{'boosting_type': 'goss', 'class_weight': None, 'colsample_bytree': 0.8124440354100548, 'learning_rate': 0.03360120046947603, 'min_child_samples': 400, 'num_leaves': 133, 'reg_alpha': 0.6430241871874026, 'reg_lambda': 0.7622737620327515, 'subsample_for_bin': 220000, 'subsample': 1.0}</td><td>14</td><td>29</td><td>3.228063451000708</td></tr></tbody></table></div>"]}}],"execution_count":20},{"cell_type":"code","source":["\n\nlgbmodel = lgb.LGBMClassifier(\n                             colsample_bytree=0.6444568404965568,\n                             gdbt_subsample=0.9157298770833132,\n                             learning_rate=0.033170339942429246,\n                             min_child_samples=25,\n                             num_leaves=96,\n                             reg_alpha=0.2800473375282556,\n                             reg_lambda=0.8509243004571374,\n                             subsample_for_bin=100000, subsample = 0.9157298770833132,n_estimators=100)\npredicts = Test_4y\nfor name in names:\n  Train_4y = pd.read_csv(os.path.join(CHEMPROP_DIR,'JAK','train-8396_bin76.csv')).dropna(subset=[name])\n  names = ['JAK1','JAK2','JAK3','TYK2']\n  All_4y = Train_4y.append(Val_4y).append(Test_4y)\n  all_fps = [Chem.MolFromSmiles(smi) for smi in All_4y['smiles']]\n  fps = get_fps(all_fps, morgan=True)\n  v = sklearn.feature_extraction.DictVectorizer(sparse=True, dtype=float)\n  v.fit(fps)\n  print(len(v.feature_names_))\n  print(len(v.vocabulary_))\n\n  X = v.transform(fps)\n\n  X = X.toarray()\n  Train_X = X[:len(Train_4y)]\n  Val_X = X[len(Train_4y):len(Train_4y)+len(Val_4y)]\n  Test_X = X[len(Train_4y)+len(Val_4y):len(Train_4y)+len(Val_4y)+len(Test_4y)]\n  \n  lgbmodel.fit(Train_X,Train_4y[name])\n\n  predicts[name]=lgbmodel.predict(Test_X)\n#rmse = np.sqrt(mean_squared_error(Test_4y[names[0]], y_pred))\npredicts.to_csv(os.path.join(XGB_DIR,'predicts20190501_binary_ext.csv'),index=None)\nTrain_X = np.concatenate((Train_X,Val_X))\nTrain_4y = Train_4y.append(Val_4y)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Errors in conversion: 0\n10256\n10256\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\nErrors in conversion: 0\n12697\n12697\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\nErrors in conversion: 0\n10262\n10262\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\nErrors in conversion: 0\n7312\n7312\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\nTest_4y = pd.read_csv(os.path.join(CHEMPROP_DIR,'JAK','test-183_bin76.csv')).dropna(subset=['JAK1'])\n\nfor name in names:\n  print(roc_auc_score(Test_4y[name], predicts[name]))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0.8110165427954926\n0.8341626213592234\n0.6264486754966887\n0.6221428571428571\n</div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["# unused material"],"metadata":{}},{"cell_type":"code","source":["full_df = pd.concat([full_internal, full_descriptors], axis=1)\nm_cols = full_descriptors.columns\ntemp = full_df.dropna(subset=names)\nXs_all = temp[m_cols]\nys_all = temp[names].apply(pd.to_numeric,errors='coerce').apply(lambda x: x*1e-9).apply(np.log10)\nys_all = -ys_all\n\ncorr_matrix = Xs_all.corr().abs()\n#upper triangle\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(Xs_all, ys_all[names[0]], test_size=0.2, random_state=7)\ngbr = XGBRegressor(\n  learning_rate =0.1,\n  n_estimators=150,\n  max_depth=6,\n  min_child_weight=1,\n  gamma=0,\n  subsample=0.8,\n  colsample_bytree=0.8,\n  nthread=4,\n  scale_pos_weight=1,\n  seed=27)\n\n\ndef filter_x_by_corr(thresh):\n  to_drop = [column for column in upper.columns if any(upper[column] > thresh)]\n  X_train.f = X_train.drop(full_descriptors[to_drop], axis=1)\n  X_test.f = X_test.drop(full_descriptors[to_drop], axis=1)\n  return X_train.f, X_test.f\n\nthresholds=[0.2,0.3,0.4,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.9]\nresults = defaultdict(list)\nfor thresh in thresholds:\n  X_train.f, X_test.f = filter_x_by_corr(thresh)\n  gbr.fit(X_train.f, y_train)\n  y_pred = gbr.predict(X_test.f)\n  #predictions = [round(value) for value in y_pred]\n  rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n  var_score = explained_variance_score(y_test, y_pred)\n  results['Threshold'].append(thresh)\n  results['N_descriptors'].append(X_train.f.shape[1])\n  results['RMSE'].append(round(rmse, 2))\n  results['Explained_var'].append(round(var_score, 2))\ndisplay(pd.DataFrame.from_dict(results))"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["param_test = {\n 'max_depth':range(3,10),\n 'min_child_weight':range(1,8),\n 'gamma':[i/10.0 for i in range(0,8)],\n 'subsample':[i/10.0 for i in range(4,12)],\n 'colsample_bytree':[i/10.0 for i in range(4,12)],\n 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["# trying out"],"metadata":{}},{"cell_type":"code","source":["Train_4y = pd.read_csv(os.path.join(CHEMPROP_DIR,'JAK','train-1460.csv'))\nVal_4y = pd.read_csv(os.path.join(CHEMPROP_DIR,'JAK','val-182.csv'))\nTest_4y = pd.read_csv(os.path.join(CHEMPROP_DIR,'JAK','test-183.csv'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":28},{"cell_type":"code","source":["print(len(Train_4y))\nprint(len(Val_4y))\nprint(len(Test_4y))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1460\n182\n183\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["All_4y = Train_4y.append(Val_4y).append(Test_4y)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":30},{"cell_type":"code","source":["display(Train_4y.head())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>smiles</th><th>JAK1 EC50 nM 1027</th><th>JAK2 EC50 nM 1024</th><th>JAK3 EC50 nM 1026</th><th>TYK2 EC50 nM 1025</th></tr></thead><tbody><tr><td>Cc1c[nH]c(C(=O)N2CCCN(c3ncnc4[nH]ccc34)CC23CC3)c1</td><td>7.856985199745905</td><td>7.946921556516581</td><td>6.886056647693162</td><td>6.82102305270683</td></tr><tr><td>O=S(=O)(N(CCN1CCOCC1)C1CCC1)N1CCN(c2ncnc3[nH]ccc23)CC12CC2</td><td>7.0695604052332985</td><td>7.357535479757877</td><td>6.33161408331</td><td>6.157390760389438</td></tr><tr><td>CN(C[C@@H]1CCCN1S(C)(=O)=O)S(=O)(=O)N1CCN(c2ncnc3[nH]ccc23)CC12CC2</td><td>7.732828271596986</td><td>7.832682665251823</td><td>6.966576244513051</td><td>6.376750709602098</td></tr><tr><td>CC(=O)N1CC[C@H]1COC(=O)N1C2CCC1CN(c1ncnc3[nH]ccc13)C2</td><td>6.7544873321858505</td><td>6.665546248849069</td><td>6.244887733604928</td><td>5.379863945026242</td></tr><tr><td>N#Cc1ccc(CC(=O)N2CCN(c3ncnc4[nH]ccc34)C3(CC3)C2)cc1</td><td>6.5044556624535526</td><td>6.1487416512809245</td><td>5.782516055786092</td><td>5.235077015350113</td></tr></tbody></table></div>"]}}],"execution_count":31},{"cell_type":"code","source":["all_fps = [Chem.MolFromSmiles(smi) for smi in All_4y['smiles']]\nfps = get_fps(all_fps, morgan=True)\n#get_fps([Chem.MolFromSmiles('Cc1c[nH]c(C(=O)N2CCCN(c3ncnc4[nH]ccc34)CC23CC3)c1')],bit=True)\nv = sklearn.feature_extraction.DictVectorizer(sparse=True, dtype=float)\nv.fit(fps)\nprint(len(v.feature_names_))\nprint(len(v.vocabulary_))\n\nX = v.transform(fps)\n\nX = X.toarray()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Errors in conversion: 0\n3689\n3689\n</div>"]}}],"execution_count":32},{"cell_type":"code","source":["Train_X = X[:1460]\nVal_X = X[1460:1460+182]\nTest_X = X[1460+182:1460+182+183]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":33},{"cell_type":"code","source":["# Model with default hyperparameters\nlgbmodel = lgb.LGBMRegressor()\nlgbmodel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: \nLGBMRegressor(boosting_type=&#39;gbdt&#39;, class_weight=None, colsample_bytree=1.0,\n       importance_type=&#39;split&#39;, learning_rate=0.1, max_depth=-1,\n       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n       n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n</div>"]}}],"execution_count":34},{"cell_type":"code","source":["xgbmodel = XGBRegressor()\nxgbmodel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[14]: \nXGBRegressor(base_score=0.5, booster=&#39;gbtree&#39;, colsample_bylevel=1,\n       colsample_bytree=1, gamma=0, importance_type=&#39;gain&#39;,\n       learning_rate=0.1, max_delta_step=0, max_depth=3,\n       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n       nthread=None, objective=&#39;reg:linear&#39;, random_state=0, reg_alpha=0,\n       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n       subsample=1)\n</div>"]}}],"execution_count":35},{"cell_type":"code","source":["import csv\nfrom hyperopt import STATUS_OK\nfrom timeit import default_timer as timer\niter=0\ndef objective(params, n_folds = N_FOLDS):\n    global iter\n    iter += 1\n    \n    subsample = params['boosting_type'].get('subsample', 1.0)\n    \n    params['boosting_type'] = params['boosting_type']['boosting_type']\n    params['subsample'] = subsample\n    \n    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n        params[parameter_name] = int(params[parameter_name])\n    \n    start = timer()\n    \n    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, nfold = n_folds, \n                        early_stopping_rounds = 100, metrics = 'rmse', seed = 13,stratified=False)\n    \n    run_time = timer() - start\n    \n    loss = np.min(cv_results['rmse-mean'])\n    print('best_score:',loss)\n    \n    n_estimators = int(np.argmin(cv_results['rmse-mean']) + 1)\n\n    logfile = open(out_file, 'a')\n    writer = csv.writer(logfile)\n    writer.writerow([loss, params, iter, n_estimators, run_time])\n    \n    return {'loss': loss, 'params': params, 'iteration': iter,\n            'estimators': n_estimators, \n            'train_time': run_time, 'status': STATUS_OK}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":36},{"cell_type":"code","source":["space = {\n    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n                                                 {'boosting_type': 'goss', 'subsample': 1.0}]),\n    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":37},{"cell_type":"code","source":["\nout_file = os.path.join(XGB_DIR,'gbm_trials.csv')\nlogfile = open(out_file, 'w')\nwriter = csv.writer(logfile)\n\nwriter.writerow(['loss', 'params', 'iteration', 'estimators', 'train_time'])\nlogfile.close()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":38},{"cell_type":"code","source":["global iter\niter=0\nlgbmodel = lgb.LGBMRegressor()\ntrain_set = lgb.Dataset(Train_X, label = Train_4y[names[0]])\nbest = fmin(fn = objective, space = space, algo = tpe.suggest, \n            max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(13))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\r  0%|          | 0/100 [00:00&lt;?, ?it/s, best loss: ?]\r                                                     \rbest_score:\n\r  0%|          | 0/100 [00:07&lt;?, ?it/s, best loss: ?]\r                                                     \r0.5502175798729334\n\r  0%|          | 0/100 [00:07&lt;?, ?it/s, best loss: ?]\r  1%|          | 1/100 [00:07&lt;12:51,  7.79s/it, best loss: 0.5502175798729334]\r                                                                              \rbest_score:\n\r  1%|          | 1/100 [00:27&lt;12:51,  7.79s/it, best loss: 0.5502175798729334]\r                                                                              \r0.7647355929918908\n\r  1%|          | 1/100 [00:27&lt;12:51,  7.79s/it, best loss: 0.5502175798729334]\r  2%|▏         | 2/100 [00:28&lt;18:50, 11.53s/it, best loss: 0.5502175798729334]\r                                                                              \rbest_score:\n\r  2%|▏         | 2/100 [00:28&lt;18:50, 11.53s/it, best loss: 0.5502175798729334]\r                                                                              \r0.9203129687560923\n\r  2%|▏         | 2/100 [00:28&lt;18:50, 11.53s/it, best loss: 0.5502175798729334]\r  3%|▎         | 3/100 [00:28&lt;13:13,  8.18s/it, best loss: 0.5502175798729334]\r                                                                              \rbest_score:\n\r  3%|▎         | 3/100 [00:32&lt;13:13,  8.18s/it, best loss: 0.5502175798729334]\r                                                                              \r0.5543020993080805\n\r  3%|▎         | 3/100 [00:32&lt;13:13,  8.18s/it, best loss: 0.5502175798729334]\r  4%|▍         | 4/100 [00:32&lt;10:57,  6.85s/it, best loss: 0.5502175798729334]\r                                                                              \rbest_score:\n\r  4%|▍         | 4/100 [00:32&lt;10:57,  6.85s/it, best loss: 0.5502175798729334]\r                                                                              \r0.7158925575522768\n\r  4%|▍         | 4/100 [00:32&lt;10:57,  6.85s/it, best loss: 0.5502175798729334]\r  5%|▌         | 5/100 [00:32&lt;07:50,  4.96s/it, best loss: 0.5502175798729334]\r                                                                              \rbest_score:\n\r  5%|▌         | 5/100 [00:44&lt;07:50,  4.96s/it, best loss: 0.5502175798729334]\r                                                                              \r0.5602758413987451\n\r  5%|▌         | 5/100 [00:44&lt;07:50,  4.96s/it, best loss: 0.5502175798729334]\r  6%|▌         | 6/100 [00:44&lt;10:52,  6.94s/it, best loss: 0.5502175798729334]\r                                                                              \rbest_score:\n\r  6%|▌         | 6/100 [01:07&lt;10:52,  6.94s/it, best loss: 0.5502175798729334]\r                                                                              \r0.5619718060026441\n\r  6%|▌         | 6/100 [01:07&lt;10:52,  6.94s/it, best loss: 0.5502175798729334]\r  7%|▋         | 7/100 [01:07&lt;18:12, 11.75s/it, best loss: 0.5502175798729334]\r                                                                              \rbest_score:\n\r  7%|▋         | 7/100 [01:20&lt;18:12, 11.75s/it, best loss: 0.5502175798729334]\r                                                                              \r0.6790442365117748\n\r  7%|▋         | 7/100 [01:20&lt;18:12, 11.75s/it, best loss: 0.5502175798729334]\r  8%|▊         | 8/100 [01:20&lt;18:32, 12.09s/it, best loss: 0.5502175798729334]\r                                                                              \rbest_score:\n\r  8%|▊         | 8/100 [01:20&lt;18:32, 12.09s/it, best loss: 0.5502175798729334]\r                                                                              \r0.8557748901756701\n\r  8%|▊         | 8/100 [01:20&lt;18:32, 12.09s/it, best loss: 0.5502175798729334]\r  9%|▉         | 9/100 [01:20&lt;12:59,  8.56s/it, best loss: 0.5502175798729334]\r                                                                              \rbest_score:\n\r  9%|▉         | 9/100 [01:42&lt;12:59,  8.56s/it, best loss: 0.5502175798729334]\r                                                                              \r0.5951413896301494\n\r  9%|▉         | 9/100 [01:42&lt;12:59,  8.56s/it, best loss: 0.5502175798729334]\r 10%|█         | 10/100 [01:42&lt;18:48, 12.54s/it, best loss: 0.5502175798729334]\r                                                                               \rbest_score:\n\r 10%|█         | 10/100 [01:58&lt;18:48, 12.54s/it, best loss: 0.5502175798729334]\r                                                                               \r0.7987255422215165\n\r 10%|█         | 10/100 [01:58&lt;18:48, 12.54s/it, best loss: 0.5502175798729334]\r 11%|█         | 11/100 [01:58&lt;20:15, 13.66s/it, best loss: 0.5502175798729334]\r                                                                               \rbest_score:\n\r 11%|█         | 11/100 [02:21&lt;20:15, 13.66s/it, best loss: 0.5502175798729334]\r                                                                               \r0.8838805640230598\n\r 11%|█         | 11/100 [02:21&lt;20:15, 13.66s/it, best loss: 0.5502175798729334]\r 12%|█▏        | 12/100 [02:22&lt;24:24, 16.65s/it, best loss: 0.5502175798729334]\r                                                                               \rbest_score:\n\r 12%|█▏        | 12/100 [02:32&lt;24:24, 16.65s/it, best loss: 0.5502175798729334]\r                                                                               \r0.8707299226088789\n\r 12%|█▏        | 12/100 [02:32&lt;24:24, 16.65s/it, best loss: 0.5502175798729334]\r 13%|█▎        | 13/100 [02:32&lt;21:33, 14.86s/it, best loss: 0.5502175798729334]\r                                                                               \rbest_score:\n\r 13%|█▎        | 13/100 [02:33&lt;21:33, 14.86s/it, best loss: 0.5502175798729334]\r                                                                               \r0.9188147086835656\n\r 13%|█▎        | 13/100 [02:33&lt;21:33, 14.86s/it, best loss: 0.5502175798729334]\r 14%|█▍        | 14/100 [02:33&lt;15:07, 10.55s/it, best loss: 0.5502175798729334]\r                                                                               \rbest_score:\n\r 14%|█▍        | 14/100 [02:36&lt;15:07, 10.55s/it, best loss: 0.5502175798729334]\r                                                                               \r0.5444591314072215\n\r 14%|█▍        | 14/100 [02:36&lt;15:07, 10.55s/it, best loss: 0.5502175798729334]\r 15%|█▌        | 15/100 [02:36&lt;11:40,  8.24s/it, best loss: 0.5444591314072215]\r                                                                               \rbest_score:\n\r 15%|█▌        | 15/100 [02:59&lt;11:40,  8.24s/it, best loss: 0.5444591314072215]\r                                                                               \r0.8842015351135079\n\r 15%|█▌        | 15/100 [02:59&lt;11:40,  8.24s/it, best loss: 0.5444591314072215]\r 16%|█▌        | 16/100 [03:00&lt;18:06, 12.93s/it, best loss: 0.5444591314072215]\r                                                                               \rbest_score:\n\r 16%|█▌        | 16/100 [03:05&lt;18:06, 12.93s/it, best loss: 0.5444591314072215]\r                                                                               \r0.5453787290631367\n\r 16%|█▌        | 16/100 [03:05&lt;18:06, 12.93s/it, best loss: 0.5444591314072215]\r 17%|█▋        | 17/100 [03:05&lt;14:37, 10.57s/it, best loss: 0.5444591314072215]\r                                                                               \rbest_score:\n\r 17%|█▋        | 17/100 [03:18&lt;14:37, 10.57s/it, best loss: 0.5444591314072215]\r                                                                               \r0.5904406060771425\n\r 17%|█▋        | 17/100 [03:18&lt;14:37, 10.57s/it, best loss: 0.5444591314072215]\r 18%|█▊        | 18/100 [03:18&lt;15:27, 11.32s/it, best loss: 0.5444591314072215]\r                                                                               \rbest_score:\n\r 18%|█▊        | 18/100 [03:18&lt;15:27, 11.32s/it, best loss: 0.5444591314072215]\r                                                                               \r0.7740024547017154\n\r 18%|█▊        | 18/100 [03:18&lt;15:27, 11.32s/it, best loss: 0.5444591314072215]\r 19%|█▉        | 19/100 [03:18&lt;10:53,  8.07s/it, best loss: 0.5444591314072215]\r                                                                               \rbest_score:\n\r 19%|█▉        | 19/100 [03:43&lt;10:53,  8.07s/it, best loss: 0.5444591314072215]\r                                                                               \r0.791039958399149\n\r 19%|█▉        | 19/100 [03:43&lt;10:53,  8.07s/it, best loss: 0.5444591314072215]\r 20%|██        | 20/100 [03:43&lt;17:19, 12.99s/it, best loss: 0.5444591314072215]\r                                                                               \rbest_score:\n\r 20%|██        | 20/100 [03:57&lt;17:19, 12.99s/it, best loss: 0.5444591314072215]\r                                                                               \r0.53941004782344\n\r 20%|██        | 20/100 [03:57&lt;17:19, 12.99s/it, best loss: 0.5444591314072215]\r 21%|██        | 21/100 [03:57&lt;17:32, 13.32s/it, best loss: 0.53941004782344]  \r                                                                             \rbest_score:\n\r 21%|██        | 21/100 [04:07&lt;17:32, 13.32s/it, best loss: 0.53941004782344]\r                                                                             \r0.5331497922084825\n\r 21%|██        | 21/100 [04:07&lt;17:32, 13.32s/it, best loss: 0.53941004782344]\r 22%|██▏       | 22/100 [04:07&lt;16:05, 12.38s/it, best loss: 0.5331497922084825]\r                                                                               \rbest_score:\n\r 22%|██▏       | 22/100 [04:35&lt;16:05, 12.38s/it, best loss: 0.5331497922084825]\r                                                                               \r0.6775829910388823\n\r 22%|██▏       | 22/100 [04:35&lt;16:05, 12.38s/it, best loss: 0.5331497922084825]\r 23%|██▎       | 23/100 [04:35&lt;21:57, 17.12s/it, best loss: 0.5331497922084825]\r                                                                               \rbest_score:\n\r 23%|██▎       | 23/100 [05:07&lt;21:57, 17.12s/it, best loss: 0.5331497922084825]\r                                                                               \r0.6212072940340624\n\r 23%|██▎       | 23/100 [05:07&lt;21:57, 17.12s/it, best loss: 0.5331497922084825]\r 24%|██▍       | 24/100 [05:07&lt;27:29, 21.70s/it, best loss: 0.5331497922084825]\r                                                                               \rbest_score:\n\r 24%|██▍       | 24/100 [05:18&lt;27:29, 21.70s/it, best loss: 0.5331497922084825]\r                                                                               \r0.5335586511423582\n\r 24%|██▍       | 24/100 [05:18&lt;27:29, 21.70s/it, best loss: 0.5331497922084825]\r 25%|██▌       | 25/100 [05:18&lt;22:46, 18.22s/it, best loss: 0.5331497922084825]\r                                                                               \rbest_score:\n\r 25%|██▌       | 25/100 [05:20&lt;22:46, 18.22s/it, best loss: 0.5331497922084825]\r                                                                               \r0.6517003346390119\n\r 25%|██▌       | 25/100 [05:20&lt;22:46, 18.22s/it, best loss: 0.5331497922084825]\r 26%|██▌       | 26/100 [05:20&lt;16:38, 13.49s/it, best loss: 0.5331497922084825]\r                                                                               \rbest_score:\n\r 26%|██▌       | 26/100 [05:47&lt;16:38, 13.49s/it, best loss: 0.5331497922084825]\r                                                                               \r0.6532049951814723\n\r 26%|██▌       | 26/100 [05:47&lt;16:38, 13.49s/it, best loss: 0.5331497922084825]\r 27%|██▋       | 27/100 [05:47&lt;21:28, 17.65s/it, best loss: 0.5331497922084825]\r                                                                               \rbest_score:\n\r 27%|██▋       | 27/100 [06:21&lt;21:28, 17.65s/it, best loss: 0.5331497922084825]\r                                                                               \r0.5880272439071513\n\r 27%|██▋       | 27/100 [06:21&lt;21:28, 17.65s/it, best loss: 0.5331497922084825]\r 28%|██▊       | 28/100 [06:21&lt;26:49, 22.36s/it, best loss: 0.5331497922084825]\r                                                                               \rbest_score:\n\r 28%|██▊       | 28/100 [06:49&lt;26:49, 22.36s/it, best loss: 0.5331497922084825]\r                                                                               \r0.6269204513163189\n\r 28%|██▊       | 28/100 [06:49&lt;26:49, 22.36s/it, best loss: 0.5331497922084825]\r 29%|██▉       | 29/100 [06:49&lt;28:35, 24.16s/it, best loss: 0.5331497922084825]\r                                                                               \rbest_score:\n\r 29%|██▉       | 29/100 [06:51&lt;28:35, 24.16s/it, best loss: 0.5331497922084825]\r                                                                               \r0.782323316743705\n\r 29%|██▉       | 29/100 [06:51&lt;28:35, 24.16s/it, best loss: 0.5331497922084825]\r 30%|███       | 30/100 [06:51&lt;20:23, 17.48s/it, best loss: 0.5331497922084825]\r                                                                               \rbest_score:\n\r 30%|███       | 30/100 [07:01&lt;20:23, 17.48s/it, best loss: 0.5331497922084825]\r                                                                               \r0.5319142836963748\n\r 30%|███       | 30/100 [07:01&lt;20:23, 17.48s/it, best loss: 0.5331497922084825]\r 31%|███       | 31/100 [07:01&lt;17:27, 15.19s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 31%|███       | 31/100 [07:27&lt;17:27, 15.19s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6941569766008385\n\r 31%|███       | 31/100 [07:27&lt;17:27, 15.19s/it, best loss: 0.5319142836963748]\r 32%|███▏      | 32/100 [07:27&lt;21:05, 18.61s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 32%|███▏      | 32/100 [07:53&lt;21:05, 18.61s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5459080302579203\n\r 32%|███▏      | 32/100 [07:53&lt;21:05, 18.61s/it, best loss: 0.5319142836963748]\r 33%|███▎      | 33/100 [07:53&lt;23:03, 20.65s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 33%|███▎      | 33/100 [07:53&lt;23:03, 20.65s/it, best loss: 0.5319142836963748]\r                                                                               \r0.8852622023128243\n\r 33%|███▎      | 33/100 [07:53&lt;23:03, 20.65s/it, best loss: 0.5319142836963748]\r 34%|███▍      | 34/100 [07:53&lt;16:01, 14.57s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 34%|███▍      | 34/100 [08:30&lt;16:01, 14.57s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5848435085594449\n\r 34%|███▍      | 34/100 [08:30&lt;16:01, 14.57s/it, best loss: 0.5319142836963748]\r 35%|███▌      | 35/100 [08:30&lt;22:58, 21.21s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 35%|███▌      | 35/100 [08:40&lt;22:58, 21.21s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5564618632113512\n\r 35%|███▌      | 35/100 [08:40&lt;22:58, 21.21s/it, best loss: 0.5319142836963748]\r 36%|███▌      | 36/100 [08:40&lt;19:00, 17.82s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 36%|███▌      | 36/100 [08:40&lt;19:00, 17.82s/it, best loss: 0.5319142836963748]\r                                                                               \r0.7498269027406653\n\r 36%|███▌      | 36/100 [08:40&lt;19:00, 17.82s/it, best loss: 0.5319142836963748]\r 37%|███▋      | 37/100 [08:40&lt;13:14, 12.61s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 37%|███▋      | 37/100 [08:51&lt;13:14, 12.61s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5581691597548614\n\r 37%|███▋      | 37/100 [08:51&lt;13:14, 12.61s/it, best loss: 0.5319142836963748]\r 38%|███▊      | 38/100 [08:51&lt;12:26, 12.04s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 38%|███▊      | 38/100 [09:21&lt;12:26, 12.04s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6228260605763323\n\r 38%|███▊      | 38/100 [09:21&lt;12:26, 12.04s/it, best loss: 0.5319142836963748]\r 39%|███▉      | 39/100 [09:21&lt;17:39, 17.38s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 39%|███▉      | 39/100 [09:59&lt;17:39, 17.38s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5849798186169186\n\r 39%|███▉      | 39/100 [09:59&lt;17:39, 17.38s/it, best loss: 0.5319142836963748]\r 40%|████      | 40/100 [09:59&lt;23:42, 23.71s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 40%|████      | 40/100 [10:00&lt;23:42, 23.71s/it, best loss: 0.5319142836963748]\r                                                                               \r0.8848626528288055\n\r 40%|████      | 40/100 [10:00&lt;23:42, 23.71s/it, best loss: 0.5319142836963748]\r 41%|████      | 41/100 [10:00&lt;16:25, 16.71s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 41%|████      | 41/100 [10:33&lt;16:25, 16.71s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6129029213862369\n\r 41%|████      | 41/100 [10:33&lt;16:25, 16.71s/it, best loss: 0.5319142836963748]\r 42%|████▏     | 42/100 [10:34&lt;21:07, 21.85s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 42%|████▏     | 42/100 [10:51&lt;21:07, 21.85s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5558223449163727\n\r 42%|████▏     | 42/100 [10:51&lt;21:07, 21.85s/it, best loss: 0.5319142836963748]\r 43%|████▎     | 43/100 [10:51&lt;19:34, 20.61s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 43%|████▎     | 43/100 [10:53&lt;19:34, 20.61s/it, best loss: 0.5319142836963748]\r                                                                               \r0.536847225923556\n\r 43%|████▎     | 43/100 [10:53&lt;19:34, 20.61s/it, best loss: 0.5319142836963748]\r 44%|████▍     | 44/100 [10:53&lt;14:02, 15.05s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 44%|████▍     | 44/100 [10:54&lt;14:02, 15.05s/it, best loss: 0.5319142836963748]\r                                                                               \r0.8265407372305547\n\r 44%|████▍     | 44/100 [10:54&lt;14:02, 15.05s/it, best loss: 0.5319142836963748]\r 45%|████▌     | 45/100 [10:54&lt;09:46, 10.66s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 45%|████▌     | 45/100 [11:18&lt;09:46, 10.66s/it, best loss: 0.5319142836963748]\r                                                                               \r0.7154706238416345\n\r 45%|████▌     | 45/100 [11:18&lt;09:46, 10.66s/it, best loss: 0.5319142836963748]\r 46%|████▌     | 46/100 [11:18&lt;13:09, 14.63s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 46%|████▌     | 46/100 [11:41&lt;13:09, 14.63s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6385913248837699\n\r 46%|████▌     | 46/100 [11:41&lt;13:09, 14.63s/it, best loss: 0.5319142836963748]\r 47%|████▋     | 47/100 [11:41&lt;15:21, 17.39s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 47%|████▋     | 47/100 [12:08&lt;15:21, 17.39s/it, best loss: 0.5319142836963748]\r                                                                               \r0.593698962393253\n\r 47%|████▋     | 47/100 [12:08&lt;15:21, 17.39s/it, best loss: 0.5319142836963748]\r 48%|████▊     | 48/100 [12:08&lt;17:27, 20.14s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 48%|████▊     | 48/100 [12:10&lt;17:27, 20.14s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6841066256637592\n\r 48%|████▊     | 48/100 [12:10&lt;17:27, 20.14s/it, best loss: 0.5319142836963748]\r 49%|████▉     | 49/100 [12:10&lt;12:34, 14.80s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 49%|████▉     | 49/100 [12:14&lt;12:34, 14.80s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5520552429476695\n\r 49%|████▉     | 49/100 [12:14&lt;12:34, 14.80s/it, best loss: 0.5319142836963748]\r 50%|█████     | 50/100 [12:15&lt;09:40, 11.62s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 50%|█████     | 50/100 [12:38&lt;09:40, 11.62s/it, best loss: 0.5319142836963748]\r                                                                               \r0.8397534143274837\n\r 50%|█████     | 50/100 [12:38&lt;09:40, 11.62s/it, best loss: 0.5319142836963748]\r 51%|█████     | 51/100 [12:38&lt;12:22, 15.16s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 51%|█████     | 51/100 [12:54&lt;12:22, 15.16s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5531101908944543\n\r 51%|█████     | 51/100 [12:54&lt;12:22, 15.16s/it, best loss: 0.5319142836963748]\r 52%|█████▏    | 52/100 [12:54&lt;12:14, 15.31s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 52%|█████▏    | 52/100 [13:25&lt;12:14, 15.31s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6214715238179127\n\r 52%|█████▏    | 52/100 [13:25&lt;12:14, 15.31s/it, best loss: 0.5319142836963748]\r 53%|█████▎    | 53/100 [13:25&lt;15:45, 20.12s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 53%|█████▎    | 53/100 [13:25&lt;15:45, 20.12s/it, best loss: 0.5319142836963748]\r                                                                               \r0.8986627589898296\n\r 53%|█████▎    | 53/100 [13:25&lt;15:45, 20.12s/it, best loss: 0.5319142836963748]\r 54%|█████▍    | 54/100 [13:25&lt;10:53, 14.21s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 54%|█████▍    | 54/100 [13:37&lt;10:53, 14.21s/it, best loss: 0.5319142836963748]\r                                                                               \r0.560330653248964\n\r 54%|█████▍    | 54/100 [13:37&lt;10:53, 14.21s/it, best loss: 0.5319142836963748]\r 55%|█████▌    | 55/100 [13:37&lt;10:02, 13.38s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 55%|█████▌    | 55/100 [13:57&lt;10:02, 13.38s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6384958327447208\n\r 55%|█████▌    | 55/100 [13:57&lt;10:02, 13.38s/it, best loss: 0.5319142836963748]\r 56%|█████▌    | 56/100 [13:57&lt;11:18, 15.42s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 56%|█████▌    | 56/100 [14:05&lt;11:18, 15.42s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5404586275721976\n\r 56%|█████▌    | 56/100 [14:05&lt;11:18, 15.42s/it, best loss: 0.5319142836963748]\r 57%|█████▋    | 57/100 [14:05&lt;09:25, 13.15s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 57%|█████▋    | 57/100 [14:05&lt;09:25, 13.15s/it, best loss: 0.5319142836963748]\r                                                                               \r0.8342307317619679\n\r 57%|█████▋    | 57/100 [14:05&lt;09:25, 13.15s/it, best loss: 0.5319142836963748]\r 58%|█████▊    | 58/100 [14:05&lt;06:33,  9.37s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 58%|█████▊    | 58/100 [14:34&lt;06:33,  9.37s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6887107607682741\n\r 58%|█████▊    | 58/100 [14:34&lt;06:33,  9.37s/it, best loss: 0.5319142836963748]\r 59%|█████▉    | 59/100 [14:35&lt;10:26, 15.29s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 59%|█████▉    | 59/100 [14:44&lt;10:26, 15.29s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5786642251209584\n\r 59%|█████▉    | 59/100 [14:44&lt;10:26, 15.29s/it, best loss: 0.5319142836963748]\r 60%|██████    | 60/100 [14:44&lt;09:06, 13.67s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 60%|██████    | 60/100 [14:56&lt;09:06, 13.67s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5450429639203976\n\r 60%|██████    | 60/100 [14:56&lt;09:06, 13.67s/it, best loss: 0.5319142836963748]\r 61%|██████    | 61/100 [14:56&lt;08:29, 13.07s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 61%|██████    | 61/100 [14:57&lt;08:29, 13.07s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6943699378353528\n\r 61%|██████    | 61/100 [14:57&lt;08:29, 13.07s/it, best loss: 0.5319142836963748]\r 62%|██████▏   | 62/100 [14:57&lt;05:56,  9.38s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 62%|██████▏   | 62/100 [15:20&lt;05:56,  9.38s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6947570057224433\n\r 62%|██████▏   | 62/100 [15:20&lt;05:56,  9.38s/it, best loss: 0.5319142836963748]\r 63%|██████▎   | 63/100 [15:20&lt;08:18, 13.46s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 63%|██████▎   | 63/100 [15:27&lt;08:18, 13.46s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6436757705550226\n\r 63%|██████▎   | 63/100 [15:27&lt;08:18, 13.46s/it, best loss: 0.5319142836963748]\r 64%|██████▍   | 64/100 [15:27&lt;07:00, 11.67s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 64%|██████▍   | 64/100 [15:37&lt;07:00, 11.67s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5405774571032778\n\r 64%|██████▍   | 64/100 [15:37&lt;07:00, 11.67s/it, best loss: 0.5319142836963748]\r 65%|██████▌   | 65/100 [15:38&lt;06:33, 11.26s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 65%|██████▌   | 65/100 [15:48&lt;06:33, 11.26s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5455590972615136\n\r 65%|██████▌   | 65/100 [15:48&lt;06:33, 11.26s/it, best loss: 0.5319142836963748]\r 66%|██████▌   | 66/100 [15:49&lt;06:19, 11.16s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 66%|██████▌   | 66/100 [15:58&lt;06:19, 11.16s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5329694302057353\n\r 66%|██████▌   | 66/100 [15:58&lt;06:19, 11.16s/it, best loss: 0.5319142836963748]\r 67%|██████▋   | 67/100 [15:58&lt;05:53, 10.72s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 67%|██████▋   | 67/100 [16:19&lt;05:53, 10.72s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5481355688359016\n\r 67%|██████▋   | 67/100 [16:19&lt;05:53, 10.72s/it, best loss: 0.5319142836963748]\r 68%|██████▊   | 68/100 [16:19&lt;07:20, 13.77s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 68%|██████▊   | 68/100 [16:45&lt;07:20, 13.77s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5688127344808784\n\r 68%|██████▊   | 68/100 [16:45&lt;07:20, 13.77s/it, best loss: 0.5319142836963748]\r 69%|██████▉   | 69/100 [16:46&lt;09:04, 17.56s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 69%|██████▉   | 69/100 [17:09&lt;09:04, 17.56s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5615794677654967\n\r 69%|██████▉   | 69/100 [17:09&lt;09:04, 17.56s/it, best loss: 0.5319142836963748]\r 70%|███████   | 70/100 [17:09&lt;09:36, 19.22s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 70%|███████   | 70/100 [17:26&lt;09:36, 19.22s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5437626673504773\n\r 70%|███████   | 70/100 [17:26&lt;09:36, 19.22s/it, best loss: 0.5319142836963748]\r 71%|███████   | 71/100 [17:26&lt;09:04, 18.77s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 71%|███████   | 71/100 [17:39&lt;09:04, 18.77s/it, best loss: 0.5319142836963748]\r                                                                               \r0.542489714812193\n\r 71%|███████   | 71/100 [17:39&lt;09:04, 18.77s/it, best loss: 0.5319142836963748]\r 72%|███████▏  | 72/100 [17:40&lt;07:58, 17.09s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 72%|███████▏  | 72/100 [17:50&lt;07:58, 17.09s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5347108582112587\n\r 72%|███████▏  | 72/100 [17:50&lt;07:58, 17.09s/it, best loss: 0.5319142836963748]\r 73%|███████▎  | 73/100 [17:50&lt;06:47, 15.11s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 73%|███████▎  | 73/100 [18:21&lt;06:47, 15.11s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6460356262813234\n\r 73%|███████▎  | 73/100 [18:21&lt;06:47, 15.11s/it, best loss: 0.5319142836963748]\r 74%|███████▍  | 74/100 [18:21&lt;08:38, 19.96s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 74%|███████▍  | 74/100 [19:00&lt;08:38, 19.96s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5680134567236341\n\r 74%|███████▍  | 74/100 [19:00&lt;08:38, 19.96s/it, best loss: 0.5319142836963748]\r 75%|███████▌  | 75/100 [19:00&lt;10:36, 25.48s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 75%|███████▌  | 75/100 [19:33&lt;10:36, 25.48s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5853881050495761\n\r 75%|███████▌  | 75/100 [19:33&lt;10:36, 25.48s/it, best loss: 0.5319142836963748]\r 76%|███████▌  | 76/100 [19:33&lt;11:09, 27.92s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 76%|███████▌  | 76/100 [19:34&lt;11:09, 27.92s/it, best loss: 0.5319142836963748]\r                                                                               \r0.845738204956408\n\r 76%|███████▌  | 76/100 [19:34&lt;11:09, 27.92s/it, best loss: 0.5319142836963748]\r 77%|███████▋  | 77/100 [19:34&lt;07:32, 19.69s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 77%|███████▋  | 77/100 [20:07&lt;07:32, 19.69s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5948253214972037\n\r 77%|███████▋  | 77/100 [20:07&lt;07:32, 19.69s/it, best loss: 0.5319142836963748]\r 78%|███████▊  | 78/100 [20:07&lt;08:40, 23.68s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 78%|███████▊  | 78/100 [20:24&lt;08:40, 23.68s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5469255817703186\n\r 78%|███████▊  | 78/100 [20:24&lt;08:40, 23.68s/it, best loss: 0.5319142836963748]\r 79%|███████▉  | 79/100 [20:24&lt;07:37, 21.78s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 79%|███████▉  | 79/100 [20:48&lt;07:37, 21.78s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5571522129568289\n\r 79%|███████▉  | 79/100 [20:48&lt;07:37, 21.78s/it, best loss: 0.5319142836963748]\r 80%|████████  | 80/100 [20:48&lt;07:30, 22.53s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 80%|████████  | 80/100 [20:51&lt;07:30, 22.53s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5446588755188849\n\r 80%|████████  | 80/100 [20:51&lt;07:30, 22.53s/it, best loss: 0.5319142836963748]\r 81%|████████  | 81/100 [20:51&lt;05:16, 16.64s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 81%|████████  | 81/100 [20:52&lt;05:16, 16.64s/it, best loss: 0.5319142836963748]\r                                                                               \r0.9663495966203358\n\r 81%|████████  | 81/100 [20:52&lt;05:16, 16.64s/it, best loss: 0.5319142836963748]\r 82%|████████▏ | 82/100 [20:52&lt;03:32, 11.80s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 82%|████████▏ | 82/100 [21:15&lt;03:32, 11.80s/it, best loss: 0.5319142836963748]\r                                                                               \r0.7957960690595391\n\r 82%|████████▏ | 82/100 [21:15&lt;03:32, 11.80s/it, best loss: 0.5319142836963748]\r 83%|████████▎ | 83/100 [21:15&lt;04:19, 15.29s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 83%|████████▎ | 83/100 [21:22&lt;04:19, 15.29s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5394843439463062\n\r 83%|████████▎ | 83/100 [21:22&lt;04:19, 15.29s/it, best loss: 0.5319142836963748]\r 84%|████████▍ | 84/100 [21:22&lt;03:24, 12.79s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 84%|████████▍ | 84/100 [21:47&lt;03:24, 12.79s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5589078198679581\n\r 84%|████████▍ | 84/100 [21:47&lt;03:24, 12.79s/it, best loss: 0.5319142836963748]\r 85%|████████▌ | 85/100 [21:47&lt;04:04, 16.31s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 85%|████████▌ | 85/100 [21:47&lt;04:04, 16.31s/it, best loss: 0.5319142836963748]\r                                                                               \r0.8429884896795669\n\r 85%|████████▌ | 85/100 [21:47&lt;04:04, 16.31s/it, best loss: 0.5319142836963748]\r 86%|████████▌ | 86/100 [21:47&lt;02:41, 11.55s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 86%|████████▌ | 86/100 [22:13&lt;02:41, 11.55s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5509087518264831\n\r 86%|████████▌ | 86/100 [22:13&lt;02:41, 11.55s/it, best loss: 0.5319142836963748]\r 87%|████████▋ | 87/100 [22:13&lt;03:26, 15.89s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 87%|████████▋ | 87/100 [22:15&lt;03:26, 15.89s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5453317331167465\n\r 87%|████████▋ | 87/100 [22:15&lt;03:26, 15.89s/it, best loss: 0.5319142836963748]\r 88%|████████▊ | 88/100 [22:15&lt;02:20, 11.73s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 88%|████████▊ | 88/100 [22:43&lt;02:20, 11.73s/it, best loss: 0.5319142836963748]\r                                                                               \r0.583064049368444\n\r 88%|████████▊ | 88/100 [22:43&lt;02:20, 11.73s/it, best loss: 0.5319142836963748]\r 89%|████████▉ | 89/100 [22:43&lt;03:02, 16.58s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 89%|████████▉ | 89/100 [22:55&lt;03:02, 16.58s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5328779121589994\n\r 89%|████████▉ | 89/100 [22:55&lt;03:02, 16.58s/it, best loss: 0.5319142836963748]\r 90%|█████████ | 90/100 [22:55&lt;02:32, 15.24s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 90%|█████████ | 90/100 [23:36&lt;02:32, 15.24s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5810681037066526\n\r 90%|█████████ | 90/100 [23:36&lt;02:32, 15.24s/it, best loss: 0.5319142836963748]\r 91%|█████████ | 91/100 [23:36&lt;03:25, 22.89s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 91%|█████████ | 91/100 [23:36&lt;03:25, 22.89s/it, best loss: 0.5319142836963748]\r                                                                               \r0.7915277242920084\n\r 91%|█████████ | 91/100 [23:36&lt;03:25, 22.89s/it, best loss: 0.5319142836963748]\r 92%|█████████▏| 92/100 [23:36&lt;02:09, 16.18s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 92%|█████████▏| 92/100 [24:06&lt;02:09, 16.18s/it, best loss: 0.5319142836963748]\r                                                                               \r0.7012031728040549\n\r 92%|█████████▏| 92/100 [24:06&lt;02:09, 16.18s/it, best loss: 0.5319142836963748]\r 93%|█████████▎| 93/100 [24:06&lt;02:20, 20.14s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 93%|█████████▎| 93/100 [24:31&lt;02:20, 20.14s/it, best loss: 0.5319142836963748]\r                                                                               \r0.7158570592689275\n\r 93%|█████████▎| 93/100 [24:31&lt;02:20, 20.14s/it, best loss: 0.5319142836963748]\r 94%|█████████▍| 94/100 [24:31&lt;02:10, 21.77s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 94%|█████████▍| 94/100 [24:35&lt;02:10, 21.77s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5322060963252964\n\r 94%|█████████▍| 94/100 [24:35&lt;02:10, 21.77s/it, best loss: 0.5319142836963748]\r 95%|█████████▌| 95/100 [24:35&lt;01:21, 16.27s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 95%|█████████▌| 95/100 [24:35&lt;01:21, 16.27s/it, best loss: 0.5319142836963748]\r                                                                               \r0.8030818845565169\n\r 95%|█████████▌| 95/100 [24:35&lt;01:21, 16.27s/it, best loss: 0.5319142836963748]\r 96%|█████████▌| 96/100 [24:35&lt;00:46, 11.52s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 96%|█████████▌| 96/100 [24:39&lt;00:46, 11.52s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5463811945608349\n\r 96%|█████████▌| 96/100 [24:39&lt;00:46, 11.52s/it, best loss: 0.5319142836963748]\r 97%|█████████▋| 97/100 [24:39&lt;00:27,  9.27s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 97%|█████████▋| 97/100 [25:02&lt;00:27,  9.27s/it, best loss: 0.5319142836963748]\r                                                                               \r0.6431179768101117\n\r 97%|█████████▋| 97/100 [25:02&lt;00:27,  9.27s/it, best loss: 0.5319142836963748]\r 98%|█████████▊| 98/100 [25:02&lt;00:26, 13.38s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 98%|█████████▊| 98/100 [25:12&lt;00:26, 13.38s/it, best loss: 0.5319142836963748]\r                                                                               \r0.5841898292034722\n\r 98%|█████████▊| 98/100 [25:12&lt;00:26, 13.38s/it, best loss: 0.5319142836963748]\r 99%|█████████▉| 99/100 [25:12&lt;00:12, 12.24s/it, best loss: 0.5319142836963748]\r                                                                               \rbest_score:\n\r 99%|█████████▉| 99/100 [25:32&lt;00:12, 12.24s/it, best loss: 0.5319142836963748]\r                                                                               \r0.8945208137828919\n\r 99%|█████████▉| 99/100 [25:32&lt;00:12, 12.24s/it, best loss: 0.5319142836963748]\r100%|██████████| 100/100 [25:32&lt;00:00, 14.53s/it, best loss: 0.5319142836963748]\n</div>"]}}],"execution_count":39},{"cell_type":"code","source":["best"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[26]: \n{&#39;boosting_type&#39;: 0,\n &#39;class_weight&#39;: 0,\n &#39;colsample_by_tree&#39;: 0.7593855006084105,\n &#39;gdbt_subsample&#39;: 0.7318441942731282,\n &#39;learning_rate&#39;: 0.013309721427152973,\n &#39;min_child_samples&#39;: 20.0,\n &#39;num_leaves&#39;: 123.0,\n &#39;reg_alpha&#39;: 0.22991023483702192,\n &#39;reg_lambda&#39;: 0.39725196762110565,\n &#39;subsample_for_bin&#39;: 180000.0}\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["import lightgbm as lgb\nfrom sklearn import cross_validation\n\nclf = lgb.sklearn.LGBMRegressor(\n                             colsample_bytree=0.7593855006084105,\n                             gdbt_subsample=0.7318441942731282,\n                             learning_rate=0.013309721427152973,\n                             min_child_samples=20,\n                             num_leaves=123,\n                             reg_alpha=0.22991023483702192,\n                             reg_lambda=0.39725196762110565,\n                             subsample_for_bin=180000, metrics='rmse',num_boost_round = 10000)\n\n\n\nTrain_X = X[:1460+182]\nTrain_4y = All_4y[:1460+182]\n\nTest_X = X[1460+182:1460+182+183]\n\npredicts = Test_4y\nfor name in names:\n  clf.fit(Train_X,Train_4y[name])\n  predicts[name]=clf.predict(Test_X)\npredicts.to_csv(os.path.join(XGB_DIR,'predicts20190514-Test.csv'),index=None)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n</div>"]}}],"execution_count":41},{"cell_type":"code","source":["import lightgbm as lgb\nfrom sklearn import cross_validation\n\nclf = lgb.sklearn.LGBMRegressor(\n                             colsample_bytree=0.7593855006084105,\n                             gdbt_subsample=0.7318441942731282,\n                             learning_rate=0.013309721427152973,\n                             min_child_samples=20,\n                             num_leaves=123,\n                             reg_alpha=0.22991023483702192,\n                             reg_lambda=0.39725196762110565,\n                             subsample_for_bin=180000, metrics='rmse',num_boost_round = 10000)\n\npredicts = All_4y\nfor name in names:\n  scores = cross_validation.cross_val_score(\n    clf, X, All_4y[name], cv=10, scoring='neg_mean_squared_error')\n  print(\"%s Accuracy: %0.5f (+/- %0.5f)\" % (\n    clf.__class__.__name__, scores.mean(), scores.std() * 2))\n  clf.fit(X,All_4y[name])\n  predicts[name]=clf.predict(X)\npredicts.to_csv(os.path.join(XGB_DIR,'predicts20190513-All.csv'),index=None)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\nLGBMRegressor Accuracy: -0.23049 (+/- 0.09103)\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\nLGBMRegressor Accuracy: -0.22537 (+/- 0.10359)\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\nLGBMRegressor Accuracy: -0.19015 (+/- 0.10585)\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\nLGBMRegressor Accuracy: -0.25019 (+/- 0.09279)\n/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n</div>"]}}],"execution_count":42},{"cell_type":"code","source":["import seaborn as sns; sns.set(color_codes=True)\nAll_4y = Train_4y.append(Val_4y).append(Test_4y)\ndiff_cp = All_4y.filter(names).subtract(predicts.filter(names)).abs()\ndiff_cp.columns=diff_cp.columns+['diff']\nplt.close()\nf, axes = plt.subplots(1, 4, sharex = True, sharey=True, figsize=(16,4))\nfor i in range(4):\n  sns.kdeplot(All_4y[names[i]], diff_cp[diff_cp.columns[i]], n_levels=10, cmap=\"Purples_d\",ax=axes[i],clip=((0,10),(0,1)))#\nplt.tight_layout()\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["lgbmodel = lgb.LGBMRegressor(\n                             colsample_bytree=0.7593855006084105,\n                             gdbt_subsample=0.7318441942731282,\n                             learning_rate=0.013309721427152973,\n                             min_child_samples=20,\n                             num_leaves=123,\n                             reg_alpha=0.22991023483702192,\n                             reg_lambda=0.39725196762110565,\n                             subsample_for_bin=180000)\npredicts = Test_4y\nfor name in names:\n  lgbmodel.fit(Train_X,Train_4y[name])\n\n  predicts[name]=lgbmodel.predict(Test_X)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":44},{"cell_type":"code","source":["predicts.to_csv(os.path.join(XGB_DIR,'predicts20190429.csv'),index=None)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":45},{"cell_type":"markdown","source":["# 4-fold domain CV"],"metadata":{}},{"cell_type":"code","source":["%run /Users/vxjdk@leo-pharma.com/mol_utils"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["domains = ['Homopiperazines','Piperazines','Piperidines','Sulphamides']\nframes = []\nfor j, file in enumerate(files):\n  frame = PandasTools.LoadSDF(file,\n                              smilesName='SMILES',molColName='Molecule', includeFingerprints=False)\n  frame.replace('newline',np.nan, inplace=True)\n  \n  frame.dropna(subset=names,inplace=True)\n  frame['domain'] = [domains[j] for i in range(len(frame))]\n  frames.append(frame)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":48},{"cell_type":"code","source":["all_bin = pd.concat(frames)\nall_bin.columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/local_disk0/tmp/1557118074189-0/PythonShell.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass &#39;sort=True&#39;.\n\nTo retain the current behavior and silence the warning, pass sort=False\n\n  from __future__ import absolute_import\nOut[31]: \nIndex([&#39;AlogP&#39;, &#39;Canonical Smiles&#39;, &#39;HBA&#39;, &#39;HBD&#39;, &#39;HLM Cl_app mL/min/kg 1065&#39;,\n       &#39;ID&#39;, &#39;JAK1 EC50 nM 1027&#39;, &#39;JAK2 EC50 nM 1024&#39;, &#39;JAK3 EC50 nM 1026&#39;,\n       &#39;Leonumber&#39;, &#39;LogD pH7.4 1192&#39;, &#39;Mol Psa&#39;, &#39;Molecule&#39;, &#39;Mw g/mol&#39;,\n       &#39;SMILES&#39;, &#39;STAT6 EC50 nM 1075&#39;, &#39;STAT6 Emax % 1075&#39;,\n       &#39;TYK2 EC50 nM 1025&#39;, &#39;domain&#39;, &#39;ope 1024&#39;, &#39;ope 1025&#39;, &#39;ope 1026&#39;,\n       &#39;ope 1027&#39;, &#39;ope 1065&#39;, &#39;ope 1075&#39;, &#39;ope 1192&#39;],\n      dtype=&#39;object&#39;)\n</div>"]}}],"execution_count":49},{"cell_type":"code","source":["for name in names:\n  all_bin[name] = all_bin[name].astype(float)\n  all_bin[name] = all_bin[name].apply(lambda x: 1 if x < 10 else 0)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":50},{"cell_type":"code","source":["all_bin = all_bin.filter(['Canonical Smiles','domain']+names)\nprint(all_bin.columns)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Index([&#39;Canonical Smiles&#39;, &#39;domain&#39;, &#39;JAK1 EC50 nM 1027&#39;, &#39;JAK2 EC50 nM 1024&#39;,\n       &#39;JAK3 EC50 nM 1026&#39;, &#39;TYK2 EC50 nM 1025&#39;],\n      dtype=&#39;object&#39;)\n</div>"]}}],"execution_count":51},{"cell_type":"code","source":["all_fps = [Chem.MolFromSmiles(smi) for smi in all_bin['Canonical Smiles']]\nfps = get_fps(all_fps, morgan=True)\nv = sklearn.feature_extraction.DictVectorizer(sparse=True, dtype=float)\nv.fit(fps)\nprint(len(v.feature_names_))\nprint(len(v.vocabulary_))\n\nX = v.transform(fps)\n\nX = X.toarray()\nprint(X.shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Errors in conversion: 0\n3689\n3689\n(1825, 3689)\n</div>"]}}],"execution_count":52},{"cell_type":"code","source":["domains"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[145]: []\n</div>"]}}],"execution_count":53},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\ncross_val_score(lgbmodel, Train_X, Train_4y[names[0]])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\nOut[51]: array([0.85948905, 0.80438757, 0.85009141])\n</div>"]}}],"execution_count":54},{"cell_type":"code","source":["from hyperopt import hp\nfrom hyperopt.pyll.stochastic import sample\n# Define the search space\nspace = {\n    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n                                                 {'boosting_type': 'goss', 'subsample': 1.0}]),\n    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n    #'n_estimators': hp.quniform('num_trees', 20, 1500, 1),\n    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":55},{"cell_type":"code","source":["import csv\nfrom hyperopt import STATUS_OK\nfrom timeit import default_timer as timer\nfrom hyperopt import tpe\n\n# optimization algorithm\ntpe_algorithm = tpe.suggest\n\nfrom hyperopt import Trials\n\n# Keep track of results\nbayes_trials = Trials()\n\n# File to save first results\nout_file = os.path.join(XGB_DIR,'gbm_testing_4cv_binary.csv')\nlogfile = open(out_file, 'w')\nwriter = csv.writer(logfile)\n\n# Write the headers to the file\nwriter.writerow(['loss', 'params', 'iteration', 'estimators', 'train_time'])\nlogfile.close()\nfrom hyperopt import fmin"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":56},{"cell_type":"code","source":["#lgbmodel = lgb.LGBMRegressor()\n#train_set = lgb.Dataset(Train_X, label = Train_4y[names[0]])\n# Run optimization\nglobal  iter\n\niter = 0\n\nbest = fmin(fn = objective, space = space, algo = tpe.suggest, \n            max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(13))"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":["lgbmodel = lgb.LGBMClassifier(boosting_type='goss',\n                             n_estimators=36,\n                             class_weight=None,\n                             colsample_bytree=0.8372995638410616,\n                             learning_rate=0.1958296478537693,\n                             min_child_samples=185,\n                             num_leaves=46,\n                             reg_alpha=0.6012356293352163,\n                             reg_lambda=0.4495316419073581,\n                             subsample_for_bin=120000)\npredicts = all_bin.filter(names)\nfor name in names:\n  for domain in domains:\n    rest = domains[:]\n    rest.remove(domain)\n\n    lgbmodel.fit(X[all_bin.domain.isin(rest)],all_bin[all_bin.domain.isin(rest)][name].tolist())\n    preds = np.round(lgbmodel.predict(X[all_bin.domain==domain]))\n    print(preds)\n    predicts.loc[all_bin.domain==domain, name] = preds\n\n#predicts.to_csv(os.path.join(XGB_DIR,'predicts20190501_binary.csv'),index=None)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n/databricks/python/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size &gt; 0` to check that an array is not empty.\n  if diff:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n</div>"]}}],"execution_count":58},{"cell_type":"code","source":["display(predicts)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>JAK1 EC50 nM 1027</th><th>JAK2 EC50 nM 1024</th><th>JAK3 EC50 nM 1026</th><th>TYK2 EC50 nM 1025</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":59},{"cell_type":"code","source":["train_data = lgb.Dataset(train[0],label=train[1])\nvalidation_data = lgb.Dataset(test[0],label=test[1], reference=train_data)\nlgbmodel = lgb.train(params=param, train_set = train_data, num_boost_round=10000, valid_sets=[validation_data],early_stopping_rounds =100)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_trees` in params. Will use it instead of argument\n  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))\n[1]\tvalid_0&#39;s auc: 0.823306\nTraining until validation scores don&#39;t improve for 100 rounds.\n[2]\tvalid_0&#39;s auc: 0.831843\n[3]\tvalid_0&#39;s auc: 0.832656\n[4]\tvalid_0&#39;s auc: 0.836856\n[5]\tvalid_0&#39;s auc: 0.843496\n[6]\tvalid_0&#39;s auc: 0.85481\n[7]\tvalid_0&#39;s auc: 0.857385\n[8]\tvalid_0&#39;s auc: 0.86416\n[9]\tvalid_0&#39;s auc: 0.86416\n[10]\tvalid_0&#39;s auc: 0.867005\n[11]\tvalid_0&#39;s auc: 0.868428\n[12]\tvalid_0&#39;s auc: 0.86897\n[13]\tvalid_0&#39;s auc: 0.871748\n[14]\tvalid_0&#39;s auc: 0.872696\n[15]\tvalid_0&#39;s auc: 0.874322\n[16]\tvalid_0&#39;s auc: 0.872967\n[17]\tvalid_0&#39;s auc: 0.875271\n[18]\tvalid_0&#39;s auc: 0.875\n[19]\tvalid_0&#39;s auc: 0.877913\n[20]\tvalid_0&#39;s auc: 0.878794\n[21]\tvalid_0&#39;s auc: 0.87893\n[22]\tvalid_0&#39;s auc: 0.880149\n[23]\tvalid_0&#39;s auc: 0.880556\n[24]\tvalid_0&#39;s auc: 0.879065\n[25]\tvalid_0&#39;s auc: 0.881707\n[26]\tvalid_0&#39;s auc: 0.880488\n[27]\tvalid_0&#39;s auc: 0.88252\n[28]\tvalid_0&#39;s auc: 0.883604\n[29]\tvalid_0&#39;s auc: 0.884892\n[30]\tvalid_0&#39;s auc: 0.884892\n[31]\tvalid_0&#39;s auc: 0.885434\n[32]\tvalid_0&#39;s auc: 0.88706\n[33]\tvalid_0&#39;s auc: 0.887737\n[34]\tvalid_0&#39;s auc: 0.889228\n[35]\tvalid_0&#39;s auc: 0.890854\n[36]\tvalid_0&#39;s auc: 0.891192\n[37]\tvalid_0&#39;s auc: 0.889566\n[38]\tvalid_0&#39;s auc: 0.890921\n[39]\tvalid_0&#39;s auc: 0.892683\n[40]\tvalid_0&#39;s auc: 0.89458\n[41]\tvalid_0&#39;s auc: 0.895122\n[42]\tvalid_0&#39;s auc: 0.896341\n[43]\tvalid_0&#39;s auc: 0.89607\n[44]\tvalid_0&#39;s auc: 0.89607\n[45]\tvalid_0&#39;s auc: 0.897019\n[46]\tvalid_0&#39;s auc: 0.898238\n[47]\tvalid_0&#39;s auc: 0.898374\n[48]\tvalid_0&#39;s auc: 0.900271\n[49]\tvalid_0&#39;s auc: 0.900813\n[50]\tvalid_0&#39;s auc: 0.900949\n[51]\tvalid_0&#39;s auc: 0.900678\n[52]\tvalid_0&#39;s auc: 0.901491\n[53]\tvalid_0&#39;s auc: 0.900949\n[54]\tvalid_0&#39;s auc: 0.900813\n[55]\tvalid_0&#39;s auc: 0.900949\n[56]\tvalid_0&#39;s auc: 0.90122\n[57]\tvalid_0&#39;s auc: 0.901355\n[58]\tvalid_0&#39;s auc: 0.901762\n[59]\tvalid_0&#39;s auc: 0.901897\n[60]\tvalid_0&#39;s auc: 0.901491\n[61]\tvalid_0&#39;s auc: 0.902033\n[62]\tvalid_0&#39;s auc: 0.902981\n[63]\tvalid_0&#39;s auc: 0.901762\n[64]\tvalid_0&#39;s auc: 0.902033\n[65]\tvalid_0&#39;s auc: 0.901897\n[66]\tvalid_0&#39;s auc: 0.900949\n[67]\tvalid_0&#39;s auc: 0.901897\n[68]\tvalid_0&#39;s auc: 0.901762\n[69]\tvalid_0&#39;s auc: 0.900678\n[70]\tvalid_0&#39;s auc: 0.901084\n[71]\tvalid_0&#39;s auc: 0.902168\n[72]\tvalid_0&#39;s auc: 0.903388\n[73]\tvalid_0&#39;s auc: 0.903659\n[74]\tvalid_0&#39;s auc: 0.903659\n[75]\tvalid_0&#39;s auc: 0.903794\n[76]\tvalid_0&#39;s auc: 0.903523\n[77]\tvalid_0&#39;s auc: 0.904065\n[78]\tvalid_0&#39;s auc: 0.90393\n[79]\tvalid_0&#39;s auc: 0.903659\n[80]\tvalid_0&#39;s auc: 0.902981\n[81]\tvalid_0&#39;s auc: 0.90271\n[82]\tvalid_0&#39;s auc: 0.902033\n[83]\tvalid_0&#39;s auc: 0.902033\n[84]\tvalid_0&#39;s auc: 0.902439\n[85]\tvalid_0&#39;s auc: 0.902033\n[86]\tvalid_0&#39;s auc: 0.901897\n[87]\tvalid_0&#39;s auc: 0.901626\n[88]\tvalid_0&#39;s auc: 0.902168\n[89]\tvalid_0&#39;s auc: 0.902575\n[90]\tvalid_0&#39;s auc: 0.902304\n[91]\tvalid_0&#39;s auc: 0.902846\n[92]\tvalid_0&#39;s auc: 0.903252\n[93]\tvalid_0&#39;s auc: 0.902981\n[94]\tvalid_0&#39;s auc: 0.90271\n[95]\tvalid_0&#39;s auc: 0.903659\n[96]\tvalid_0&#39;s auc: 0.903388\n[97]\tvalid_0&#39;s auc: 0.901897\n[98]\tvalid_0&#39;s auc: 0.902304\n[99]\tvalid_0&#39;s auc: 0.902575\n[100]\tvalid_0&#39;s auc: 0.902439\nDid not meet early stopping. Best iteration is:\n[77]\tvalid_0&#39;s auc: 0.904065\n</div>"]}}],"execution_count":60},{"cell_type":"code","source":["lgbmodel.best_iteration"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[142]: 77\n</div>"]}}],"execution_count":61},{"cell_type":"code","source":["lgbmodel.params"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[102]: {&#39;num_leaves&#39;: 31, &#39;objective&#39;: &#39;binary&#39;, &#39;metric&#39;: &#39;auc&#39;}\n</div>"]}}],"execution_count":62},{"cell_type":"code","source":["predicts.to_csv(os.path.join(XGB_DIR,'predicts20190429.csv'),index=None)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":63}],"metadata":{"name":"XGB-Hopt","notebookId":1316131172285131},"nbformat":4,"nbformat_minor":0}
